{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de40cc7-66fa-4d34-83cf-718399f6f957",
   "metadata": {},
   "source": [
    "# AIM5004__Assignment #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793379a-f95a-49c8-81cb-d8136d8ff09c",
   "metadata": {},
   "source": [
    "* 2022 , "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10129db-b04d-4d91-b2e9-309cedac62a4",
   "metadata": {},
   "source": [
    "* Training Convolutional Neural Networks (CNN). You are going to write codes in python with whichever deep learning libraries you prefer to use, e.g. pytorch, tensorflow, keras, jax, mxnet, and so on. (10pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f9cd7-0ee7-4be5-91d3-543c9f1a90f2",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6cd10-7a98-4961-9222-0474cea4b9e2",
   "metadata": {},
   "source": [
    "## Question - a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345c088-d34e-451c-9a3f-207f702ca83b",
   "metadata": {},
   "source": [
    "(a) Download CIFAR-10 dataset from https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "and report the statistics of the dataset, e.g. how many training (and testing) images,\n",
    "the size of each image, the number of class and the number of images per each classes.\n",
    "Also show random 5 images from each classes. Report the mean and standard deviation\n",
    "of the training datasets for each color channels (R,G,B). (1 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d1a4c-b5c8-45ca-abb2-ef5086902975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691b899-867b-4f07-8c25-9bc4b35b1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df133c-e98e-4e36-ac0a-019ad6e87211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de4f66a6-4ba2-4527-bddf-303321788e6f",
   "metadata": {},
   "source": [
    "### Arguments settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa22e16-9da8-41ee-a78a-05107a0d5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=5\n",
    "    bs=4\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    num_channels=3  # due to RGB channels(image)\n",
    "    num_classes=10  # total 10 classes in CIFAR-10\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58fd5fd-381c-4f94-922d-15c53c5e8c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc488c1a-66a1-4a28-8772-b91687dd11b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "608a9373-5f29-46e3-af26-6f7ac8674932",
   "metadata": {},
   "source": [
    "### Raw Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c975733-ce06-4357-97e7-09c20b3977ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad17306a-1204-46b2-80cb-00f5ae50dd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a176dd3-b9a9-4d0e-804f-0129eaf082be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b451f3f-7b0f-4b5b-8832-85f6c8ed9a23",
   "metadata": {},
   "source": [
    "### Mean & Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403811b5-e4d6-4e21-8712-df57df1ad439",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770a0517-77dd-44e7-a5dd-7ef38141a00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = data.mean(axis = (0,1,2)) \n",
    "std = data.std(axis = (0,1,2))\n",
    "print(f\"Mean : {mean}   STD: {std}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64b0719-2832-477f-823c-f0ee1aad4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean value of the Channel 1 is\", mean[0])\n",
    "print(\"and the standard deviation of channel 1 is\", std[0])\n",
    "print(\"The mean value of the Channel 2 is\", mean[1])\n",
    "print(\"and the standard deviation of channel 2 is\", std[1])\n",
    "print(\"The mean value of the Channel 3 is\", mean[2])\n",
    "print(\"and the standard deviation of channel 3 is\", std[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93aed23-0106-43f7-bf06-d99e2ac8eba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3b15ef9-c2d6-4b49-b3ff-162e1b6ba801",
   "metadata": {},
   "source": [
    "### Prepare Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5726dff-bc7a-4173-8c7a-f6bfb83f136e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Transforms\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_transforms_nor = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d77fb7-d4cd-41c8-a6de-bdf5b0f0ecc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading dataset again without normalize.\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288ce807-592d-412c-8a50-f5c39c3f090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading dataset again with normalize.\n",
    "train_dataset_nor = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms_nor)\n",
    "test_dataset_nor = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740f195-07f2-4405-859f-b3284889b969",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set trainloader and testloader for torch training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d3d63-3d98-4c3c-ae67-b27efd23ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking train_dataset\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938a3334-1553-4a5f-8566-756b8c625fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking test_dataset\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b661b8c-45e8-4213-8f04-86ae581c7eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7db3a9-d399-4e51-97a8-e1d9567bc18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0493b-92a6-4f8e-bf13-08bd9567c5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e60d122-d00c-43fb-9647-4ce9291b0bf9",
   "metadata": {},
   "source": [
    "### Basic information of CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0eb8ef-02e9-4efa-b4a4-aa575a9ad221",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of train dataset image is:\", train_dataset.data.shape[0])\n",
    "print(\"The number of test dataset image is:\", test_dataset.data.shape[0])\n",
    "print(\"The number of train dataset label is:\", len(collections.Counter(train_dataset.targets).keys()))\n",
    "print(\"The number of train dataset label is:\", len(collections.Counter(test_dataset.targets).keys()))\n",
    "print(\"The input image size of CIFAR 10 dataset is\", train_dataset.data.shape[1], \"x\", train_dataset.data.shape[2])\n",
    "print(\"The number of dataset in each label for train_dataset is \", collections.Counter(train_dataset.targets))\n",
    "print(\"The number of dataset in each label for test_dataset is \", collections.Counter(test_dataset.targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8565b-8402-4f14-91b9-0d89987eeeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3e96d-774a-4577-bd34-b27b093b5e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e8dbf-0da0-4c43-9326-d31ece8058f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575b243-5fe1-42e1-a9c6-ac8c98068309",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a8aec2-0bac-412e-a338-03129a52b0ef",
   "metadata": {},
   "source": [
    "### Sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d464537-a975-4eb3-9bd1-25d5817a1512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98343b2-cb4a-4ef3-a495-532155c6eb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba994ed-9d17-4821-a8e3-5424846f4812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284e472-668f-4443-908b-4942ab277fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b87322-ab64-4121-8379-1536b2397d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41ab3757-defe-4879-ad7b-89a38ed809a8",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e32a1a6-18a3-4929-afce-ba18c3f89b61",
   "metadata": {},
   "source": [
    "## Question - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fc6bb7-a32e-46ee-a8a6-508c505016f4",
   "metadata": {},
   "source": [
    "(b) Design a CNN architecture and write the training codes with the following hyperparameters. Provide a training loss curve (x-axis: the number of training iteration, y-axis: loss value) and a testing accuracy curve (x-axis: the number of training iteration, y-axis: classification accuracy on testing dataset). (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935a8359-5bdc-4dcd-844e-ad49a9081d98",
   "metadata": {},
   "source": [
    "(1) CNN architecture:\n",
    ">[conv1] → input channels: 3, output channels: 6, kernel size: 5, padding: 0, stride: 1\\\n",
    "[max pooling] → kernel size: 2, stride: 2\\\n",
    "[conv2] → input channels: 6, output channels: 16, kernel size: 5, padding: 0, stride: 1\\\n",
    "[fully connected layer1] → output channels: 120\\\n",
    "[fully connected layer2] → output channels: 84\\\n",
    "[fully connected layer3] → output channels: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa49d56-1b44-476e-b05c-9ee08bad108d",
   "metadata": {},
   "source": [
    "(2) activation function: ReLU\\\n",
    "(3) loss function: cross entropy loss\\\n",
    "(4) optimization algorithm: SGD\\\n",
    "(5) learning rate: 0.001\\\n",
    "(6) momentum: 0.9\\\n",
    "(7) batch size: 4\\\n",
    "(8) The number of training epoch: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fc2a6-2541-49a6-b7f7-03a13f6e9139",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7a3db-1da5-4dd9-a30b-11eac033e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Batch size is\", args.bs)\n",
    "print(\"Learning rate is\", args.lr)\n",
    "print(\"Momentum is \", args.momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70f29be-d7c7-4af0-8848-71705996d095",
   "metadata": {},
   "source": [
    "### CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0168e3-b8b4-47c8-bec8-b13d0048f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CIFAR-10 CNN model architecture design\n",
    "class CIFAR_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR_CNN, self).__init__()\n",
    "        ## convolution layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        ##### 28x28\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        ##### 14x14\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        ##### 10x10\n",
    "        \n",
    "        ## fully connected layers\n",
    "        self.fc1 = nn.Linear(10*10*16, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, args.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(-1, 10*10*16)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c176fee-c5d9-4851-a8ec-69a0140dc6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR_CNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = args.lr, momentum=args.momentum)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b048d79-0b81-46ca-87cb-a40a6d7f0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set trainloader and testloader for torch training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caed47ff-463a-4819-905e-69746401ae33",
   "metadata": {},
   "source": [
    "### Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588b042-7e0d-41d1-af37-87199c77957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11d645-729b-4157-a873-63cf9b22f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader)) \n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b79b8f1-6af8-4d67-8d05-263828f806ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "los_total = []\n",
    "acc_total = []\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    val_loss, validation_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, val_loss, validation_accuracy))\n",
    "    \n",
    "    los_total.append(val_loss)\n",
    "    acc_total.append(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72950fd7-d205-413d-b2b8-1e04b7c11b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "610c3ad0-fd8a-4edb-b6a1-afc20d73bc91",
   "metadata": {},
   "source": [
    "### Accuracy and Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f488d66b-cb6c-45eb-b240-afc78066bb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), acc_total)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['CNN Accuracy'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc379048-c343-4d07-96ff-ad31eef9f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), los_total, '-r')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['CNN Loss'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d60905-658a-4e16-8f87-82edcfe27e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be85ed-091d-40ec-a09f-c3784898b702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "447e7dbb-a49c-40cc-b4e4-1022d9eefd96",
   "metadata": {},
   "source": [
    "- - - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941afe0-191b-4ea9-b138-b05c1c41439f",
   "metadata": {},
   "source": [
    "## Question - c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa8ed08-94ff-46d7-a08b-dadb40223063",
   "metadata": {},
   "source": [
    "(c) Normalize the inputs with mean and standard deviation computed in (1). Compare the training loss and testing accuracy curves by drawing two curves in a same plot. (1pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bec73e-1c44-442a-bad8-d14a91e49c2e",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10fdee-247c-435a-ac3c-71c54e0d7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading dataset again with normalize.\n",
    "train_dataset_nor = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms_nor)\n",
    "test_dataset_nor = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms_nor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2def74-1323-46ef-b220-f900fa73d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set trainloader and testloader for torch training\n",
    "train_loader_nor = torch.utils.data.DataLoader(train_dataset_nor, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader_nor = torch.utils.data.DataLoader(test_dataset_nor, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3f8cb4-991c-49b7-9e55-0c8be598da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR_CNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = args.lr, momentum=args.momentum)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470b9786-dd8d-46c1-9bc3-2d49aefebb46",
   "metadata": {},
   "source": [
    "### Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd48a38-ddd2-4d97-953a-d7146eaa25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader_nor, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    for batch_idx, (image, label) in enumerate(train_loader_nor):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader_nor.dataset), 100. * batch_idx / len(train_loader_nor), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78422b2-d772-4473-a633-54aec8faab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader_nor):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader_nor:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader_nor)) \n",
    "    test_accuracy = 100. * correct / len(test_loader_nor.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf045b-c7a9-453f-99d0-74e6741e2465",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking train, val loss and accuracy\n",
    "los_total_nor = []\n",
    "acc_total_nor = []\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader_nor, optimizer, log_interval = 200)\n",
    "    val_loss, validation_accuracy = evaluate(model, test_loader_nor)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, val_loss, validation_accuracy))\n",
    "    \n",
    "    los_total_nor.append(val_loss)\n",
    "    acc_total_nor.append(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e132a6fd-bb58-4ba1-854a-2a4cd32849ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8109c7d-fddc-46d3-8615-e04c968c7b97",
   "metadata": {},
   "source": [
    "### Accuracy and Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414bf08d-d5b6-48c8-9467-a6176bfa2f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), acc_total)\n",
    "plt.plot(range(args.epochs -1), acc_total_nor)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['Basic Accuracy', 'Normalize Accuracy'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabeb8b7-bb6e-48f6-a851-48428c648c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), los_total)\n",
    "plt.plot(range(args.epochs -1), los_total_nor)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['Basic Loss', 'Normalize Loss'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d38908-6973-41bd-8f07-dc3ef1c1c6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ed1fc-836f-4352-a81e-d5fb6d80ce21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b826e65-0592-49ef-aa75-5f8390656ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49529d4-fbcc-4f7e-ad11-cbdad57e2d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bdf2a8-605d-4b1c-9179-0d24ac332e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27898d3d-859c-4620-ab83-ab4cfcfe3f52",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538a7d52-30c5-4df9-951a-1efbb492fda9",
   "metadata": {},
   "source": [
    "## Question - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cbaab-090b-4f76-a82b-520d00b05660",
   "metadata": {},
   "source": [
    "(d) Train with a MLP architecture that has the same number of layers (4 layers, each layers have 128 hidden units, ReLU activation function). Compare the training loss and testing accuracy by drawing two curves in a same plot. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee554c1-8738-4d26-b70b-1934b202d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set trainloader and testloader for torch training\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdf0a4-2e34-43c2-b7c1-da17bc983265",
   "metadata": {},
   "source": [
    "### MLP model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f251b8b3-b0dc-45cf-8a12-4a2c8eab33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFAR_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR_MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(32 * 32 * 3, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 128)\n",
    "        self.layer4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32 * 32 * 3)\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer4(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a45882-add6-41b2-b14a-0fa47cc4698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MNIST = CIFAR_MLP()\n",
    "model_MLP = model_MNIST.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_MLP.parameters(), lr = args.lr, momentum=args.momentum)\n",
    "print(model_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036e70e5-aa6e-4236-9ecb-58935b675332",
   "metadata": {},
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e2a13-3152-470b-a096-e4d4fbe6a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "los_total_mlp = []\n",
    "acc_total_mlp = []\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model_MLP, train_loader, optimizer, log_interval = 200)\n",
    "    val_loss, validation_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, val_loss, validation_accuracy))\n",
    "    \n",
    "    los_total_mlp.append(val_loss)\n",
    "    acc_total_mlp.append(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d18656-bdbb-4375-8f23-17502cff1033",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b49925-3ab3-4596-8340-0157265167b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8657dc8-f128-42a0-898a-28cc6f2c78cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b80162-3e22-4cf4-91ef-550e6537dbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c55ecfa-546a-41d7-9603-27acb4c72325",
   "metadata": {},
   "source": [
    "### Accuracy and Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b7cb0-6697-4c86-9d70-3823640bf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), acc_total)\n",
    "plt.plot(range(args.epochs -1), acc_total_mlp)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['Basic Accuracy', 'MLP Accuracy'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd544fb-8590-457c-8467-628792582491",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), los_total)\n",
    "plt.plot(range(args.epochs -1), los_total_mlp)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['Basic Loss', 'MLP Loss'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64badc01-48cd-4a6e-9d5d-dc429fe4d2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d10a5-108e-4cde-9299-d3f8969869fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04e42039-639c-44d0-b7d5-daadc8143274",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43abbff0-94cb-43ed-b5f3-ad25469acf91",
   "metadata": {},
   "source": [
    "## Question - e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d91091-cf9e-4df9-a38b-cd3af132302d",
   "metadata": {},
   "source": [
    "(e) Train with Adam optimizer and compare the training loss and testing accuracy by drawing two curves in a same plot. (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93ab84-6931-44b2-b1e7-252ff07b1022",
   "metadata": {},
   "source": [
    "### Adam Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a11775-ef0e-4c5a-a43e-ccf086be0226",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CIFAR_CNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9296f1-7ced-4691-9272-e01f147ce2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7b06f18-976d-42de-91c6-e2ab00c87d33",
   "metadata": {},
   "source": [
    "### Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd838f58-9634-40ee-ab74-422884a9dfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "los_total_adam = []\n",
    "acc_total_adam = []\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    val_loss, validation_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, val_loss, validation_accuracy))\n",
    "    \n",
    "    los_total_adam.append(val_loss)\n",
    "    acc_total_adam.append(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92b31e-8497-4f60-a276-0d21e7f4a286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc1d751-17c5-45d0-a421-dfdcfaafd989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31d71574-1b05-4d10-9e0b-64bac9392f2c",
   "metadata": {},
   "source": [
    "### Accuracy and Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fcaf5e-7689-44c8-9b13-b6d6d23ee216",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), acc_total)\n",
    "plt.plot(range(args.epochs -1), acc_total_adam)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['SGD Accuracy', 'ADAM Accuracy'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce1ca5f-c027-428b-ad7b-a2662b2e68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "## edit the plot list here\n",
    "plt.plot(range(args.epochs -1), los_total)\n",
    "plt.plot(range(args.epochs -1), los_total_adam)\n",
    "\n",
    "\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "ax.legend(['SGD Loss', 'ADAM Loss'],fontsize=15)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d61f95-0a56-4027-8f0e-2e9d3ad4f206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8542ccd4-d2cc-4bb1-9c98-c319c578d33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "494ffa72-d62a-4c2d-afd6-638b530753b9",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca41b5-52eb-434e-b098-3a37f2e7a404",
   "metadata": {},
   "source": [
    "## Question - f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0126d25-14d5-42bc-b822-047f175c4c12",
   "metadata": {},
   "source": [
    "(f) Change the hyperparameters and network architectures to achieve better training loss and testing accuracy curves. Provide the final architecture and hyperparameters that you used. (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d15d68-1533-4a41-9f65-64bac0f13585",
   "metadata": {},
   "source": [
    "### Arguments settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f1adf5-e334-4da5-bea5-9a26db8c4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=10\n",
    "    bs=16\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    num_channels=3  # due to RGB channels(image)\n",
    "    num_classes=10  # total 10 classes in CIFAR-10\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349cb395-f2aa-4aa3-a966-2a27e2c9dc50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b504ea7-18a1-417d-b451-0144241de5f6",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b544a2b9-2ac0-4386-abdb-a163e5a2b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms_my = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(contrast=(0.3,1), saturation=(0.3,1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.49139968, 0.48215841, 0.44653091], [0.24703223, 0.24348513, 0.26158784])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd77ab9-b9f8-44c2-b00a-07c486f5d0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading dataset again with normalize.\n",
    "train_dataset_my = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms_my)\n",
    "test_dataset_my = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms_my)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8ac09e-3dc8-4e36-b696-956c9cc8cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set trainloader and testloader for torch training\n",
    "train_loader_my = torch.utils.data.DataLoader(train_dataset_my, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader_my = torch.utils.data.DataLoader(test_dataset_my, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae1c015-eaa9-4929-8a28-75759455ed1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e3f15-4241-48e9-8747-1070bd2c1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader_my)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2102459a-e611-429b-96af-41fe45f2a78b",
   "metadata": {},
   "source": [
    "### My model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393c540-26d1-420f-b14e-8be823684211",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Designing simple CNN model architecture.\n",
    "class CNN_my(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(CNN_my, self).__init__()\n",
    "\n",
    "        def conv_batch(input_size, output_size, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_size, output_size, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(output_size),\n",
    "                nn.ReLU(inplace=True)\n",
    "                )\n",
    "\n",
    "        def conv_depth(input_size, output_size, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_size, input_size, 3, stride, 1, groups=input_size, bias=False),\n",
    "                nn.BatchNorm2d(input_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                \n",
    "                nn.Conv2d(input_size, output_size, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(output_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_batch(3, 32, 2),\n",
    "            conv_depth(32, 64, 1),\n",
    "            conv_depth(64, 128, 2),\n",
    "            conv_depth(128, 128, 1),\n",
    "            conv_depth(128, 256, 2),\n",
    "            conv_depth(256, 256, 1),\n",
    "            conv_depth(256, 512, 2),\n",
    "            conv_depth(512, 512, 1),\n",
    "            conv_depth(512, 512, 1),\n",
    "            conv_depth(512, 1024, 2),\n",
    "            conv_depth(1024, 1024, 1),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b9a71-23ce-45e9-b99b-e4e9aca844d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2e8aa-d4d3-4409-8a93-af9a97d72b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ff9f3-b5d7-48a0-89ec-348ad5b4ed10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccc859-fd9b-4123-9b49-4b93a79ef557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60d0e0e9-b7de-4f14-bc99-a2e8183faf6a",
   "metadata": {},
   "source": [
    "### Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138166c8-e1e8-4bbf-be27-bc52af235530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_res = models.resnet18(num_classes=2, pretrained=True)\n",
    "model_eff3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes=args.num_classes)\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "model_mobnetv2 = models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4f8f1-f80a-4c75-a9b3-6e189ae4b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ff14f-db97-4d72-843f-76a18a350fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet18.fc = nn.Linear(in_features = 512, out_features = 256)\n",
    "model_mobnetv2.classifier = nn.Linear(in_features = 1280, out_features=args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb99a450-a64e-45fc-a9c5-b787c67ebd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_layer = nn.Linear(in_features = 256, out_features = args.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922cfe9-4ee4-40fe-8005-0aeb34276db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.fc = nn.Sequential(model_resnet18, add_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab66a22-c012-4675-8565-c8c4cdb6a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16722bc1-0bb9-4abc-94c6-1e2d4ea0d097",
   "metadata": {},
   "source": [
    "### Finalize the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8548f87-517b-4e71-9010-1ca4c325bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_my = CNN_my(args.num_channels, num_classes = args.num_classes).to(DEVICE)\n",
    "# model_my = CIFAR_LeNet().to(DEVICE)\n",
    "model_my = model_eff3.to(DEVICE)\n",
    "# model_my = model_mobnetv2.to(DEVICE)\n",
    "# model_my = model_resnet18.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c878e25-8f63-4d65-8784-466d4802cbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81094250-2709-49a5-a205-c43013c27730",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e11bac-3bef-4956-8522-b63b81791388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Optimizer and Objective Function\n",
    "\n",
    "optimizer = torch.optim.Adam(model_my.parameters(), lr = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=args.epochs, anneal_strategy='cos')\n",
    "criterion = nn.CrossEntropyLoss() ## setup the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cfda2-e3ee-4ceb-87ec-31ef5975f856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a001e16-4698-4400-976e-4e8b9cee131b",
   "metadata": {},
   "source": [
    "### Training procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0118fd9-2eb5-4f55-899f-28da80e3abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model_my, train_loader_my, optimizer, log_interval):\n",
    "    model_my.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    for batch_idx, (image, label) in enumerate(train_loader_my):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model_my(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader_my.dataset), 100. * batch_idx / len(train_loader_my), \n",
    "                loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a2816-c6ab-4d6c-b5a9-6516d64534df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model_my, test_loader_my):\n",
    "    model_my.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader_my:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model_my(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader_my)) \n",
    "    test_accuracy = 100. * correct / len(test_loader_my.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b668ce97-92ca-4aee-a2d8-af9103717df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "los_total_my = []\n",
    "acc_total_my = []\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model_my, train_loader_my, optimizer, log_interval = 200)\n",
    "    val_loss, validation_accuracy = evaluate(model_my, test_loader_my)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, val_loss, validation_accuracy))\n",
    "    \n",
    "    los_total_my.append(val_loss)\n",
    "    acc_total_my.append(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebba435-a825-4e06-af2f-31ff743d9bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eeda8fe-bc57-40a4-89b3-47cc03d07008",
   "metadata": {},
   "source": [
    "### Accuracy and Loss plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd990ac3-4db6-4715-9890-645e01c8f483",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy Graphs\n",
    "plt.rc('font', family='Times New Roman', serif='Times')\n",
    "plt.rc('xtick', labelsize=16)\n",
    "plt.rc('ytick', labelsize=16)\n",
    "plt.rc('axes', labelsize=20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.subplots_adjust(left=.15, bottom=-1.16, right=1.99, top=.97)\n",
    "\n",
    "color ='tab:blue'\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Number of Epochs')\n",
    "plt.plot(range(args.epochs -1), acc_total_my)\n",
    "ax.legend(['My Model Accuracy'],fontsize=15, loc='upper right')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "ax1 = ax.twinx()\n",
    "color = 'tab:red'\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.plot(range(args.epochs -1), los_total_my, color = color)\n",
    "ax1.legend(['My Model Loss'], fontsize=15, loc='lower right')\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e71b1-fdf6-4822-afd5-4b3ac0aa823a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2663c15-181b-4e97-baec-87b19089f8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6cee33-b275-4091-a3b9-ce3efcc359fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564c167e-61e0-4bf8-ad29-f2395fcd4983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
