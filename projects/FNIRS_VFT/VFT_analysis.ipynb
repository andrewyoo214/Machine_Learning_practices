{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2712d938-c14b-4158-8afa-58787e0ea333",
   "metadata": {},
   "source": [
    "# FNIRS + VFT analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa41bf-d633-40f0-a42c-2541bce98415",
   "metadata": {},
   "source": [
    "* fNIRS brain blood flow dataset with VFT (Verbal Fluency Task) on normal / depression / suicidality subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4f27d2-3f08-4a1c-a0a5-b0b7573a0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dae33-3294-4aa5-a0dd-e0d91718db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa98f63-20c1-479c-8efb-4039da5c49eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f094132-6cab-4047-ab1f-faae97d9224e",
   "metadata": {},
   "source": [
    "# #2. VFT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0ce9c-3222-4911-aa5b-35979b9df16e",
   "metadata": {},
   "source": [
    "## Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561a0e0-c0a6-4319-92b5-57329da79b02",
   "metadata": {},
   "source": [
    "### Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fff46a-595e-4793-8b1f-fdae390ad3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking current directory\n",
    "directory = os.getcwd()\n",
    "print(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88151baa-cde6-45e4-8f9f-ecf7a51eecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "data_transforms = transforms.Compose([\n",
    "#     transforms.Resize(300),\n",
    "#     transforms.RandomResizedCrop(300),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.ColorJitter(contrast=(0.3, 1), saturation=(0.3, 1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456,0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e064710a-3917-4821-9594-2ed5915b441c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6f36e-f08b-417f-bfe4-340860d3beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading the food image data\n",
    "vft_train = datasets.ImageFolder(root = 'E:/RESEARCH/BRAIN/research_data/VFT__', transform = data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566612c3-2af6-4f11-ad87-8e2850942877",
   "metadata": {},
   "outputs": [],
   "source": [
    "vft_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50b360c-9671-4aca-8f88-238299d226e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f82326c6-4dee-4022-9873-617caf48d271",
   "metadata": {},
   "source": [
    "### Device setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c90812-e716-4d8d-aa1a-dbe525af4ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## enviroinment setting\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655390eb-fcff-4210-bf3d-9f2c092c4594",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53bf2c90-f97c-4327-bbaf-52274827e383",
   "metadata": {},
   "source": [
    "## Model  preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca60d9-20cc-4d18-9e26-1506d4569a4b",
   "metadata": {},
   "source": [
    "### Basic settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3c4fd-55e7-4bdb-a928-fcf419067c40",
   "metadata": {},
   "source": [
    "#### arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674c69a-5b8e-480b-bad8-2550f8615945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## arguments setting for hyperparameter tuning\n",
    "class Args:\n",
    "    # arugments\n",
    "    epochs=50\n",
    "    bs=64\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    \n",
    "    num_channels=3\n",
    "    num_classes=3\n",
    "    verbose='store_true'\n",
    "    seed=712002\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ff01c5-92cf-461b-be52-f846b56356a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf75f4-2e80-4d6b-b76f-ac1240588e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## divide the overall dataset into train and test dataset\n",
    "train_size = int(0.8 * len(vft_train))\n",
    "test_size = len(vft_train)-train_size\n",
    "print('Training dataset size is:', train_size, '/ Test dataset size is:', test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc739c81-3fc2-4b9b-badb-7011c943d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split for model training\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(vft_train, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c2ccb-984b-4a21-9a81-ae583dbb37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df374cb8-a3e4-488f-91d7-e4c636d746d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864e54d-977d-42eb-806d-8eae7fa25a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a836d484-6fcb-42d9-9cb7-a184687fd355",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81439c14-88a4-4b26-9428-97cffb1e151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_vft(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(cnn_vft, self).__init__()\n",
    "\n",
    "        def conv_batch(input_size, output_size, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_size, output_size, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(output_size),\n",
    "                nn.ReLU(inplace=True)\n",
    "                )\n",
    "\n",
    "        def conv_depth(input_size, output_size, stride):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(input_size, input_size, 3, stride, 1, groups=input_size, bias=False),\n",
    "                nn.BatchNorm2d(input_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                \n",
    "                nn.Conv2d(input_size, output_size, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(output_size),\n",
    "                nn.ReLU(inplace=True),\n",
    "                )\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            conv_batch(3, 32, 2),\n",
    "            conv_depth(32, 64, 1),\n",
    "            conv_depth(64, 128, 2),\n",
    "            conv_depth(128, 128, 1),\n",
    "            conv_depth(128, 256, 2),\n",
    "            conv_depth(256, 256, 1),\n",
    "            conv_depth(256, 512, 2),\n",
    "            conv_depth(512, 512, 1),\n",
    "            conv_depth(512, 512, 1),\n",
    "            conv_depth(512, 1024, 2),\n",
    "            conv_depth(1024, 1024, 1),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "#         self.fc1 = nn.Linear(1024, 100)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(-1, 1024)\n",
    "#         x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc86061-d902-456e-b563-7f187161d952",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting Optimizer and Objective Function\n",
    "\n",
    "model = cnn_vft(in_channels=args.num_channels, num_classes=args.num_classes).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, total_steps=600, anneal_strategy='cos')\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3b92e-23d6-44c6-8a77-a705ba5e48d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "180be19e-a754-4548-9478-5ce3ebe44d7e",
   "metadata": {},
   "source": [
    "### Training on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a86a6-94a8-4058-b599-f8defa75a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "    \n",
    "    scheduler.step() #for learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae517319-8d03-4623-b8fd-c6bbb4ff1be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a25bd5e-9784-4aa3-87b8-0febd559b06b",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8ab19-e7cf-4d74-8c97-3b53f68e3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader)) \n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c040d1-46a7-4fef-b57e-4a806806647b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa2cedc-4d53-43a3-9b84-643b85c723a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "total = []\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))\n",
    "    \n",
    "    total.append((test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea73383-0b99-4d28-8948-756a0acd7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d77abf-6a7b-4b81-bd43-106ca193bb62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "622d6a12-38d2-4ded-a227-ea5f7eb241e2",
   "metadata": {},
   "source": [
    "### Save the model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ced10d1-e016-48a4-9ac0-02e92fe0da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving pytorch model\n",
    "\n",
    "torch.save(model.state_dict(), directory + '/vft_model1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf6941-e61a-4991-bbfc-0c9329251b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd328185-4907-4921-9aea-1c37c038d064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f94a74e-bc91-4ec8-b336-fe7228670cb5",
   "metadata": {},
   "source": [
    "## Using pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73734c2-9a0e-41aa-b8dc-a22d9147496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eff3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes= args.num_classes)\n",
    "model = model_eff3.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313f652-a8a5-40bb-94b1-07be3355d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving pytorch model\n",
    "torch.save(model.state_dict(), directory + '/vft_pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d7869-fcf2-4530-9dcc-11a9b2c5e9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Optimizer and Objective Function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=args.epochs, anneal_strategy='cos')\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c36ea-7972-401d-8e67-8ea53b743996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "\n",
    "    scheduler.step() #for learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f8c77a-076a-4b7b-b6ed-ba9b2843cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader)) \n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af54a2c-80b9-4881-abe4-741333309014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "\n",
    "total = []\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))\n",
    "    \n",
    "    total.append((test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cbe7d1-5948-4ce1-9f84-e8412ee50f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8696a-d344-4643-894c-d5c5d933d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving pytorch model\n",
    "\n",
    "torch.save(model.state_dict(), directory + '/fnirs_pretrained_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8741039e-f4f0-4555-9581-e8639979f5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2251eb5-9e50-4e4d-9865-01e07ba2ed33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe4266-055a-48f4-a049-881a54082102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c71592b9-9128-4001-a0a1-6a3b77db34ef",
   "metadata": {},
   "source": [
    "## Model performance check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905334e-f0da-4c17-8444-34d18ddcce92",
   "metadata": {},
   "source": [
    "### Heatmap for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c8ad21-ab02-41d9-b5c5-4cebbddebbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classes = args.num_classes\n",
    "confusion_matrix = np.zeros((nb_classes, nb_classes))\n",
    "classes = {\n",
    "    \"0\": \"Depression\",\n",
    "    \"1\": \"Normal\",\n",
    "    \"2\": \"Suicidality\"\n",
    "}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (image, label) in enumerate(test_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        outputs = model(image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(label.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "print(confusion_matrix)\n",
    "\n",
    "class_names = list(classes.values())\n",
    "df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names).astype(int)\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right',fontsize=10)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize=10)\n",
    "plt.ylabel('True label', fontsize=12)\n",
    "plt.xlabel('Predicted label', fontsize=12)\n",
    "# plt.savefig('dep_train_entire_output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e2262-1d3c-4e6a-a86f-c1ff23543a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "080b8292-c085-4b36-a42f-be9297060b7b",
   "metadata": {},
   "source": [
    "### Accuracy, sensitivity, specificity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ce809c-dbb0-44e9-9349-cd778a0630b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix\n",
    "total = sum(sum(cm))\n",
    "\n",
    "## Accuracy, Sensitivity, and Specificity\n",
    "acc = (cm[0,0]+cm[1,1]+cm[2,2]) / total\n",
    "sen_dep = cm[0,0] / (cm[0,0] + cm[0,1] + cm[0,2])\n",
    "sen_nor = cm[1,1] / (cm[1,0] + cm[1,1] + cm[1,2])\n",
    "sen_sui = cm[2,2] / (cm[2,0] + cm[2,1] + cm[2,2])\n",
    "\n",
    "spe_dep = (cm[1,1] + cm[2,2]) / (cm[1,0] + cm[2,0] + cm[1,1] + cm[2,2])\n",
    "spe_nor = (cm[0,0] + cm[2,2]) / (cm[0,1] + cm[2,1] + cm[0,0] + cm[2,2])\n",
    "spe_sui = (cm[0,0] + cm[1,1]) / (cm[0,2] + cm[1,2] + cm[0,0] + cm[1,1])\n",
    "\n",
    "print(\"Overall classification accuracy is :\", round(acc, 4))\n",
    "print(\"sensitivity of Depression class is :\", round(sen_dep, 4))\n",
    "print(\"sensitivity of Normal class is :\", round(sen_nor,4))\n",
    "print(\"sensitivity of Suicidality class is :\", round(sen_sui,4))\n",
    "\n",
    "print(\"specificity of Depression class is :\", round(spe_dep,4))\n",
    "print(\"specificity of Normal class is :\", round(spe_nor,4))\n",
    "print(\"specificity of Suicidality class is :\", round(spe_sui,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe69b5b8-e7f8-43b1-9368-d7b2483d294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average sensitivity is \",      ((sen_dep + sen_nor + sen_sui) /3) )\n",
    "print(\"Average specificity is \", ((spe_dep + spe_nor + spe_sui) /3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1d1ae-b104-47fa-93bf-fa11b506b318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a14b1-8caf-46bd-ab2e-30333df05e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9463c9-c25d-45c1-920c-bc494ff41d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75acaba8-ccb8-467c-bade-da26af7dec1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bd8676-7a25-4a24-93cf-7651a54190df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
