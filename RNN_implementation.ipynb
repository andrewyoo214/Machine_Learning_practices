{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85d30a4-0085-45fd-93a4-e493a7a52920",
   "metadata": {},
   "source": [
    "# AIM5004_HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437b24-0103-441b-bb0d-17f6ba7f0e7c",
   "metadata": {},
   "source": [
    "* (Total 10 pts) Training a character-level language model with recurrent neural networks and Transformers architecture. You are going to write codes in python w/ whichever deep learning libraries you prefer to use, e.g. pytorch, tensorflow, keras, jax, mxnet, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb124e35-d4dd-4e46-a818-bb98e5fbd71b",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2f4bf-7cd4-4eaa-aef1-9091958d8888",
   "metadata": {},
   "source": [
    "## Question - a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f45a5-3328-4dd3-9e88-61c0b3ccef24",
   "metadata": {},
   "source": [
    "(a) Download shakespeare dataset from https://storage.googleapis.com/download.\n",
    "tensorflow.org/data/shakespeare.txt. Report the number of unique characters\n",
    "and this number will be the number of your vocabulary (note that ’a’ and ’A’ are\n",
    "different characters). Also, show 3 random chunks (200 characters per each) of the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61091cd-63e9-438d-9f25-2bdc301d0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import codecs\n",
    "import string\n",
    "import nltk\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6377fcea-798b-47a6-a9a2-9ded243ebd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aff1044-3fb8-4f9a-83c4-2e675d0fd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.7.1  Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "##Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e67ee8-a653-408b-9f3e-25826c36ebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f08785-283f-42eb-bbd8-6484d4c78cf6",
   "metadata": {},
   "source": [
    "### Shakespeare text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d9b5d73-aeef-4679-b624-ed73659df5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us\n"
     ]
    }
   ],
   "source": [
    "data_fpath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "shakespeare = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
    "data = shakespeare\n",
    "data_len = len(data)\n",
    "print(data_len)\n",
    "print(data[:300]) ## including space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8fc70-de85-46f0-8fb5-160ea54c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e6cc9-5b27-4390-a950-c05b2faaf60c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90123771-d369-4e43-b6a5-442c942a6c78",
   "metadata": {},
   "source": [
    "### Vocabulary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1fa81fa-38a9-475f-adc7-28e85a60be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of the Shakespeare data: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "The number of unique characters: 65\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary of the Shakespeare data: {}'.format(vocab))\n",
    "print('The number of unique characters: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "631e22a0-ab16-4aec-839f-bd8a472c95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of the original text:  First Citizen\n",
      "Example of the encoded text:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}         ## dictionary to create id for each vocab(character)\n",
    "idx2char = np.array(vocab)                            ## numpy array for each vocab(character)\n",
    "text_as_int = np.array([char2idx[c] for c in data])   ## convert text format into id format\n",
    "\n",
    "print('Example of the original text: ', data[:13])\n",
    "print('Example of the encoded text:  {}'.format(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6ac1d-7e1e-49cb-a3cf-2b58422c1a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de912833-ef50-4bc0-924b-bd1f35cd963b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86af9869-f5a2-4116-9afc-2ec2741474cb",
   "metadata": {},
   "source": [
    "### Random dataset chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2eb1bb-8de1-4c4e-878f-df9391ad95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 200\n",
    "\n",
    "def random_select():\n",
    "    stt = random.randint(0, data_len - chunk)\n",
    "    end = stt + chunk + 1\n",
    "    return data[stt : end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743825c-3bcb-42ea-8cc7-2ee39ac8d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0904ca-bf27-4354-afed-3a8808e853c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Second random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc92e5-3d38-4b1a-8bb3-8dcd6f6dc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Third random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33af7a-060a-4717-a785-abd553174339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc687f4-7b8c-4d40-8603-8e635b1fa098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207b3f19-2295-480b-898d-9898857d5a08",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52088903-49b7-417c-8c7b-8f6e7947088d",
   "metadata": {},
   "source": [
    "## Question - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14389ca6-e02b-46ee-bcc6-75195d0fe0bf",
   "metadata": {},
   "source": [
    "(b) Design a vanila RNN architecture and write the training codes w/ following hyperparameters. Report the number of model parameters.\n",
    "(You can use RNN libararies, if you want, but I recommend you to implement by yourself.)\n",
    "> (1) input embedding size: 64 \\\n",
    "(2) hidden size: 128 \\\n",
    "(3) the number of time steps (sequence length, or chunk length): 200 \\\n",
    "(4) the number of layers: 3 \\\n",
    "(5) activation function for hidden units: tanh \\\n",
    "(6) loss function: cross entropy loss \\\n",
    "(7) optimization algorithm: ADAM \\\n",
    "(8) batch size: 64 \\\n",
    "(9) training epochs: 30 \\\n",
    "(10) for other hyperparemeters, you are free to choose whatever you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606485fa-b100-42e1-b60c-7f7bb3623739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    emb_size=64\n",
    "    seq_size=200   ## chunk length\n",
    "    lstm_size=64\n",
    "    g_norm=5\n",
    "    bs=64\n",
    "    num_step=20\n",
    "    epochs=30\n",
    "    lr=0.001\n",
    "    momentum = 0.9\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb614450-ef0c-42e8-a45e-8a14aac7860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b10ff-9a7c-4ed8-b0a2-d7dbfd92ea89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37598ce-f48d-4111-af11-6fa666f402f8",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc48bb8-80ec-424d-b2cc-dc6c230e6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting document into words\n",
    "def doc2words(doc):\n",
    "    lines = doc.split('\\n')\n",
    "    lines = [line.strip(r'\\\"') for line in lines]\n",
    "    words = ' '.join(lines).split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5ef75-1427-4a66-8fb8-d5d19fc9beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing punctuations attached to words\n",
    "def removepunct(words):\n",
    "    punct = set(string.punctuation)\n",
    "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba40e2-64fa-4e1f-9851-f9d8c9ee3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get vocabulary from word list\n",
    "def getvocab(words):\n",
    "    wordfreq = Counter(words)\n",
    "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
    "    return sorted_wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b9a3d-57a6-4660-95c7-cce56b38c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get dictionary of int to words and word to int\n",
    "def vocab_map(vocab):\n",
    "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
    "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f125b5-79ec-4139-b13a-00f9a456b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = removepunct(doc2words(data))\n",
    "vocab = getvocab(words)\n",
    "int_to_vocab, vocab_to_int = vocab_map(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39687d5a-3d4f-4612-b1db-5056271f0bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sample words: \", words[:10])\n",
    "print(\"sample vocab: \", vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf189b-6384-42ac-b905-9f0938b33ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780b8d2-7115-4a10-902b-d35a8c49e33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d76a403f-5a42-4e12-8061-a273b7b006fd",
   "metadata": {},
   "source": [
    "* Preparing batch set for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b1d8b-0a1c-4f9e-8617-6bfa350988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
    "    # generate a Xs and Ys of shape (batchsize * num_batches) * seq_size\n",
    "    word_ints = [vocab_to_int[word] for word in words]\n",
    "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
    "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
    "    Ys = np.zeros_like(Xs)\n",
    "    Ys[:-1] = Xs[1:]\n",
    "    Ys[-1] = Xs[0]\n",
    "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
    "    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
    "    \n",
    "    # iterate over rows of Xs and Ys to generate batches\n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31ea0c-b744-4721-9808-f0a9f216e0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bca8a4-3084-4034-8dc1-3f6759c0946f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57098ff2-ff67-4d0b-b6df-6b1429223377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5e343e-dcb8-4bc5-8621-06114ccabc80",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8970b-0d6a-4a07-bee1-3b2cd1cfa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    ## initialize RNN module\n",
    "    def __init__(self, n_vocab, seq_size, emb_size, lstm_size):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, lstm_size, batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "    \n",
    "    \n",
    "    ## forward path\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec6fa5-6f21-4ac9-9e62-8fc73a439238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65f31-30d3-466f-a39d-2274c7befe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38e2f758-a632-4d2c-8281-afac3fdce6e1",
   "metadata": {},
   "source": [
    "* Criterion and optimizer settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dee2e-dea5-4222-98f8-c8d5d94b1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cri_opti(net, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2239e-5a2e-4b5b-8734-11c556653bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25ce3f-4f10-42ad-8837-8e1235a566e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ea5839-fcba-49da-9d1a-6a5259fa095a",
   "metadata": {},
   "source": [
    "* RNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6a5e5-a50e-467c-a52f-7064be6a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = []\n",
    "def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
    "    \n",
    "    ## RNN instance\n",
    "    model = RNN_model(n_vocab, args.seq_size, args.emb_size, args.lstm_size)\n",
    "    model = model.to(DEVICE)\n",
    "    criterion, optimizer = cri_opti(model, lr=args.lr)\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        batches = get_batches(words, vocab_to_int, args.bs, args.seq_size)\n",
    "        state_h, state_c = model.zero_state(args.bs)\n",
    "\n",
    "        ## Transfer data to GPU\n",
    "        state_h = state_h.to(DEVICE)\n",
    "        state_c = state_c.to(DEVICE)\n",
    "        \n",
    "        for x, y in batches:\n",
    "            iteration += 1\n",
    "\n",
    "            ## Tell it we are in training mode\n",
    "            model.train()\n",
    "\n",
    "            ## Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## Transfer data to GPU\n",
    "            x = torch.tensor(x).to(DEVICE).long()\n",
    "            y = torch.tensor(y).to(DEVICE).long()\n",
    "\n",
    "            logits, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "            ppl.append(loss_value)\n",
    "\n",
    "            ## Perform back-propagation\n",
    "            loss.backward(retain_graph=True)\n",
    "            _ = torch.nn.utils.clip_grad_norm_(model.parameters(), args.g_norm)\n",
    "            \n",
    "            # Update the network's parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % 10 == 0:\n",
    "                print('Epoch: {}/{}'.format(epoch, args.epochs),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
    "\n",
    "            # if iteration % 1000 == 0:\n",
    "                # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
    "                # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c380a7-57c0-42a6-819a-b72d79548581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbb087-062f-4035-a3f7-7a2ac6a39c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1293047e-a242-457e-8a02-6c9faa315aa3",
   "metadata": {},
   "source": [
    "* Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e12a87-9fb6-466b-8f25-685806a557bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de281445-a2a5-4c7c-a0dd-b62aaa4f3faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c430db7-2b28-4cf5-91df-161d6c766066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f5a47-01dc-475a-8bc3-1acddc6c7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(DEVICE, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(DEVICE)\n",
    "    state_c = state_c.to(DEVICE)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a16c7-5641-4ca6-a428-d3db9a2dd136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc106899-9bce-45f9-90fc-38385b69cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['We', 'are'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc9731-5a4f-43f5-8a5e-30c288791bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['what'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b18102-232e-4517-8000-129de9c944a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['You'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ad29b-44ba-47ff-8cd6-a978a0069255",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['I', 'tell', 'you', 'friends'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe57ed-30f9-453c-921d-84c2fd8dd19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe994beb-c794-46d5-9697-38c1b345b9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf56c2-82c9-41a2-86c1-8197a06d5412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ff89f-8271-45bd-a0c2-23239034a6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee5b1e-f12a-40ff-860f-dd944f951807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdae16ea-eccd-4b4f-839f-74f2c7ef9f24",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346659e-5516-4b2f-af31-887d433ee7a5",
   "metadata": {},
   "source": [
    "## Question - c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa515db-25e9-48d6-a927-0b621d0f60c1",
   "metadata": {},
   "source": [
    "(c) Perplexity is defined as the exponentiated average negative log-likelihood of a sequence. Let X = (x0, . . . , xt), then the perplexity of X is ...\n",
    "> Train your network RNNs and provide a PPL curve over the course of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8ffc8-65e2-4318-b5a8-30c8ac806349",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89923f-8e9f-41d2-ac40-0f6e1cc1b2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfce62-c3f7-49a3-9e1d-e470f036ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08bdcc-76dd-49f3-b977-a51625409c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04d65-f1e0-44ff-b660-67de0e799246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f437a8-2e19-485d-96f5-fe37538ae19c",
   "metadata": {},
   "source": [
    "### Perplexity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350f56e-272d-4bdd-aeb9-d26700dee8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078cc5b-e8f6-4657-a352-d4d912b9e958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8983da-500f-4c17-a952-f0a49c3048de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783a513-b4ce-4eb7-a970-7da1b5fa02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1114a422-86c6-49f4-9279-dcd917906213",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca83d1-aae6-430d-b331-35724d28bba5",
   "metadata": {},
   "source": [
    "## Question - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334afccd-4bda-450f-983b-5964dea8641b",
   "metadata": {},
   "source": [
    "(d) Among GRU, LSTM, or Transformer, pick one of your favorite architecture, and design the architecture whose the number of parameters is similar to vanila RNN you implemented above. Then train and provide a PPL curve over the course of the training (in the same plots in (c)). You are free to select any hyperparameters if needed (no need to use the hyperparameters above). Report the number of model parameters. (You can use GRU, LSTM, or Transformer libararies, if you want, but I recommend you to implement by yourself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc54bfc-d377-48e8-89c7-92bb7a1559b9",
   "metadata": {},
   "source": [
    "* Setting new parameters in args_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb07f434-f5c9-4d8f-ba9a-ecdf252394c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_:\n",
    "    emb_size=64\n",
    "    seq_size=1000\n",
    "    lstm_size=64\n",
    "    g_norm=5\n",
    "    bs=64\n",
    "    num_step=20\n",
    "    epochs=30\n",
    "    lr=0.001\n",
    "    momentum = 0.9\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args_ = Args_()    \n",
    "\n",
    "np.random.seed(args_.seed)\n",
    "random.seed(args_.seed)\n",
    "torch.manual_seed(args_.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42f6b4-fbda-46c0-8f8c-6e0e6e3ef7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shakespeare\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b98ec-4b10-4f81-a535-1e21dfa174cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "30197337-4c4f-46cc-9d47-5434dc250899",
   "metadata": {
    "tags": []
   },
   "source": [
    "* vocab setting as done in question a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860cc9af-cd05-41d9-8d9e-e65b49f2b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary of the Shakespeare data: {}'.format(vocab))\n",
    "print('The number of unique characters: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8007c-0656-4498-a27c-fc79802897e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7289a9e2-22e5-45bb-8342-0f6ebc3ea5c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f84b220-005b-4e16-a99f-44e25fc83b2c",
   "metadata": {},
   "source": [
    "### generator model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7224872-1f62-4d15-9ce5-1987c1e5a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = args_.seq_size\n",
    "batch = args_.bs\n",
    "\n",
    "input_seqs = []\n",
    "target_seqs = []\n",
    "\n",
    "num_seqs = len(text_as_int) // (seq_len+1)\n",
    "\n",
    "for i in range(num_seqs):\n",
    "    seq = text_as_int[i:i+seq_len+1]\n",
    "    input_seqs.append(np.array(seq[:-1]))\n",
    "    target_seqs.append(np.array(seq[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e7df9-5973-49f3-aa53-af81a46604f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = np.array(input_seqs)\n",
    "target_seqs = np.array(target_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bd960c-4f9e-43e7-af15-4aef49a326f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = input_seqs[:(len(input_seqs)//batch)*batch]\n",
    "target_seqs = target_seqs[:(len(input_seqs)//batch)*batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a725bf1-f97b-422f-9e2b-5f2d5c130d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ce94e-bb87-47cf-9506-02bf05591c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54cfd2f2-b2d6-41ab-8a49-f30dd0b1fb60",
   "metadata": {},
   "source": [
    "### GRU based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86646615-ed1b-4c98-ada4-43b0b33fdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, 256, batch_input_shape=(batch_size, None)),\n",
    "        tf.keras.layers.GRU(256, return_sequences=True, stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size),\n",
    "    ])\n",
    "    model.build()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e2b8e-1fc5-487e-b9a9-df03fec20285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bccb840-11fc-4151-95ac-3a020b786dc7",
   "metadata": {},
   "source": [
    "* Checking model structure and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34825e8-892f-40a8-885a-aea85c64cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(batch)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d3621-3cca-48c8-9a07-4cd152e214c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = args_.epochs\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "history = model.fit(input_seqs, target_seqs, epochs=args_.epochs, batch_size=args_.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dbfc1-639c-47de-8080-af59e5d54f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73cff5a-739d-402d-bf9b-c68201f43a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29d369-63bb-478e-b980-bd80cc07264a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905c999-996e-4289-8cdf-6e9671ab7bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709fd804-2f01-44e4-b428-3aa55a2cb644",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb46ed8-0efb-41fc-a0a8-5e9811676d57",
   "metadata": {},
   "source": [
    "## Question - e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a38a22-f661-446f-bcdc-adc6c7db06a3",
   "metadata": {},
   "source": [
    "(e) Pick the best performing (lowest PPL score) model, and generate the text autoregressively given the following prompts.\n",
    "> (1) ‘We are’ \\\n",
    "(2) ‘what’ \\\n",
    "(3) ‘You’ \\\n",
    "(4) ‘I tell you, friends’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c69d18-a42c-4fb0-a4e5-699314d02b1f",
   "metadata": {},
   "source": [
    "### Text generator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08de67-3c2a-4df7-8e4f-acd4927558c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = build_model(1)\n",
    "\n",
    "for i in range(len(generator_model.layers)):\n",
    "    for j in range(len(generator_model.layers[i].weights)):\n",
    "        generator_model.layers[i].weights[j].assign(model.layers[i].weights[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8e779-f182-47e2-8c32-218d35bb8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed, out_len):\n",
    "\n",
    "    text_generated = []\n",
    "    model.reset_states()    \n",
    "    inp = np.array([char2idx[s] for s in seed])\n",
    "\n",
    "    for i in range(out_len):\n",
    "\n",
    "        pred = model(inp[None, ...])[0]\n",
    "        temperature = 1.0\n",
    "        pred = pred / temperature\n",
    "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()        \n",
    "        text_generated.append(idx2char[pred_c])        \n",
    "        inp = np.array([pred_c])\n",
    "\n",
    "    return (seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19672dc7-b944-4ecf-86cc-a28191a78d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d25eb8-2681-43a4-862a-ca298c5bb455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f4f151b-14ae-4606-b04d-1042b94ed46f",
   "metadata": {},
   "source": [
    "### Text  generation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e53156-5b49-4618-afee-83f729f04faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(generator_model, seed=u\"We are\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c1267-508e-494c-898d-746cc9707c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(generator_model, seed=u\"what\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ba83a-3f7d-4935-a177-aee68a4d2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(generator_model, seed=u\"You\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c3dd-6964-4b6d-9a7d-8d2eec741c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(generator_model, seed=u\"I tell you, friends\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30aa29-5ae1-40f6-9a8f-d4643134656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be72bd-3b9b-4989-b13f-93f93a8a3027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
