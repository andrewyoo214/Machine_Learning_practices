{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85d30a4-0085-45fd-93a4-e493a7a52920",
   "metadata": {},
   "source": [
    "# AIM5004_HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437b24-0103-441b-bb0d-17f6ba7f0e7c",
   "metadata": {},
   "source": [
    "* (Total 10 pts) Training a character-level language model with recurrent neural networks and Transformers architecture. You are going to write codes in python w/ whichever deep learning libraries you prefer to use, e.g. pytorch, tensorflow, keras, jax, mxnet, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb124e35-d4dd-4e46-a818-bb98e5fbd71b",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2f4bf-7cd4-4eaa-aef1-9091958d8888",
   "metadata": {},
   "source": [
    "## Question - a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f45a5-3328-4dd3-9e88-61c0b3ccef24",
   "metadata": {},
   "source": [
    "(a) Download shakespeare dataset from https://storage.googleapis.com/download.\n",
    "tensorflow.org/data/shakespeare.txt. Report the number of unique characters\n",
    "and this number will be the number of your vocabulary (note that ’a’ and ’A’ are\n",
    "different characters). Also, show 3 random chunks (200 characters per each) of the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61091cd-63e9-438d-9f25-2bdc301d0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import codecs\n",
    "import string\n",
    "import nltk\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6377fcea-798b-47a6-a9a2-9ded243ebd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aff1044-3fb8-4f9a-83c4-2e675d0fd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.7.1  Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "##Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e67ee8-a653-408b-9f3e-25826c36ebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f08785-283f-42eb-bbd8-6484d4c78cf6",
   "metadata": {},
   "source": [
    "### Shakespeare text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d9b5d73-aeef-4679-b624-ed73659df5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "data_fpath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "shakespeare = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
    "data = shakespeare\n",
    "data_len = len(data)\n",
    "print(data_len)\n",
    "print(data[:100]) ## including space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e3b84-5478-4ff1-97ab-69eb96f129f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3524e97-443c-48a1-be8c-1859e991818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8fc70-de85-46f0-8fb5-160ea54c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90123771-d369-4e43-b6a5-442c942a6c78",
   "metadata": {},
   "source": [
    "### Vocabulary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1fa81fa-38a9-475f-adc7-28e85a60be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of the Shakespeare data: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "The number of unique characters: 65\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary of the Shakespeare data: {}'.format(vocab))\n",
    "print('The number of unique characters: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631e22a0-ab16-4aec-839f-bd8a472c95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of the original text:  First Citizen\n",
      "Example of the encoded text:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in data])\n",
    "\n",
    "print('Example of the original text: ', data[:13])\n",
    "print('Example of the encoded text:  {}'.format(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd67858-ec10-44f9-ade8-3c162884d6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?',\n",
       "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6ac1d-7e1e-49cb-a3cf-2b58422c1a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86af9869-f5a2-4116-9afc-2ec2741474cb",
   "metadata": {},
   "source": [
    "### Random dataset chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf2eb1bb-8de1-4c4e-878f-df9391ad95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 200\n",
    "\n",
    "def random_select():\n",
    "    stt = random.randint(0, data_len - chunk)\n",
    "    end = stt + chunk + 1\n",
    "    return data[stt : end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1743825c-3bcb-42ea-8cc7-2ee39ac8d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First random Chunk: \n",
      "  stoop and take't\n",
      "Because we see it; but what we do not see\n",
      "We tread upon, and never think of it.\n",
      "You may not so extenuate his offence\n",
      "For I have had such faults; but rather tell me,\n",
      "When I, that censu\n"
     ]
    }
   ],
   "source": [
    "print(\"First random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0904ca-bf27-4354-afed-3a8808e853c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second random Chunk: \n",
      " nment?\n",
      "\n",
      "HASTINGS:\n",
      "With patience, noble lord, as prisoners must:\n",
      "But I shall live, my lord, to give them thanks\n",
      "That were the cause of my imprisonment.\n",
      "\n",
      "GLOUCESTER:\n",
      "No doubt, no doubt; and so shall Clar\n"
     ]
    }
   ],
   "source": [
    "print(\"Second random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68cc92e5-3d38-4b1a-8bb3-8dcd6f6dc44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third random Chunk: \n",
      " ou judge my wit would\n",
      "fly?\n",
      "\n",
      "Third Citizen:\n",
      "Nay, your wit will not so soon out as another man's\n",
      "will;'tis strongly wedged up in a block-head, but\n",
      "if it were at liberty, 'twould, sure, southward.\n",
      "\n",
      "Second\n"
     ]
    }
   ],
   "source": [
    "print(\"Third random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33af7a-060a-4717-a785-abd553174339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc687f4-7b8c-4d40-8603-8e635b1fa098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207b3f19-2295-480b-898d-9898857d5a08",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52088903-49b7-417c-8c7b-8f6e7947088d",
   "metadata": {},
   "source": [
    "## Question - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14389ca6-e02b-46ee-bcc6-75195d0fe0bf",
   "metadata": {},
   "source": [
    "(b) Design a vanila RNN architecture and write the training codes w/ following hyperparameters. Report the number of model parameters.\n",
    "(You can use RNN libararies, if you want, but I recommend you to implement by yourself.)\n",
    "> (1) input embedding size: 64 \\\n",
    "(2) hidden size: 128 \\\n",
    "(3) the number of time steps (sequence length, or chunk length): 200 \\\n",
    "(4) the number of layers: 3 \\\n",
    "(5) activation function for hidden units: tanh \\\n",
    "(6) loss function: cross entropy loss \\\n",
    "(7) optimization algorithm: ADAM \\\n",
    "(8) batch size: 64 \\\n",
    "(9) training epochs: 30 \\\n",
    "(10) for other hyperparemeters, you are free to choose whatever you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "606485fa-b100-42e1-b60c-7f7bb3623739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c90e9a0b30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args:\n",
    "    emb_size=64\n",
    "    seq_size=200   ## chunk length\n",
    "    lstm_size=64\n",
    "    g_norm=5\n",
    "    bs=64\n",
    "    num_step=20\n",
    "    epochs=30\n",
    "    lr=0.001\n",
    "    momentum = 0.9\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb614450-ef0c-42e8-a45e-8a14aac7860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b10ff-9a7c-4ed8-b0a2-d7dbfd92ea89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37598ce-f48d-4111-af11-6fa666f402f8",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edc48bb8-80ec-424d-b2cc-dc6c230e6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "## splitting document into words\n",
    "def doc2words(doc):\n",
    "    lines = doc.split('\\n')\n",
    "    lines = [line.strip(r'\\\"') for line in lines]\n",
    "    words = ' '.join(lines).split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2c5ef75-1427-4a66-8fb8-d5d19fc9beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing punctuations attached to words\n",
    "def removepunct(words):\n",
    "    punct = set(string.punctuation)\n",
    "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afba40e2-64fa-4e1f-9851-f9d8c9ee3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get vocabulary from word list\n",
    "def getvocab(words):\n",
    "    wordfreq = Counter(words)\n",
    "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
    "    return sorted_wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f21b9a3d-57a6-4660-95c7-cce56b38c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get dictionary of int to words and word to int\n",
    "def vocab_map(vocab):\n",
    "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
    "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62f125b5-79ec-4139-b13a-00f9a456b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = removepunct(doc2words(data))\n",
    "vocab = getvocab(words)\n",
    "int_to_vocab, vocab_to_int = vocab_map(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39687d5a-3d4f-4612-b1db-5056271f0bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample words:  ['First', 'Citizen', 'Before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak']\n",
      "sample vocab:  ['relieved', 'humanely', 'afflicts', 'inventory', 'particularise', 'rakes', 'commonalty', 'maliciously', 'softconscienced', 'altitude']\n"
     ]
    }
   ],
   "source": [
    "print(\"sample words: \", words[:10])\n",
    "print(\"sample vocab: \", vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf189b-6384-42ac-b905-9f0938b33ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780b8d2-7115-4a10-902b-d35a8c49e33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d76a403f-5a42-4e12-8061-a273b7b006fd",
   "metadata": {},
   "source": [
    "* Preparing batch set for the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "364b1d8b-0a1c-4f9e-8617-6bfa350988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
    "    # generate a Xs and Ys of shape (batchsize * num_batches) * seq_size\n",
    "    word_ints = [vocab_to_int[word] for word in words]\n",
    "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
    "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
    "    Ys = np.zeros_like(Xs)\n",
    "    Ys[:-1] = Xs[1:]\n",
    "    Ys[-1] = Xs[0]\n",
    "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
    "    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
    "    \n",
    "    # iterate over rows of Xs and Ys to generate batches\n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31ea0c-b744-4721-9808-f0a9f216e0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bca8a4-3084-4034-8dc1-3f6759c0946f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57098ff2-ff67-4d0b-b6df-6b1429223377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5e343e-dcb8-4bc5-8621-06114ccabc80",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8a8970b-0d6a-4a07-bee1-3b2cd1cfa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    ## initialize RNN module\n",
    "    def __init__(self, n_vocab, seq_size, emb_size, lstm_size):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, lstm_size, batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "    \n",
    "    \n",
    "    ## forward path\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8dc98-d7e4-470f-a4f3-a6043879fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    ## initialize the model\n",
    "    def __init__(self):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.seq_size = args.seq_size\n",
    "        self.lstm_size = args.lstm_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, args.emb_size)\n",
    "        self.lstm = nn.LSTM(args.emb_size, args.lstm_size, batch_first=True)\n",
    "        self.dense = nn.Linear(args.lstm_size, n_vocab)\n",
    "    \n",
    "    ## forward \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, args.bs, self.lstm_size),torch.zeros(1, args.bs, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec6fa5-6f21-4ac9-9e62-8fc73a439238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65f31-30d3-466f-a39d-2274c7befe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38e2f758-a632-4d2c-8281-afac3fdce6e1",
   "metadata": {},
   "source": [
    "* Criterion and optimizer settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "487dee2e-dea5-4222-98f8-c8d5d94b1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cri_opti(net, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2239e-5a2e-4b5b-8734-11c556653bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25ce3f-4f10-42ad-8837-8e1235a566e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ea5839-fcba-49da-9d1a-6a5259fa095a",
   "metadata": {},
   "source": [
    "* RNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31c6a5e5-a50e-467c-a52f-7064be6a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = []\n",
    "def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
    "    \n",
    "    ## RNN instance\n",
    "    model = RNN_model(n_vocab, args.seq_size, args.emb_size, args.lstm_size)\n",
    "    model = model.to(DEVICE)\n",
    "    criterion, optimizer = cri_opti(model, lr=args.lr)\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        batches = get_batches(words, vocab_to_int, args.bs, args.seq_size)\n",
    "        state_h, state_c = model.zero_state(args.bs)\n",
    "\n",
    "        ## Transfer data to GPU\n",
    "        state_h = state_h.to(DEVICE)\n",
    "        state_c = state_c.to(DEVICE)\n",
    "        \n",
    "        for x, y in batches:\n",
    "            iteration += 1\n",
    "\n",
    "            ## Tell it we are in training mode\n",
    "            model.train()\n",
    "\n",
    "            ## Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## Transfer data to GPU\n",
    "            x = torch.tensor(x).to(DEVICE).long()\n",
    "            y = torch.tensor(y).to(DEVICE).long()\n",
    "\n",
    "            logits, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "            ppl.append(loss_value)\n",
    "\n",
    "            ## Perform back-propagation\n",
    "            loss.backward(retain_graph=True)\n",
    "            _ = torch.nn.utils.clip_grad_norm_(model.parameters(), args.g_norm)\n",
    "            \n",
    "            # Update the network's parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % 10 == 0:\n",
    "                print('Epoch: {}/{}'.format(epoch, args.epochs),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
    "\n",
    "            # if iteration % 1000 == 0:\n",
    "                # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
    "                # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c380a7-57c0-42a6-819a-b72d79548581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbb087-062f-4035-a3f7-7a2ac6a39c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1293047e-a242-457e-8a02-6c9faa315aa3",
   "metadata": {},
   "source": [
    "* Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "54e12a87-9fb6-466b-8f25-685806a557bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/30 Iteration: 10 Loss: 9.552824020385742\n",
      "Epoch: 1/30 Iteration: 20 Loss: 9.418272972106934\n",
      "Epoch: 1/30 Iteration: 30 Loss: 8.828167915344238\n",
      "Epoch: 2/30 Iteration: 40 Loss: 7.833779335021973\n",
      "Epoch: 3/30 Iteration: 50 Loss: 7.433371543884277\n",
      "Epoch: 3/30 Iteration: 60 Loss: 7.126779079437256\n",
      "Epoch: 4/30 Iteration: 70 Loss: 7.080755233764648\n",
      "Epoch: 5/30 Iteration: 80 Loss: 7.20672607421875\n",
      "Epoch: 5/30 Iteration: 90 Loss: 7.034430027008057\n",
      "Epoch: 6/30 Iteration: 100 Loss: 7.044061660766602\n",
      "Epoch: 7/30 Iteration: 110 Loss: 7.178586006164551\n",
      "Epoch: 7/30 Iteration: 120 Loss: 7.019558906555176\n",
      "Epoch: 8/30 Iteration: 130 Loss: 7.03132438659668\n",
      "Epoch: 9/30 Iteration: 140 Loss: 7.162107944488525\n",
      "Epoch: 9/30 Iteration: 150 Loss: 7.000847816467285\n",
      "Epoch: 10/30 Iteration: 160 Loss: 7.017824649810791\n",
      "Epoch: 11/30 Iteration: 170 Loss: 7.144162654876709\n",
      "Epoch: 11/30 Iteration: 180 Loss: 6.979130268096924\n",
      "Epoch: 12/30 Iteration: 190 Loss: 6.999989032745361\n",
      "Epoch: 13/30 Iteration: 200 Loss: 7.121901035308838\n",
      "Epoch: 13/30 Iteration: 210 Loss: 6.95376443862915\n",
      "Epoch: 14/30 Iteration: 220 Loss: 6.9782586097717285\n",
      "Epoch: 15/30 Iteration: 230 Loss: 7.095463275909424\n",
      "Epoch: 15/30 Iteration: 240 Loss: 6.925037860870361\n",
      "Epoch: 16/30 Iteration: 250 Loss: 6.952576160430908\n",
      "Epoch: 17/30 Iteration: 260 Loss: 7.064745903015137\n",
      "Epoch: 17/30 Iteration: 270 Loss: 6.893364429473877\n",
      "Epoch: 18/30 Iteration: 280 Loss: 6.922740936279297\n",
      "Epoch: 19/30 Iteration: 290 Loss: 7.030142307281494\n",
      "Epoch: 19/30 Iteration: 300 Loss: 6.859227180480957\n",
      "Epoch: 20/30 Iteration: 310 Loss: 6.889608860015869\n",
      "Epoch: 21/30 Iteration: 320 Loss: 6.992843151092529\n",
      "Epoch: 21/30 Iteration: 330 Loss: 6.823324203491211\n",
      "Epoch: 22/30 Iteration: 340 Loss: 6.853937149047852\n",
      "Epoch: 23/30 Iteration: 350 Loss: 6.953625679016113\n",
      "Epoch: 23/30 Iteration: 360 Loss: 6.786139488220215\n",
      "Epoch: 24/30 Iteration: 370 Loss: 6.816220760345459\n",
      "Epoch: 25/30 Iteration: 380 Loss: 6.912930488586426\n",
      "Epoch: 25/30 Iteration: 390 Loss: 6.748336315155029\n",
      "Epoch: 26/30 Iteration: 400 Loss: 6.777331352233887\n",
      "Epoch: 27/30 Iteration: 410 Loss: 6.871411323547363\n",
      "Epoch: 27/30 Iteration: 420 Loss: 6.7104902267456055\n",
      "Epoch: 28/30 Iteration: 430 Loss: 6.737573146820068\n",
      "Epoch: 29/30 Iteration: 440 Loss: 6.829232215881348\n",
      "Epoch: 29/30 Iteration: 450 Loss: 6.672536849975586\n"
     ]
    }
   ],
   "source": [
    "rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de281445-a2a5-4c7c-a0dd-b62aaa4f3faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c430db7-2b28-4cf5-91df-161d6c766066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f5a47-01dc-475a-8bc3-1acddc6c7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(DEVICE, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(DEVICE)\n",
    "    state_c = state_c.to(DEVICE)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a16c7-5641-4ca6-a428-d3db9a2dd136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc106899-9bce-45f9-90fc-38385b69cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['We', 'are'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc9731-5a4f-43f5-8a5e-30c288791bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['what'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b18102-232e-4517-8000-129de9c944a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['You'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ad29b-44ba-47ff-8cd6-a978a0069255",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['I', 'tell', 'you', 'friends'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe57ed-30f9-453c-921d-84c2fd8dd19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe994beb-c794-46d5-9697-38c1b345b9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf56c2-82c9-41a2-86c1-8197a06d5412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ff89f-8271-45bd-a0c2-23239034a6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee5b1e-f12a-40ff-860f-dd944f951807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdae16ea-eccd-4b4f-839f-74f2c7ef9f24",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346659e-5516-4b2f-af31-887d433ee7a5",
   "metadata": {},
   "source": [
    "## Question - c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa515db-25e9-48d6-a927-0b621d0f60c1",
   "metadata": {},
   "source": [
    "(c) Perplexity is defined as the exponentiated average negative log-likelihood of a sequence. Let X = (x0, . . . , xt), then the perplexity of X is ...\n",
    "> Train your network RNNs and provide a PPL curve over the course of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf8ffc8-65e2-4318-b5a8-30c8ac806349",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89923f-8e9f-41d2-ac40-0f6e1cc1b2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfce62-c3f7-49a3-9e1d-e470f036ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08bdcc-76dd-49f3-b977-a51625409c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04d65-f1e0-44ff-b660-67de0e799246",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f437a8-2e19-485d-96f5-fe37538ae19c",
   "metadata": {},
   "source": [
    "### Perplexity curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5350f56e-272d-4bdd-aeb9-d26700dee8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078cc5b-e8f6-4657-a352-d4d912b9e958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8983da-500f-4c17-a952-f0a49c3048de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783a513-b4ce-4eb7-a970-7da1b5fa02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1114a422-86c6-49f4-9279-dcd917906213",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca83d1-aae6-430d-b331-35724d28bba5",
   "metadata": {},
   "source": [
    "## Question - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334afccd-4bda-450f-983b-5964dea8641b",
   "metadata": {},
   "source": [
    "(d) Among GRU, LSTM, or Transformer, pick one of your favorite architecture, and design the architecture whose the number of parameters is similar to vanila RNN you implemented above. Then train and provide a PPL curve over the course of the training (in the same plots in (c)). You are free to select any hyperparameters if needed (no need to use the hyperparameters above). Report the number of model parameters. (You can use GRU, LSTM, or Transformer libararies, if you want, but I recommend you to implement by yourself.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc54bfc-d377-48e8-89c7-92bb7a1559b9",
   "metadata": {},
   "source": [
    "* Setting new parameters in args_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cb07f434-f5c9-4d8f-ba9a-ecdf252394c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c90e9a0b30>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args_:\n",
    "    emb_size=64\n",
    "    seq_size=1000\n",
    "    lstm_size=64\n",
    "    g_norm=5\n",
    "    bs=64\n",
    "    num_step=20\n",
    "    epochs=30\n",
    "    lr=0.001\n",
    "    momentum = 0.9\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args_ = Args_()    \n",
    "\n",
    "np.random.seed(args_.seed)\n",
    "random.seed(args_.seed)\n",
    "torch.manual_seed(args_.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eb42f6b4-fbda-46c0-8f8c-6e0e6e3ef7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = shakespeare\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "860cc9af-cd05-41d9-8d9e-e65b49f2b316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of the Shakespeare data: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "The number of unique characters: 65\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary of the Shakespeare data: {}'.format(vocab))\n",
    "print('The number of unique characters: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8007c-0656-4498-a27c-fc79802897e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7289a9e2-22e5-45bb-8342-0f6ebc3ea5c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f7224872-1f62-4d15-9ce5-1987c1e5a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = args_.seq_size\n",
    "BATCH_SIZE = args_.bs\n",
    "\n",
    "input_seqs = []\n",
    "target_seqs = []\n",
    "\n",
    "num_seqs = len(text_as_int) // (SEQ_LEN+1)\n",
    "for i in range(num_seqs):\n",
    "    seq = text_as_int[i:i+SEQ_LEN+1]\n",
    "    input_seqs.append(np.array(seq[:-1]))\n",
    "    target_seqs.append(np.array(seq[1:]))\n",
    "\n",
    "input_seqs = np.array(input_seqs)\n",
    "target_seqs = np.array(target_seqs)\n",
    "\n",
    "input_seqs = input_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]\n",
    "target_seqs = target_seqs[:(len(input_seqs)//BATCH_SIZE)*BATCH_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e7df9-5973-49f3-aa53-af81a46604f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "86646615-ed1b-4c98-ada4-43b0b33fdf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, 256, batch_input_shape=(batch_size, None)),\n",
    "        tf.keras.layers.GRU(256, return_sequences=True, stateful=True),\n",
    "        tf.keras.layers.Dense(vocab_size),\n",
    "    ])\n",
    "    model.build()\n",
    "    return model\n",
    "\n",
    "model = build_model(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d3621-3cca-48c8-9a07-4cd152e214c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "17/17 [==============================] - 52s 3s/step - loss: 3.6910\n",
      "Epoch 2/30\n",
      "17/17 [==============================] - 59s 3s/step - loss: 3.0404\n",
      "Epoch 3/30\n",
      "17/17 [==============================] - 64s 4s/step - loss: 2.7684\n",
      "Epoch 4/30\n",
      "17/17 [==============================] - 67s 4s/step - loss: 2.4632\n",
      "Epoch 5/30\n",
      "17/17 [==============================] - 68s 4s/step - loss: 2.2513\n",
      "Epoch 6/30\n",
      "17/17 [==============================] - 70s 4s/step - loss: 2.0924\n",
      "Epoch 7/30\n",
      "17/17 [==============================] - 71s 4s/step - loss: 1.9458\n",
      "Epoch 8/30\n",
      "17/17 [==============================] - 74s 4s/step - loss: 1.7911\n",
      "Epoch 9/30\n",
      "17/17 [==============================] - 74s 4s/step - loss: 1.6156\n",
      "Epoch 10/30\n",
      "17/17 [==============================] - 75s 4s/step - loss: 1.4133\n",
      "Epoch 11/30\n",
      "17/17 [==============================] - 77s 5s/step - loss: 1.1851\n",
      "Epoch 12/30\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.9373\n",
      "Epoch 13/30\n",
      "17/17 [==============================] - 78s 5s/step - loss: 0.6901\n",
      "Epoch 14/30\n",
      "17/17 [==============================] - 79s 5s/step - loss: 0.4786\n",
      "Epoch 15/30\n",
      "17/17 [==============================] - 80s 5s/step - loss: 0.3243\n",
      "Epoch 16/30\n",
      "17/17 [==============================] - 81s 5s/step - loss: 0.2221\n",
      "Epoch 17/30\n",
      "17/17 [==============================] - 82s 5s/step - loss: 0.1590\n",
      "Epoch 18/30\n",
      "17/17 [==============================] - 84s 5s/step - loss: 0.1201\n",
      "Epoch 19/30\n",
      " 4/17 [======>.......................] - ETA: 49s - loss: 0.1002"
     ]
    }
   ],
   "source": [
    "EPOCHS = args_.epochs\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "history = model.fit(input_seqs, \n",
    "    target_seqs,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972dbfc1-639c-47de-8080-af59e5d54f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08de67-3c2a-4df7-8e4f-acd4927558c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inf = build_model(1)\n",
    "\n",
    "for i in range(len(model_inf.layers)):\n",
    "    for j in range(len(model_inf.layers[i].weights)):\n",
    "        model_inf.layers[i].weights[j].assign(model.layers[i].weights[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee8e779-f182-47e2-8c32-218d35bb8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, seed, out_len):\n",
    "\n",
    "    text_generated = []\n",
    "\n",
    "    model.reset_states()\n",
    "    \n",
    "    inp = np.array([char2idx[s] for s in seed])\n",
    "\n",
    "    for i in range(out_len):\n",
    "\n",
    "        pred = model(inp[None, ...])[0]\n",
    "\n",
    "        temperature = 1.0\n",
    "        pred = pred / temperature\n",
    "        pred_c = tf.random.categorical(pred, num_samples=1)[-1][0].numpy()\n",
    "        \n",
    "        text_generated.append(idx2char[pred_c])\n",
    "        \n",
    "        inp = np.array([pred_c])\n",
    "\n",
    "    return (seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2b9f8-bb06-4611-b617-67db3cceb315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7caee98-5bb9-40f7-8c3e-93a0b993c6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3840fe8a-05fb-4061-b6bf-f3f55f37b0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905c999-996e-4289-8cdf-6e9671ab7bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709fd804-2f01-44e4-b428-3aa55a2cb644",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb46ed8-0efb-41fc-a0a8-5e9811676d57",
   "metadata": {},
   "source": [
    "## Question - e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a38a22-f661-446f-bcdc-adc6c7db06a3",
   "metadata": {},
   "source": [
    "(e) Pick the best performing (lowest PPL score) model, and generate the text autoregressively given the following prompts.\n",
    "> (1) ‘We are’ \\\n",
    "(2) ‘what’ \\\n",
    "(3) ‘You’ \\\n",
    "(4) ‘I tell you, friends’"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f151b-14ae-4606-b04d-1042b94ed46f",
   "metadata": {},
   "source": [
    "### Text  generation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e53156-5b49-4618-afee-83f729f04faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model_inf, seed=u\"We are\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c1267-508e-494c-898d-746cc9707c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model_inf, seed=u\"what\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ba83a-3f7d-4935-a177-aee68a4d2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model_inf, seed=u\"You\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c3dd-6964-4b6d-9a7d-8d2eec741c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(model_inf, seed=u\"I tell you, friends\", out_len=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30aa29-5ae1-40f6-9a8f-d4643134656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be72bd-3b9b-4989-b13f-93f93a8a3027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
