{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85d30a4-0085-45fd-93a4-e493a7a52920",
   "metadata": {},
   "source": [
    "# AIM5004_HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437b24-0103-441b-bb0d-17f6ba7f0e7c",
   "metadata": {},
   "source": [
    "* (Total 10 pts) Training a character-level language model with recurrent neural networks and Transformers architecture. You are going to write codes in python w/ whichever deep learning libraries you prefer to use, e.g. pytorch, tensorflow, keras, jax, mxnet, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb124e35-d4dd-4e46-a818-bb98e5fbd71b",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2f4bf-7cd4-4eaa-aef1-9091958d8888",
   "metadata": {},
   "source": [
    "## Question - a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f45a5-3328-4dd3-9e88-61c0b3ccef24",
   "metadata": {},
   "source": [
    "(a) Download shakespeare dataset from https://storage.googleapis.com/download.\n",
    "tensorflow.org/data/shakespeare.txt. Report the number of unique characters\n",
    "and this number will be the number of your vocabulary (note that ’a’ and ’A’ are\n",
    "different characters). Also, show 3 random chunks (200 characters per each) of the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61091cd-63e9-438d-9f25-2bdc301d0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377fcea-798b-47a6-a9a2-9ded243ebd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff1044-3fb8-4f9a-83c4-2e675d0fd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e67ee8-a653-408b-9f3e-25826c36ebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f08785-283f-42eb-bbd8-6484d4c78cf6",
   "metadata": {},
   "source": [
    "### Shakespeare text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b5d73-aeef-4679-b624-ed73659df5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fpath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "shakespeare = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
    "data = shakespeare\n",
    "data_len = len(data)\n",
    "print(data_len)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e3b84-5478-4ff1-97ab-69eb96f129f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3524e97-443c-48a1-be8c-1859e991818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8fc70-de85-46f0-8fb5-160ea54c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90123771-d369-4e43-b6a5-442c942a6c78",
   "metadata": {},
   "source": [
    "### Vocabulary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa81fa-38a9-475f-adc7-28e85a60be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary of the Shakespeare data: {}'.format(vocab))\n",
    "print('Unique Characters: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e22a0-ab16-4aec-839f-bd8a472c95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in data])\n",
    "\n",
    "print('Example of the original text: ', data[:13])\n",
    "print('Example of the encoded text:  {}'.format(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd67858-ec10-44f9-ade8-3c162884d6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6ac1d-7e1e-49cb-a3cf-2b58422c1a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86af9869-f5a2-4116-9afc-2ec2741474cb",
   "metadata": {},
   "source": [
    "### Random dataset chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2eb1bb-8de1-4c4e-878f-df9391ad95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 200\n",
    "\n",
    "def random_select():\n",
    "    stt = random.randint(0, data_len - chunk)\n",
    "    end = stt + chunk + 1\n",
    "    return data[stt : end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743825c-3bcb-42ea-8cc7-2ee39ac8d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0904ca-bf27-4354-afed-3a8808e853c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Second random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cc92e5-3d38-4b1a-8bb3-8dcd6f6dc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Third random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33af7a-060a-4717-a785-abd553174339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc687f4-7b8c-4d40-8603-8e635b1fa098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207b3f19-2295-480b-898d-9898857d5a08",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52088903-49b7-417c-8c7b-8f6e7947088d",
   "metadata": {},
   "source": [
    "## Question - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14389ca6-e02b-46ee-bcc6-75195d0fe0bf",
   "metadata": {},
   "source": [
    "(b) Design a vanila RNN architecture and write the training codes w/ following hyperparameters. Report the number of model parameters.\n",
    "(You can use RNN libararies, if you want, but I recommend you to implement by yourself.)\n",
    "> (1) input embedding size: 64 \\\n",
    "(2) hidden size: 128 \\\n",
    "(3) the number of time steps (sequence length, or chunk length): 200 \\\n",
    "(4) the number of layers: 3 \\\n",
    "(5) activation function for hidden units: tanh \\\n",
    "(6) loss function: cross entropy loss \\\n",
    "(7) optimization algorithm: ADAM \\\n",
    "(8) batch size: 64 \\\n",
    "(9) training epochs: 30 \\\n",
    "(10) for other hyperparemeters, you are free to choose whatever you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606485fa-b100-42e1-b60c-7f7bb3623739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    emb_size=64\n",
    "    seq_size=200\n",
    "    lstm_size=64\n",
    "    g_norm=5\n",
    "    bs=64\n",
    "    num_step=20\n",
    "    epochs=30\n",
    "    lr=0.001\n",
    "    momentum = 0.9\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed9a60-7d13-4fcd-a1fa-ea8d589327bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb614450-ef0c-42e8-a45e-8a14aac7860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b10ff-9a7c-4ed8-b0a2-d7dbfd92ea89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37598ce-f48d-4111-af11-6fa666f402f8",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973ddfa-a3f9-4bfd-858d-3d0d40feb9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc48bb8-80ec-424d-b2cc-dc6c230e6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2words(doc):\n",
    "    lines = doc.split('\\n')\n",
    "    lines = [line.strip(r'\\\"') for line in lines]\n",
    "    words = ' '.join(lines).split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c5ef75-1427-4a66-8fb8-d5d19fc9beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunct(words):\n",
    "    punct = set(string.punctuation)\n",
    "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afba40e2-64fa-4e1f-9851-f9d8c9ee3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab from word list\n",
    "def getvocab(words):\n",
    "    wordfreq = Counter(words)\n",
    "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
    "    return sorted_wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b9a3d-57a6-4660-95c7-cce56b38c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary of int to words and word to int\n",
    "def vocab_map(vocab):\n",
    "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
    "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f125b5-79ec-4139-b13a-00f9a456b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = removepunct(doc2words(data))\n",
    "vocab = getvocab(words)\n",
    "int_to_vocab, vocab_to_int = vocab_map(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984ca649-df66-425f-9fb0-961f255cd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba33e96-2a47-464d-a76c-0f9eb6aac9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4a7d17-f238-42eb-8374-71e9a447a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(words))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eadc52-d140-4b90-959c-752112c92580",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_to_int = [vocab_to_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117591b-2b5b-4b46-8663-1ac762b664f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(v_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39687d5a-3d4f-4612-b1db-5056271f0bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69045c99-54e1-4e0e-84dc-1039007ef72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70be8c33-5463-4d48-b88f-4f0b3b3ce250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b1d8b-0a1c-4f9e-8617-6bfa350988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
    "    # generate a Xs and Ys of shape (batchsize * num_batches) * seq_size\n",
    "    word_ints = [vocab_to_int[word] for word in words]\n",
    "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
    "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
    "    Ys = np.zeros_like(Xs)\n",
    "    Ys[:-1] = Xs[1:]\n",
    "    Ys[-1] = Xs[0]\n",
    "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
    "    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
    "    \n",
    "    # iterate over rows of Xs and Ys to generate batches\n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31ea0c-b744-4721-9808-f0a9f216e0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bca8a4-3084-4034-8dc1-3f6759c0946f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57098ff2-ff67-4d0b-b6df-6b1429223377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5e343e-dcb8-4bc5-8621-06114ccabc80",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8970b-0d6a-4a07-bee1-3b2cd1cfa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    ## initialize RNN module\n",
    "    def __init__(self, n_vocab, seq_size, emb_size, lstm_size):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "    \n",
    "    \n",
    "    ## forward path\n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8dc98-d7e4-470f-a4f3-a6043879fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    ## initialize the model\n",
    "    def __init__(self):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.seq_size = args.seq_size\n",
    "        self.lstm_size = args.lstm_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_vocab, args.emb_size)\n",
    "        self.lstm = nn.LSTM(args.emb_size, args.lstm_size, batch_first=True)\n",
    "        self.dense = nn.Linear(args.lstm_size, n_vocab)\n",
    "    \n",
    "    ## forward \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, args.bs, self.lstm_size),torch.zeros(1, args.bs, self.lstm_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec6fa5-6f21-4ac9-9e62-8fc73a439238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65f31-30d3-466f-a39d-2274c7befe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38e2f758-a632-4d2c-8281-afac3fdce6e1",
   "metadata": {},
   "source": [
    "* Criterion and optimizer settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487dee2e-dea5-4222-98f8-c8d5d94b1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cri_opti(net, lr):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
    "\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c2239e-5a2e-4b5b-8734-11c556653bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d25ce3f-4f10-42ad-8837-8e1235a566e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23ea5839-fcba-49da-9d1a-6a5259fa095a",
   "metadata": {},
   "source": [
    "* RNN model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6a5e5-a50e-467c-a52f-7064be6a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
    "    \n",
    "    ## RNN instance\n",
    "    model = RNN_model(n_vocab, seq_size, embedding_size, lstm_size)\n",
    "    model = model.to(DEVICE)\n",
    "    criterion, optimizer = cri_opti(model, lr=args.lr)\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        batches = get_batches(words, vocab_to_int, batch_size, seq_size)\n",
    "        state_h, state_c = model.zero_state(batch_size)\n",
    "\n",
    "        ## Transfer data to GPU\n",
    "        state_h = state_h.to(DEVICE)\n",
    "        state_c = state_c.to(DEVICE)\n",
    "        \n",
    "        for x, y in batches:\n",
    "            iteration += 1\n",
    "\n",
    "            ## Tell it we are in training mode\n",
    "            model.train()\n",
    "\n",
    "            ## Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## Transfer data to GPU\n",
    "            x = torch.tensor(x).to(DEVICE).long()\n",
    "            y = torch.tensor(y).to(DEVICE).long()\n",
    "\n",
    "            logits, (state_h, state_c) = model(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            ## Perform back-propagation\n",
    "            loss.backward(retain_graph=True)\n",
    "            _ = torch.nn.utils.clip_grad_norm_(model.parameters(), gradients_norm)\n",
    "            \n",
    "            # Update the network's parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(epoch, args.epochs),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
    "\n",
    "            # if iteration % 1000 == 0:\n",
    "                # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
    "                # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
    "                \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c380a7-57c0-42a6-819a-b72d79548581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458700a-2bc5-479c-99ab-d812a028e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795c8ea-cebd-48c9-8558-ab44f1914a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe45a19-925d-4025-8943-a61021e39173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbb087-062f-4035-a3f7-7a2ac6a39c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1293047e-a242-457e-8a02-6c9faa315aa3",
   "metadata": {},
   "source": [
    "* Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e12a87-9fb6-466b-8f25-685806a557bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de281445-a2a5-4c7c-a0dd-b62aaa4f3faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c430db7-2b28-4cf5-91df-161d6c766066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12f5a47-01dc-475a-8bc3-1acddc6c7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(DEVICE, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(DEVICE)\n",
    "    state_c = state_c.to(DEVICE)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a16c7-5641-4ca6-a428-d3db9a2dd136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc106899-9bce-45f9-90fc-38385b69cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['We', 'are'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc9731-5a4f-43f5-8a5e-30c288791bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['what'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b18102-232e-4517-8000-129de9c944a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['You'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ad29b-44ba-47ff-8cd6-a978a0069255",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(DEVICE, rnn_net, ['I', 'tell', 'you', 'friends'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe57ed-30f9-453c-921d-84c2fd8dd19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe994beb-c794-46d5-9697-38c1b345b9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf56c2-82c9-41a2-86c1-8197a06d5412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ff89f-8271-45bd-a0c2-23239034a6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee5b1e-f12a-40ff-860f-dd944f951807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdae16ea-eccd-4b4f-839f-74f2c7ef9f24",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346659e-5516-4b2f-af31-887d433ee7a5",
   "metadata": {},
   "source": [
    "## Question - c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa515db-25e9-48d6-a927-0b621d0f60c1",
   "metadata": {},
   "source": [
    "(c) Perplexity is defined as the exponentiated average negative log-likelihood of a sequence. Let X = (x0, . . . , xt), then the perplexity of X is ...\n",
    "> Train your network RNNs and provide a PPL curve over the course of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f7e27-0453-4212-98db-3d9a7db9e610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89923f-8e9f-41d2-ac40-0f6e1cc1b2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfce62-c3f7-49a3-9e1d-e470f036ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08bdcc-76dd-49f3-b977-a51625409c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8983da-500f-4c17-a952-f0a49c3048de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783a513-b4ce-4eb7-a970-7da1b5fa02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1114a422-86c6-49f4-9279-dcd917906213",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca83d1-aae6-430d-b331-35724d28bba5",
   "metadata": {},
   "source": [
    "## Question - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334afccd-4bda-450f-983b-5964dea8641b",
   "metadata": {},
   "source": [
    "(d) Among GRU, LSTM, or Transformer, pick one of your favorite architecture, and design the architecture whose the number of parameters is similar to vanila RNN you implemented above. Then train and provide a PPL curve over the course of the training (in the same plots in (c)). You are free to select any hyperparameters if needed (no need to use the hyperparameters above). Report the number of model parameters. (You can use GRU, LSTM, or Transformer libararies, if you want, but I recommend you to implement by yourself.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9bb607-1937-4a69-ba95-f8e0eae0c136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02eeacb-c0a8-4821-a0e1-f986a4d58c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138be7f-c517-4693-a0b8-4089b9e89847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f4260-bf9c-416e-a55f-6fcb43585bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190aa62-bcc8-47cc-9b51-0e9826c6adce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26bc4e-8310-40ee-8517-d8d849608732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c684da-7b79-4653-acfe-f9c16ca06add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0cf34-b361-45dd-98bb-f50fb4712941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905c999-996e-4289-8cdf-6e9671ab7bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709fd804-2f01-44e4-b428-3aa55a2cb644",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb46ed8-0efb-41fc-a0a8-5e9811676d57",
   "metadata": {},
   "source": [
    "## Question - e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a38a22-f661-446f-bcdc-adc6c7db06a3",
   "metadata": {},
   "source": [
    "(e) Pick the best performing (lowest PPL score) model, and generate the text autoregressively given the following prompts.\n",
    "> (1) ‘We are’ \\\n",
    "(2) ‘what’ \\\n",
    "(3) ‘You’ \\\n",
    "(4) ‘I tell you, friends’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c1267-508e-494c-898d-746cc9707c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ba83a-3f7d-4935-a177-aee68a4d2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c3dd-6964-4b6d-9a7d-8d2eec741c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e576e8-628a-4d2a-a0fb-acd213ef4cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30aa29-5ae1-40f6-9a8f-d4643134656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be72bd-3b9b-4989-b13f-93f93a8a3027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
