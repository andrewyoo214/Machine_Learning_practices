{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e85d30a4-0085-45fd-93a4-e493a7a52920",
   "metadata": {},
   "source": [
    "# AIM5004_HW3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437b24-0103-441b-bb0d-17f6ba7f0e7c",
   "metadata": {},
   "source": [
    "* (Total 10 pts) Training a character-level language model with recurrent neural networks and Transformers architecture. You are going to write codes in python w/ whichever deep learning libraries you prefer to use, e.g. pytorch, tensorflow, keras, jax, mxnet, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb124e35-d4dd-4e46-a818-bb98e5fbd71b",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e2f4bf-7cd4-4eaa-aef1-9091958d8888",
   "metadata": {},
   "source": [
    "## Question - a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f45a5-3328-4dd3-9e88-61c0b3ccef24",
   "metadata": {},
   "source": [
    "(a) Download shakespeare dataset from https://storage.googleapis.com/download.\n",
    "tensorflow.org/data/shakespeare.txt. Report the number of unique characters\n",
    "and this number will be the number of your vocabulary (note that ’a’ and ’A’ are\n",
    "different characters). Also, show 3 random chunks (200 characters per each) of the\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d61091cd-63e9-438d-9f25-2bdc301d0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6377fcea-798b-47a6-a9a2-9ded243ebd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6aff1044-3fb8-4f9a-83c4-2e675d0fd488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.7.1  Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "##Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e67ee8-a653-408b-9f3e-25826c36ebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0f08785-283f-42eb-bbd8-6484d4c78cf6",
   "metadata": {},
   "source": [
    "### Shakespeare text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d9b5d73-aeef-4679-b624-ed73659df5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "data_fpath = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "shakespeare = codecs.open(data_fpath, 'r', encoding='utf8').read()\n",
    "data = shakespeare\n",
    "data_len = len(data)\n",
    "print(data_len)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e3b84-5478-4ff1-97ab-69eb96f129f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3524e97-443c-48a1-be8c-1859e991818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8fc70-de85-46f0-8fb5-160ea54c72b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90123771-d369-4e43-b6a5-442c942a6c78",
   "metadata": {},
   "source": [
    "### Vocabulary check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1fa81fa-38a9-475f-adc7-28e85a60be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary of the Shakespeare data: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "Unique Characters: 65\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(data))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "print('Vocabulary of the Shakespeare data: {}'.format(vocab))\n",
    "print('Unique Characters: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "631e22a0-ab16-4aec-839f-bd8a472c95a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of the original text:  First Citizen\n",
      "Example of the encoded text:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in data])\n",
    "\n",
    "print('Example of the original text: ', data[:13])\n",
    "print('Example of the encoded text:  {}'.format(text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd67858-ec10-44f9-ade8-3c162884d6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6ac1d-7e1e-49cb-a3cf-2b58422c1a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86af9869-f5a2-4116-9afc-2ec2741474cb",
   "metadata": {},
   "source": [
    "### Random dataset chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf2eb1bb-8de1-4c4e-878f-df9391ad95bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 200\n",
    "\n",
    "def random_select():\n",
    "    stt = random.randint(0, data_len - chunk)\n",
    "    end = stt + chunk + 1\n",
    "    return data[stt : end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1743825c-3bcb-42ea-8cc7-2ee39ac8d066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First random Chunk: \n",
      " olmasters will I keep within my house,\n",
      "Fit to instruct her youth. If you, Hortensio,\n",
      "Or Signior Gremio, you, know any such,\n",
      "Prefer them hither; for to cunning men\n",
      "I will be very kind, and liberal\n",
      "To mi\n"
     ]
    }
   ],
   "source": [
    "print(\"First random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d0904ca-bf27-4354-afed-3a8808e853c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second random Chunk: \n",
      " ueen,\n",
      "For she is good, hath brought you forth a daughter;\n",
      "Here 'tis; commends it to your blessing.\n",
      "\n",
      "LEONTES:\n",
      "Out!\n",
      "A mankind witch! Hence with her, out o' door:\n",
      "A most intelligencing bawd!\n",
      "\n",
      "PAULINA:\n",
      "Not\n"
     ]
    }
   ],
   "source": [
    "print(\"Second random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68cc92e5-3d38-4b1a-8bb3-8dcd6f6dc44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third random Chunk: \n",
      "  before Corioli, call him,\n",
      "With all the applause and clamour of the host,\n",
      "CAIUS MARCIUS CORIOLANUS! Bear\n",
      "The addition nobly ever!\n",
      "\n",
      "All:\n",
      "Caius Marcius Coriolanus!\n",
      "\n",
      "CORIOLANUS:\n",
      "I will go wash;\n",
      "And when m\n"
     ]
    }
   ],
   "source": [
    "print(\"Third random Chunk: \\n\", random_select())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33af7a-060a-4717-a785-abd553174339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc687f4-7b8c-4d40-8603-8e635b1fa098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207b3f19-2295-480b-898d-9898857d5a08",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52088903-49b7-417c-8c7b-8f6e7947088d",
   "metadata": {},
   "source": [
    "## Question - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14389ca6-e02b-46ee-bcc6-75195d0fe0bf",
   "metadata": {},
   "source": [
    "(b) Design a vanila RNN architecture and write the training codes w/ following hyperparameters. Report the number of model parameters.\n",
    "(You can use RNN libararies, if you want, but I recommend you to implement by yourself.)\n",
    "> (1) input embedding size: 64 \\\n",
    "(2) hidden size: 128 \\\n",
    "(3) the number of time steps (sequence length, or chunk length): 200 \\\n",
    "(4) the number of layers: 3 \\\n",
    "(5) activation function for hidden units: tanh \\\n",
    "(6) loss function: cross entropy loss \\\n",
    "(7) optimization algorithm: ADAM \\\n",
    "(8) batch size: 64 \\\n",
    "(9) training epochs: 30 \\\n",
    "(10) for other hyperparemeters, you are free to choose whatever you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606485fa-b100-42e1-b60c-7f7bb3623739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    emb_size=64\n",
    "    num_step=20\n",
    "    epochs=30\n",
    "    bs=64\n",
    "    lr=0.001\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed9a60-7d13-4fcd-a1fa-ea8d589327bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ddba99dc-6196-435d-98c8-9b337575c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "seq_size = 32\n",
    "embedding_size = 64\n",
    "lstm_size = 64\n",
    "gradients_norm = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb614450-ef0c-42e8-a45e-8a14aac7860a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b10ff-9a7c-4ed8-b0a2-d7dbfd92ea89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a37598ce-f48d-4111-af11-6fa666f402f8",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "edc48bb8-80ec-424d-b2cc-dc6c230e6077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2words(doc):\n",
    "    lines = doc.split('\\n')\n",
    "    lines = [line.strip(r'\\\"') for line in lines]\n",
    "    words = ' '.join(lines).split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e2c5ef75-1427-4a66-8fb8-d5d19fc9beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removepunct(words):\n",
    "    punct = set(string.punctuation)\n",
    "    words = [''.join([char for char in list(word) if char not in punct]) for word in words]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "afba40e2-64fa-4e1f-9851-f9d8c9ee3140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocab from word list\n",
    "def getvocab(words):\n",
    "    wordfreq = Counter(words)\n",
    "    sorted_wordfreq = sorted(wordfreq, key=wordfreq.get)\n",
    "    return sorted_wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f21b9a3d-57a6-4660-95c7-cce56b38c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary of int to words and word to int\n",
    "def vocab_map(vocab):\n",
    "    int_to_vocab = {k:w for k,w in enumerate(vocab)}\n",
    "    vocab_to_int = {w:k for k,w in int_to_vocab.items()}\n",
    "    return int_to_vocab, vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "62f125b5-79ec-4139-b13a-00f9a456b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = removepunct(doc2words(data))\n",
    "vocab = getvocab(words)\n",
    "int_to_vocab, vocab_to_int = vocab_map(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "364b1d8b-0a1c-4f9e-8617-6bfa350988a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(words, vocab_to_int, batch_size, seq_size):\n",
    "    # generate a Xs and Ys of shape (batchsize * num_batches) * seq_size\n",
    "    word_ints = [vocab_to_int[word] for word in words]\n",
    "    num_batches = int(len(word_ints) / (batch_size * seq_size))\n",
    "    Xs = word_ints[:num_batches*batch_size*seq_size]\n",
    "    Ys = np.zeros_like(Xs)\n",
    "    Ys[:-1] = Xs[1:]\n",
    "    Ys[-1] = Xs[0]\n",
    "    Xs = np.reshape(Xs, (num_batches*batch_size, seq_size))\n",
    "    Ys= np.reshape(Ys, (num_batches*batch_size, seq_size))\n",
    "    \n",
    "    # iterate over rows of Xs and Ys to generate batches\n",
    "    for i in range(0, num_batches*batch_size, batch_size):\n",
    "        yield Xs[i:i+batch_size, :], Ys[i:i+batch_size, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db31ea0c-b744-4721-9808-f0a9f216e0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bca8a4-3084-4034-8dc1-3f6759c0946f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57098ff2-ff67-4d0b-b6df-6b1429223377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5e343e-dcb8-4bc5-8621-06114ccabc80",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "37b8dc98-d7e4-470f-a4f3-a6043879fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModule(nn.Module):\n",
    "    # initialize RNN module\n",
    "    def __init__(self, n_vocab, seq_size=32, embedding_size=64, lstm_size=64):\n",
    "        super(RNNModule, self).__init__()\n",
    "        self.seq_size = seq_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(n_vocab, embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=True)\n",
    "        self.dense = nn.Linear(lstm_size, n_vocab)\n",
    "        \n",
    "    def forward(self, x, prev_state):\n",
    "        embed = self.embedding(x)\n",
    "        output, state = self.lstm(embed, prev_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "    \n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),torch.zeros(1, batch_size, self.lstm_size))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec6fa5-6f21-4ac9-9e62-8fc73a439238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0fc3b6ff-780b-46bc-b909-d0c6a647c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_and_train_op(net, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d65f31-30d3-466f-a39d-2274c7befe79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e12f5a47-01dc-475a-8bc3-1acddc6c7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(DEVICE, net, words, n_vocab, vocab_to_int, int_to_vocab, top_k=5):\n",
    "    net.eval()\n",
    "\n",
    "    state_h, state_c = net.zero_state(1)\n",
    "    state_h = state_h.to(DEVICE)\n",
    "    state_c = state_c.to(DEVICE)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[vocab_to_int[w]]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "    \n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "    for _ in range(100):\n",
    "        ix = torch.tensor([[choice]]).to(DEVICE).long()\n",
    "        output, (state_h, state_c) = net(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    print(' '.join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31c6a5e5-a50e-467c-a52f-7064be6a57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(words, vocab_to_int, int_to_vocab, n_vocab):\n",
    "    \n",
    "    # RNN instance\n",
    "    net = RNNModule(n_vocab, seq_size, embedding_size, lstm_size)\n",
    "    net = net.to(DEVICE)\n",
    "    criterion, optimizer = get_loss_and_train_op(net, 0.01)\n",
    "\n",
    "    iteration = 0\n",
    "    \n",
    "    for e in range(50):\n",
    "        batches = get_batches(words, vocab_to_int, batch_size, seq_size)\n",
    "        state_h, state_c = net.zero_state(batch_size)\n",
    "\n",
    "        # Transfer data to GPU\n",
    "        state_h = state_h.to(DEVICE)\n",
    "        state_c = state_c.to(DEVICE)\n",
    "        for x, y in batches:\n",
    "            iteration += 1\n",
    "\n",
    "            # Tell it we are in training mode\n",
    "            net.train()\n",
    "\n",
    "            # Reset all gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Transfer data to GPU\n",
    "            x = torch.tensor(x).to(DEVICE).long()\n",
    "            y = torch.tensor(y).to(DEVICE).long()\n",
    "\n",
    "            logits, (state_h, state_c) = net(x, (state_h, state_c))\n",
    "            loss = criterion(logits.transpose(1, 2), y)\n",
    "\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            # Perform back-propagation\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            _ = torch.nn.utils.clip_grad_norm_(net.parameters(), gradients_norm)\n",
    "            \n",
    "            # Update the network's parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                print('Epoch: {}/{}'.format(e, 200),'Iteration: {}'.format(iteration),'Loss: {}'.format(loss_value))\n",
    "\n",
    "            # if iteration % 1000 == 0:\n",
    "                # predict(device, net, flags.initial_words, n_vocab,vocab_to_int, int_to_vocab, top_k=5)\n",
    "                # torch.save(net.state_dict(),'checkpoint_pt/model-{}.pth'.format(iteration))\n",
    "                \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c380a7-57c0-42a6-819a-b72d79548581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0458700a-2bc5-479c-99ab-d812a028e5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14746"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795c8ea-cebd-48c9-8558-ab44f1914a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de281445-a2a5-4c7c-a0dd-b62aaa4f3faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c430db7-2b28-4cf5-91df-161d6c766066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "54e12a87-9fb6-466b-8f25-685806a557bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/200 Iteration: 100 Loss: 7.218320369720459\n",
      "Epoch: 0/200 Iteration: 200 Loss: 7.013370513916016\n",
      "Epoch: 0/200 Iteration: 300 Loss: 6.7905378341674805\n",
      "Epoch: 1/200 Iteration: 400 Loss: 6.801114082336426\n",
      "Epoch: 1/200 Iteration: 500 Loss: 5.949028968811035\n",
      "Epoch: 1/200 Iteration: 600 Loss: 6.4804606437683105\n",
      "Epoch: 1/200 Iteration: 700 Loss: 6.328885078430176\n",
      "Epoch: 2/200 Iteration: 800 Loss: 6.197182655334473\n",
      "Epoch: 2/200 Iteration: 900 Loss: 5.70449161529541\n",
      "Epoch: 2/200 Iteration: 1000 Loss: 5.8689069747924805\n",
      "Epoch: 2/200 Iteration: 1100 Loss: 5.627951622009277\n",
      "Epoch: 3/200 Iteration: 1200 Loss: 5.7942304611206055\n",
      "Epoch: 3/200 Iteration: 1300 Loss: 5.828190326690674\n",
      "Epoch: 3/200 Iteration: 1400 Loss: 5.717165946960449\n",
      "Epoch: 3/200 Iteration: 1500 Loss: 5.5473127365112305\n",
      "Epoch: 4/200 Iteration: 1600 Loss: 5.134014129638672\n",
      "Epoch: 4/200 Iteration: 1700 Loss: 5.2309250831604\n",
      "Epoch: 4/200 Iteration: 1800 Loss: 5.256106853485107\n",
      "Epoch: 4/200 Iteration: 1900 Loss: 5.1061835289001465\n",
      "Epoch: 5/200 Iteration: 2000 Loss: 5.2457685470581055\n",
      "Epoch: 5/200 Iteration: 2100 Loss: 5.337480545043945\n",
      "Epoch: 5/200 Iteration: 2200 Loss: 5.214288234710693\n",
      "Epoch: 5/200 Iteration: 2300 Loss: 4.729503154754639\n",
      "Epoch: 6/200 Iteration: 2400 Loss: 4.974648475646973\n",
      "Epoch: 6/200 Iteration: 2500 Loss: 4.7979736328125\n",
      "Epoch: 6/200 Iteration: 2600 Loss: 4.8110671043396\n",
      "Epoch: 6/200 Iteration: 2700 Loss: 4.6429266929626465\n",
      "Epoch: 7/200 Iteration: 2800 Loss: 4.995627403259277\n",
      "Epoch: 7/200 Iteration: 2900 Loss: 4.684664249420166\n",
      "Epoch: 7/200 Iteration: 3000 Loss: 4.991228103637695\n",
      "Epoch: 7/200 Iteration: 3100 Loss: 4.622051239013672\n",
      "Epoch: 8/200 Iteration: 3200 Loss: 4.522671222686768\n",
      "Epoch: 8/200 Iteration: 3300 Loss: 4.774727821350098\n",
      "Epoch: 8/200 Iteration: 3400 Loss: 4.664931297302246\n",
      "Epoch: 8/200 Iteration: 3500 Loss: 4.294223785400391\n",
      "Epoch: 9/200 Iteration: 3600 Loss: 4.5827531814575195\n",
      "Epoch: 9/200 Iteration: 3700 Loss: 4.7499003410339355\n",
      "Epoch: 9/200 Iteration: 3800 Loss: 4.757405757904053\n",
      "Epoch: 9/200 Iteration: 3900 Loss: 4.779231548309326\n",
      "Epoch: 10/200 Iteration: 4000 Loss: 4.581347465515137\n",
      "Epoch: 10/200 Iteration: 4100 Loss: 4.133676528930664\n",
      "Epoch: 10/200 Iteration: 4200 Loss: 4.471527099609375\n",
      "Epoch: 10/200 Iteration: 4300 Loss: 4.727019786834717\n",
      "Epoch: 11/200 Iteration: 4400 Loss: 4.294926166534424\n",
      "Epoch: 11/200 Iteration: 4500 Loss: 4.316093444824219\n",
      "Epoch: 11/200 Iteration: 4600 Loss: 4.360705375671387\n",
      "Epoch: 11/200 Iteration: 4700 Loss: 4.486708641052246\n",
      "Epoch: 12/200 Iteration: 4800 Loss: 4.669713020324707\n",
      "Epoch: 12/200 Iteration: 4900 Loss: 4.7930402755737305\n",
      "Epoch: 12/200 Iteration: 5000 Loss: 4.594470977783203\n",
      "Epoch: 12/200 Iteration: 5100 Loss: 4.39540958404541\n",
      "Epoch: 13/200 Iteration: 5200 Loss: 4.515370845794678\n",
      "Epoch: 13/200 Iteration: 5300 Loss: 3.7664098739624023\n",
      "Epoch: 13/200 Iteration: 5400 Loss: 4.517638206481934\n",
      "Epoch: 13/200 Iteration: 5500 Loss: 4.000795364379883\n",
      "Epoch: 14/200 Iteration: 5600 Loss: 4.255074501037598\n",
      "Epoch: 14/200 Iteration: 5700 Loss: 4.585557460784912\n",
      "Epoch: 14/200 Iteration: 5800 Loss: 4.289248943328857\n",
      "Epoch: 14/200 Iteration: 5900 Loss: 4.194854736328125\n",
      "Epoch: 15/200 Iteration: 6000 Loss: 4.201354026794434\n",
      "Epoch: 15/200 Iteration: 6100 Loss: 4.231490612030029\n",
      "Epoch: 15/200 Iteration: 6200 Loss: 4.309757232666016\n",
      "Epoch: 15/200 Iteration: 6300 Loss: 3.9428224563598633\n",
      "Epoch: 16/200 Iteration: 6400 Loss: 4.328312873840332\n",
      "Epoch: 16/200 Iteration: 6500 Loss: 4.257735729217529\n",
      "Epoch: 16/200 Iteration: 6600 Loss: 4.235830783843994\n",
      "Epoch: 16/200 Iteration: 6700 Loss: 4.073421955108643\n",
      "Epoch: 17/200 Iteration: 6800 Loss: 4.232738018035889\n",
      "Epoch: 17/200 Iteration: 6900 Loss: 4.266266345977783\n",
      "Epoch: 17/200 Iteration: 7000 Loss: 4.313567638397217\n",
      "Epoch: 17/200 Iteration: 7100 Loss: 4.175388813018799\n",
      "Epoch: 18/200 Iteration: 7200 Loss: 3.86006760597229\n",
      "Epoch: 18/200 Iteration: 7300 Loss: 4.17552375793457\n",
      "Epoch: 18/200 Iteration: 7400 Loss: 4.128142833709717\n",
      "Epoch: 18/200 Iteration: 7500 Loss: 3.9601104259490967\n",
      "Epoch: 19/200 Iteration: 7600 Loss: 3.9980428218841553\n",
      "Epoch: 19/200 Iteration: 7700 Loss: 3.9018490314483643\n",
      "Epoch: 19/200 Iteration: 7800 Loss: 4.16694450378418\n",
      "Epoch: 19/200 Iteration: 7900 Loss: 4.009371280670166\n",
      "Epoch: 20/200 Iteration: 8000 Loss: 3.981231212615967\n",
      "Epoch: 20/200 Iteration: 8100 Loss: 4.0300188064575195\n",
      "Epoch: 20/200 Iteration: 8200 Loss: 4.447484970092773\n",
      "Epoch: 21/200 Iteration: 8300 Loss: 4.570027828216553\n",
      "Epoch: 21/200 Iteration: 8400 Loss: 3.905802011489868\n",
      "Epoch: 21/200 Iteration: 8500 Loss: 4.362813949584961\n",
      "Epoch: 21/200 Iteration: 8600 Loss: 4.0565667152404785\n",
      "Epoch: 22/200 Iteration: 8700 Loss: 4.345974445343018\n",
      "Epoch: 22/200 Iteration: 8800 Loss: 3.9976580142974854\n",
      "Epoch: 22/200 Iteration: 8900 Loss: 4.460056781768799\n",
      "Epoch: 22/200 Iteration: 9000 Loss: 4.056583404541016\n",
      "Epoch: 23/200 Iteration: 9100 Loss: 4.094761848449707\n",
      "Epoch: 23/200 Iteration: 9200 Loss: 3.9043354988098145\n",
      "Epoch: 23/200 Iteration: 9300 Loss: 3.950540065765381\n",
      "Epoch: 23/200 Iteration: 9400 Loss: 4.146176815032959\n",
      "Epoch: 24/200 Iteration: 9500 Loss: 4.0715789794921875\n",
      "Epoch: 24/200 Iteration: 9600 Loss: 4.073230743408203\n",
      "Epoch: 24/200 Iteration: 9700 Loss: 3.8570852279663086\n",
      "Epoch: 24/200 Iteration: 9800 Loss: 3.6954588890075684\n",
      "Epoch: 25/200 Iteration: 9900 Loss: 3.996300220489502\n",
      "Epoch: 25/200 Iteration: 10000 Loss: 4.18963098526001\n",
      "Epoch: 25/200 Iteration: 10100 Loss: 4.121070861816406\n",
      "Epoch: 25/200 Iteration: 10200 Loss: 3.8077614307403564\n",
      "Epoch: 26/200 Iteration: 10300 Loss: 4.296611785888672\n",
      "Epoch: 26/200 Iteration: 10400 Loss: 3.78825306892395\n",
      "Epoch: 26/200 Iteration: 10500 Loss: 3.713691473007202\n",
      "Epoch: 26/200 Iteration: 10600 Loss: 3.8248422145843506\n",
      "Epoch: 27/200 Iteration: 10700 Loss: 4.277746200561523\n",
      "Epoch: 27/200 Iteration: 10800 Loss: 3.5337913036346436\n",
      "Epoch: 27/200 Iteration: 10900 Loss: 4.3972697257995605\n",
      "Epoch: 27/200 Iteration: 11000 Loss: 3.842034339904785\n",
      "Epoch: 28/200 Iteration: 11100 Loss: 3.8928115367889404\n",
      "Epoch: 28/200 Iteration: 11200 Loss: 4.118575572967529\n",
      "Epoch: 28/200 Iteration: 11300 Loss: 3.981933832168579\n",
      "Epoch: 28/200 Iteration: 11400 Loss: 3.644915819168091\n",
      "Epoch: 29/200 Iteration: 11500 Loss: 3.8489131927490234\n",
      "Epoch: 29/200 Iteration: 11600 Loss: 4.174243927001953\n",
      "Epoch: 29/200 Iteration: 11700 Loss: 4.106546878814697\n",
      "Epoch: 29/200 Iteration: 11800 Loss: 3.9044718742370605\n",
      "Epoch: 30/200 Iteration: 11900 Loss: 3.889491558074951\n",
      "Epoch: 30/200 Iteration: 12000 Loss: 3.6350574493408203\n",
      "Epoch: 30/200 Iteration: 12100 Loss: 3.9135475158691406\n",
      "Epoch: 30/200 Iteration: 12200 Loss: 4.104899883270264\n",
      "Epoch: 31/200 Iteration: 12300 Loss: 3.4656333923339844\n",
      "Epoch: 31/200 Iteration: 12400 Loss: 3.7204079627990723\n",
      "Epoch: 31/200 Iteration: 12500 Loss: 3.573570728302002\n",
      "Epoch: 31/200 Iteration: 12600 Loss: 3.8266983032226562\n",
      "Epoch: 32/200 Iteration: 12700 Loss: 4.054777145385742\n",
      "Epoch: 32/200 Iteration: 12800 Loss: 4.127017974853516\n",
      "Epoch: 32/200 Iteration: 12900 Loss: 3.899021625518799\n",
      "Epoch: 32/200 Iteration: 13000 Loss: 3.897671699523926\n",
      "Epoch: 33/200 Iteration: 13100 Loss: 3.969728946685791\n",
      "Epoch: 33/200 Iteration: 13200 Loss: 3.022783041000366\n",
      "Epoch: 33/200 Iteration: 13300 Loss: 4.044974327087402\n",
      "Epoch: 33/200 Iteration: 13400 Loss: 3.3314127922058105\n",
      "Epoch: 34/200 Iteration: 13500 Loss: 3.7824254035949707\n",
      "Epoch: 34/200 Iteration: 13600 Loss: 4.223938465118408\n",
      "Epoch: 34/200 Iteration: 13700 Loss: 3.9306282997131348\n",
      "Epoch: 34/200 Iteration: 13800 Loss: 3.7241389751434326\n",
      "Epoch: 35/200 Iteration: 13900 Loss: 3.738778591156006\n",
      "Epoch: 35/200 Iteration: 14000 Loss: 3.8597254753112793\n",
      "Epoch: 35/200 Iteration: 14100 Loss: 3.9103376865386963\n",
      "Epoch: 35/200 Iteration: 14200 Loss: 3.3792974948883057\n",
      "Epoch: 36/200 Iteration: 14300 Loss: 4.0467376708984375\n",
      "Epoch: 36/200 Iteration: 14400 Loss: 3.873762369155884\n",
      "Epoch: 36/200 Iteration: 14500 Loss: 3.8698503971099854\n",
      "Epoch: 36/200 Iteration: 14600 Loss: 3.6915740966796875\n",
      "Epoch: 37/200 Iteration: 14700 Loss: 3.7899515628814697\n",
      "Epoch: 37/200 Iteration: 14800 Loss: 3.9038074016571045\n",
      "Epoch: 37/200 Iteration: 14900 Loss: 3.973788022994995\n",
      "Epoch: 37/200 Iteration: 15000 Loss: 3.778965711593628\n",
      "Epoch: 38/200 Iteration: 15100 Loss: 3.3225321769714355\n",
      "Epoch: 38/200 Iteration: 15200 Loss: 3.9328360557556152\n",
      "Epoch: 38/200 Iteration: 15300 Loss: 3.756314992904663\n",
      "Epoch: 38/200 Iteration: 15400 Loss: 3.5250892639160156\n",
      "Epoch: 39/200 Iteration: 15500 Loss: 3.611283540725708\n",
      "Epoch: 39/200 Iteration: 15600 Loss: 3.5686657428741455\n",
      "Epoch: 39/200 Iteration: 15700 Loss: 3.8930211067199707\n",
      "Epoch: 39/200 Iteration: 15800 Loss: 3.572667121887207\n",
      "Epoch: 40/200 Iteration: 15900 Loss: 3.659122943878174\n",
      "Epoch: 40/200 Iteration: 16000 Loss: 3.603905200958252\n",
      "Epoch: 40/200 Iteration: 16100 Loss: 3.9855785369873047\n",
      "Epoch: 41/200 Iteration: 16200 Loss: 4.105998992919922\n",
      "Epoch: 41/200 Iteration: 16300 Loss: 3.6178767681121826\n",
      "Epoch: 41/200 Iteration: 16400 Loss: 4.082993507385254\n",
      "Epoch: 41/200 Iteration: 16500 Loss: 3.671190023422241\n",
      "Epoch: 42/200 Iteration: 16600 Loss: 4.038402557373047\n",
      "Epoch: 42/200 Iteration: 16700 Loss: 3.652944564819336\n",
      "Epoch: 42/200 Iteration: 16800 Loss: 4.219247341156006\n",
      "Epoch: 42/200 Iteration: 16900 Loss: 3.761261463165283\n",
      "Epoch: 43/200 Iteration: 17000 Loss: 3.7634055614471436\n",
      "Epoch: 43/200 Iteration: 17100 Loss: 3.4409382343292236\n",
      "Epoch: 43/200 Iteration: 17200 Loss: 3.657282829284668\n",
      "Epoch: 43/200 Iteration: 17300 Loss: 3.941521644592285\n",
      "Epoch: 44/200 Iteration: 17400 Loss: 3.811720371246338\n",
      "Epoch: 44/200 Iteration: 17500 Loss: 3.7914843559265137\n",
      "Epoch: 44/200 Iteration: 17600 Loss: 3.5889720916748047\n",
      "Epoch: 44/200 Iteration: 17700 Loss: 3.4899353981018066\n",
      "Epoch: 45/200 Iteration: 17800 Loss: 3.692492961883545\n",
      "Epoch: 45/200 Iteration: 17900 Loss: 4.016368389129639\n",
      "Epoch: 45/200 Iteration: 18000 Loss: 3.9599969387054443\n",
      "Epoch: 45/200 Iteration: 18100 Loss: 3.5190200805664062\n",
      "Epoch: 46/200 Iteration: 18200 Loss: 4.085782527923584\n",
      "Epoch: 46/200 Iteration: 18300 Loss: 3.5545053482055664\n",
      "Epoch: 46/200 Iteration: 18400 Loss: 3.520735502243042\n",
      "Epoch: 46/200 Iteration: 18500 Loss: 3.6655991077423096\n",
      "Epoch: 47/200 Iteration: 18600 Loss: 4.078673362731934\n",
      "Epoch: 47/200 Iteration: 18700 Loss: 3.2769203186035156\n",
      "Epoch: 47/200 Iteration: 18800 Loss: 4.18435525894165\n",
      "Epoch: 47/200 Iteration: 18900 Loss: 3.6464169025421143\n",
      "Epoch: 48/200 Iteration: 19000 Loss: 3.6978306770324707\n",
      "Epoch: 48/200 Iteration: 19100 Loss: 3.9141428470611572\n",
      "Epoch: 48/200 Iteration: 19200 Loss: 3.5969862937927246\n",
      "Epoch: 48/200 Iteration: 19300 Loss: 3.4538140296936035\n",
      "Epoch: 49/200 Iteration: 19400 Loss: 3.778651714324951\n",
      "Epoch: 49/200 Iteration: 19500 Loss: 3.9641425609588623\n",
      "Epoch: 49/200 Iteration: 19600 Loss: 3.896867275238037\n",
      "Epoch: 49/200 Iteration: 19700 Loss: 3.7509403228759766\n"
     ]
    }
   ],
   "source": [
    "rnn_net = train_rnn(words, vocab_to_int, int_to_vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a16c7-5641-4ca6-a428-d3db9a2dd136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bc106899-9bce-45f9-90fc-38385b69cce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are merely cheated of the mustard PETRUCHIO Marry sir tis not the fountain and wary ARIEL Not to your reports KATHARINA What noise so thriftless trust Like the way to be touched BAPTISTA What is the day She shall we proceed But in my remembrance MIRANDA The other moon shines to make thee From whence that thou must Katharina As we shall have the master Angelo I know not how he woo PETRUCHIO A horse in the lampass slaughter in a chains arms and break it and a fossetseller for the beak Have he is a kind man Three accident that hath\n"
     ]
    }
   ],
   "source": [
    "generate_text(DEVICE, rnn_net, ['We', 'are'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62bc9731-5a4f-43f5-8a5e-30c288791bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is no more Suitors in this action of it will come you at least Affections run mad Under the bay to be vows to the people And so I pray thee for the rest o the bolster BAPTISTA Now by my troth is it not heard him with the gown owes thee to me If it doth not PETRUCHIO I pray you are welcome And I have used me in a warrant fat tear and obtaind for the window 3 In human reason thou varlet now HORTENSIO Now by your lordship drink my master wink BAPTISTA Now in your staves as\n"
     ]
    }
   ],
   "source": [
    "generate_text(DEVICE, rnn_net, ['what'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "31b18102-232e-4517-8000-129de9c944a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You may not be done When you have done withal and called the world without counters I crave any man of Pisa and vengeance ISABELLA A whoreson Ay sir to Padua GRUMIO Nay if Katharina may be your ben Page His demand Springs not that it was certainly to be Pisa PETRUCHIO Now Kate Master thou art thence which thou shalt be deceived But now Lucentio or dost thou art to him I mean in sooth Signior Baptista whilst I am Grumios pledge unhappy master Lucentio is not so much lengththe Aufidius And thou hast never forgot Nothing anon and ride not\n"
     ]
    }
   ],
   "source": [
    "generate_text(DEVICE, rnn_net, ['You'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c0ad29b-44ba-47ff-8cd6-a978a0069255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I tell you friends and admit my lord tis a father which is that she is coming BAPTISTA What ist eer seven i the heel And so to do me to thy minions charge night PROSPERO MIRANDA What says my father will I not Four lagging clout Duke at We shall I go by manifest LUCENTIO Peace Now be some comfort be ruled GREEN That in this business AUTOLYCUS She was a respected woman in my fathers liking Claudio VINCENTIO Not you gentlemen No impediment as he is a toy to the gaol BAPTISTA How now the sliding of your hands and tie me so\n"
     ]
    }
   ],
   "source": [
    "generate_text(DEVICE, rnn_net, ['I', 'tell', 'you', 'friends'], len(vocab), vocab_to_int, int_to_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fe57ed-30f9-453c-921d-84c2fd8dd19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe994beb-c794-46d5-9697-38c1b345b9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf56c2-82c9-41a2-86c1-8197a06d5412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ff89f-8271-45bd-a0c2-23239034a6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee5b1e-f12a-40ff-860f-dd944f951807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdae16ea-eccd-4b4f-839f-74f2c7ef9f24",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7346659e-5516-4b2f-af31-887d433ee7a5",
   "metadata": {},
   "source": [
    "## Question - c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa515db-25e9-48d6-a927-0b621d0f60c1",
   "metadata": {},
   "source": [
    "(c) Perplexity is defined as the exponentiated average negative log-likelihood of a sequence. Let X = (x0, . . . , xt), then the perplexity of X is ...\n",
    "Train your network RNNs and provide a PPL curve over the course of the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f7e27-0453-4212-98db-3d9a7db9e610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89923f-8e9f-41d2-ac40-0f6e1cc1b2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfce62-c3f7-49a3-9e1d-e470f036ecdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b08bdcc-76dd-49f3-b977-a51625409c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8983da-500f-4c17-a952-f0a49c3048de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2783a513-b4ce-4eb7-a970-7da1b5fa02f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1114a422-86c6-49f4-9279-dcd917906213",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca83d1-aae6-430d-b331-35724d28bba5",
   "metadata": {},
   "source": [
    "## Question - d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334afccd-4bda-450f-983b-5964dea8641b",
   "metadata": {},
   "source": [
    "(d) Among GRU, LSTM, or Transformer, pick one of your favorite architecture, and design the architecture whose the number of parameters is similar to vanila RNN you implemented above. Then train and provide a PPL curve over the course of the training (in the same plots in (c)). You are free to select any hyperparameters if needed (no need to use the hyperparameters above). Report the number of model parameters. (You can use GRU, LSTM, or Transformer libararies, if you want, but I recommend you to implement by yourself.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9bb607-1937-4a69-ba95-f8e0eae0c136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02eeacb-c0a8-4821-a0e1-f986a4d58c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138be7f-c517-4693-a0b8-4089b9e89847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78f4260-bf9c-416e-a55f-6fcb43585bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190aa62-bcc8-47cc-9b51-0e9826c6adce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26bc4e-8310-40ee-8517-d8d849608732",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c684da-7b79-4653-acfe-f9c16ca06add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0cf34-b361-45dd-98bb-f50fb4712941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c905c999-996e-4289-8cdf-6e9671ab7bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "709fd804-2f01-44e4-b428-3aa55a2cb644",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb46ed8-0efb-41fc-a0a8-5e9811676d57",
   "metadata": {},
   "source": [
    "## Question - e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a38a22-f661-446f-bcdc-adc6c7db06a3",
   "metadata": {},
   "source": [
    "(e) Pick the best performing (lowest PPL score) model, and generate the text autoregressively given the following prompts.\n",
    "> (1) ‘We are’ \\\n",
    "(2) ‘what’ \\\n",
    "(3) ‘You’ \\\n",
    "(4) ‘I tell you, friends’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c1267-508e-494c-898d-746cc9707c61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ba83a-3f7d-4935-a177-aee68a4d2f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad2c3dd-6964-4b6d-9a7d-8d2eec741c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e576e8-628a-4d2a-a0fb-acd213ef4cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30aa29-5ae1-40f6-9a8f-d4643134656f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be72bd-3b9b-4989-b13f-93f93a8a3027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
