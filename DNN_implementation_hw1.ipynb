{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14256a7-f748-4036-bc2e-0cdb72c3ade6",
   "metadata": {},
   "source": [
    "# AIM5004_HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763857cf-9ed9-4f2b-bb1a-dc11e57aebb7",
   "metadata": {},
   "source": [
    "* Implementation of MLP (Multilayer Perceptron). You are going to write codes in any programming languages from the scratch. You can use some libraries, e.g. numpy, but you are NOT allowed to use any deep learning libraries, such as. Tensorflow, Pytorch, and JAX.\n",
    "\n",
    "* You should submit the codes as Jupyter notebook, .ipynb file or google colab link. All codes should be executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ea062-558d-4c41-91dd-3e27c26d808f",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb822c2-5672-49a4-90d3-a0b7e90d2d55",
   "metadata": {},
   "source": [
    "(a) Download MNIST dataset from http://yann.lecun.com/exdb/mnist/ and report the\n",
    "statistics of the dataset, e.g. how many training (and testing) images, the size of each image, the number of class and the number of images per each classes. Normalize data to [0, 1] if necessary. Show random 3 images per each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d8158-4b9d-4d4c-b0fa-c9844d95cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import random\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a49a9f-ced3-4364-8fe3-d3dd32adf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef1e54-4e67-4164-829a-54379735b689",
   "metadata": {},
   "source": [
    "We got 4 data files\n",
    "- train-images-idx3-ubyte.gz\n",
    "- train-labels-idx1-ubyte.gz\n",
    "- t10k-images-idx3-ubyte.gz\n",
    "- t10k-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e1d5a-a62e-4931-9e7c-4b6b4c84625f",
   "metadata": {},
   "source": [
    "### Handling Training dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a110d9-41c9-4d77-8a58-86a5efa99e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open gz train data downloaded from lecun. - using gzip.open \n",
    "with gzip.open('./data/mnist/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_data_ori = idx2numpy.convert_from_file(f)\n",
    "\n",
    "with gzip.open('./data/mnist/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_label = idx2numpy.convert_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b695d-a3b2-44c0-ae51-42ae6156d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resizing training dataset and normalize data\n",
    "train_data_ori = train_data_ori.reshape(len(train_data_ori),-1)\n",
    "train_data_ori = train_data_ori.astype(float)/255\n",
    "# train_data_ori = MinMaxScaler().fit_transform(train_data_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a5cb5-4f62-4a40-997e-8e3b2f77401a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Encoding training label values\n",
    "train_label = np.eye(10)[train_label].reshape(len(train_label),10)\n",
    "# train_label = train_label.astype(int)\n",
    "## Seperate out the validation set.\n",
    "train_data_ori, val_data, train_label, val_label = train_test_split(train_data_ori, train_label, test_size=10000, random_state=710674)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55895ba-ee91-4b72-8974-1a4cc47b0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.array(train_data)\n",
    "# train_label = np.array(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cee8c5-55ec-4333-bded-85b5470815a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handling Test dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54208b-5fc2-4958-b8a2-1145d717c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open gz test dataset\n",
    "with gzip.open('./data/mnist/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_data = idx2numpy.convert_from_file(f)\n",
    "    \n",
    "with gzip.open('./data/mnist/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_label = idx2numpy.convert_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8006a3-f2b3-4494-8b68-f8d29cab00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping test dataset and normalize the data\n",
    "test_data = test_data.reshape(len(test_data),-1)\n",
    "test_data = test_data.astype(float)/255\n",
    "# test_data = MinMaxScaler().fit_transform(test_data)\n",
    "\n",
    "## Encoding test label values\n",
    "test_label = np.eye(10)[test_label].reshape(len(test_label),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc96f3-89b8-4f57-9dd1-0958cac56b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping data into pixel formats: (28 x 28) format\n",
    "train_data = train_data_ori.reshape(len(train_data_ori),28,28)\n",
    "val_data = val_data.reshape(len(val_data),28,28)\n",
    "test_data = test_data.reshape(len(test_data),28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158df3cf-a7ad-49ae-bac6-299868e23ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfceffe-0042-4dfb-9b7a-7f614925f119",
   "metadata": {},
   "source": [
    "### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3503c01-fe60-4201-a17e-70b22e65f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The train data has \", str(train_data.shape[0]), \"samples\")\n",
    "print(\"The validation data has \", str(val_data.shape[0]), \"samples\")\n",
    "print(\"The test data has \", str(test_data.shape[0]), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d25f1c-c45a-435a-9aba-509c31081345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b17e494-1a5c-41ce-b1ae-0d568b11e328",
   "metadata": {},
   "source": [
    "### Random image samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a80187-42fb-4e1d-a52f-f6a6aa5493fc",
   "metadata": {},
   "source": [
    "* Show random 3 images per each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd934dc-eb82-40d6-a8f1-5043aa3e80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc2145-8786-46d6-b95a-36109e1a9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding out which data row is matched for\n",
    "class0 = train_df.loc[train_df[0] == 1]\n",
    "class1 = train_df.loc[train_df[1] == 1]\n",
    "class2 = train_df.loc[train_df[2] == 1]\n",
    "class3 = train_df.loc[train_df[3] == 1]\n",
    "class4 = train_df.loc[train_df[4] == 1]\n",
    "class5 = train_df.loc[train_df[5] == 1]\n",
    "class6 = train_df.loc[train_df[6] == 1]\n",
    "class7 = train_df.loc[train_df[7] == 1]\n",
    "class8 = train_df.loc[train_df[8] == 1]\n",
    "class9 = train_df.loc[train_df[9] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9e7c7-5f7d-419d-bdfa-b73f83fdf2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_index = class0.index\n",
    "class1_index = class1.index\n",
    "class2_index = class2.index\n",
    "class3_index = class3.index\n",
    "class4_index = class4.index\n",
    "class5_index = class5.index\n",
    "class6_index = class6.index\n",
    "class7_index = class7.index\n",
    "class8_index = class8.index\n",
    "class9_index = class9.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe834723-1b5c-4ac0-a5f5-b829a5c710f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SampleImages():\n",
    "#     ran = random.sample(range(len(train_data)),3)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(5,6,1)\n",
    "    plt.imshow(train_data[0], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,2)\n",
    "    plt.imshow(train_data[3], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,3)\n",
    "    plt.imshow(train_data[4], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,4)\n",
    "    plt.imshow(train_data[13], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,5)\n",
    "    plt.imshow(train_data[39], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,6)\n",
    "    plt.imshow(train_data[44], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,7)\n",
    "    plt.imshow(train_data[11], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,8)\n",
    "    plt.imshow(train_data[16], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,9)\n",
    "    plt.imshow(train_data[30], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,10)\n",
    "    plt.imshow(train_data[9], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,11)\n",
    "    plt.imshow(train_data[22], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,12)\n",
    "    plt.imshow(train_data[38], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,13)\n",
    "    plt.imshow(train_data[6], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,14)\n",
    "    plt.imshow(train_data[7], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,15)\n",
    "    plt.imshow(train_data[18], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,16)\n",
    "    plt.imshow(train_data[1], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,17)\n",
    "    plt.imshow(train_data[20], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,18)\n",
    "    plt.imshow(train_data[24], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,19)\n",
    "    plt.imshow(train_data[8], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,20)\n",
    "    plt.imshow(train_data[21], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,21)\n",
    "    plt.imshow(train_data[26], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,22)\n",
    "    plt.imshow(train_data[5], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,23)\n",
    "    plt.imshow(train_data[12], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,24)\n",
    "    plt.imshow(train_data[17], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,25)\n",
    "    plt.imshow(train_data[2], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,26)\n",
    "    plt.imshow(train_data[29], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,27)\n",
    "    plt.imshow(train_data[45], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,28)\n",
    "    plt.imshow(train_data[15], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,29)\n",
    "    plt.imshow(train_data[23], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,30)\n",
    "    plt.imshow(train_data[25], cmap='gray');plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266ac01-24ec-4bae-b335-b1ad1a6f510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d68f4-3d37-40bc-91ba-c6b4236c078f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "585733ec-1d84-4e36-afc6-0d0a61c3015a",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa007fef-f2ca-40eb-a051-4e17a7d8a84f",
   "metadata": {},
   "source": [
    "### MNIST_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65808e6d-d702-4cd4-b5fb-26dc490b199a",
   "metadata": {},
   "source": [
    "(b) Implement a MLP architecture and write forward pass. You need to implement all\n",
    "following layers, ReLU activation function, and softmax function. You should also\n",
    "implement cross-entropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f3747-d47d-4c4d-82fb-3e9c0312b59d",
   "metadata": {},
   "source": [
    "(1) Architecture:\\\n",
    "[Layer 1] → Flatten layer that will flatten image 2D matrix into 1D vector.\\\n",
    "[Layer 2] → Dense layer (fully connected layer) with 128 hidden units, followed\n",
    "by ReLU activation function.\\\n",
    "[Layer 3] → Dense layer (fully connected layer) with 128 hidden units, followed\n",
    "by ReLU activation function.\\\n",
    "[Layer 4] → Output dense layer (fully connected layer) with 10 softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971fed0a-31eb-4817-a238-e82f2cc45109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.001\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af19989-d941-4785-810d-23f35c09c2c8",
   "metadata": {},
   "source": [
    "* Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4f8df-efd7-4177-85ef-49591098ec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sigmoid Function\n",
    "def sigmoid(self, x, derivative=False):\n",
    "    if derivative:\n",
    "        return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab842a2-3a7e-4058-ac7e-4e97e4f2e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Softmax Function\n",
    "def softmax(self, x, derivative=False):\n",
    "    exps = np.exp(x - x.max())\n",
    "    if derivative:\n",
    "        return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "    return exps / np.sum(exps, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454a98c7-dd04-4655-bf98-2a9b765deae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relu Function\n",
    "def relu(self, x):\n",
    "    return np.maximum(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d980450-e4d2-4302-9dab-213cf2bea0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dReLu Function\n",
    "def drelu(self,x):\n",
    "    return 1 * (x > 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce27785-3d5b-4deb-afd2-8fb7d0cbd950",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating MNIST MLP model structure\n",
    "class MNIST_MLP():\n",
    "    def __init__(self, sizes, epochs=args.epochs, lr=args.lr):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.l_rate = lr\n",
    "        self.params = self.initialization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97782d-b102-4ccb-acbb-ec60a22257ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight Initializing\n",
    "def initialization(self):\n",
    "    input_layer=self.sizes[0]\n",
    "    hidden_1=self.sizes[1]\n",
    "    hidden_2=self.sizes[2]\n",
    "    output_layer=self.sizes[3]\n",
    "    \n",
    "    params = {'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "              'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "              'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "    }\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbc594d-ac23-42ba-9d50-2ea083391b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Forward propagation\n",
    "def forward(self, train_data):\n",
    "    params = self.params\n",
    "    params['A0'] = train_data.reshape(28*28) #have to reshape for the training process\n",
    "#     print(params['A0']) #testing the error\n",
    "\n",
    "    ## hidden layer 1\n",
    "    params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "    params['A1'] = self.relu(params['Z1'])\n",
    "\n",
    "    ## hidden layer 2\n",
    "    params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "    params['A2'] = self.relu(params['Z2'])\n",
    "\n",
    "    ## output layer\n",
    "    params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "    params['A3'] = self.softmax(params['Z3'])\n",
    "\n",
    "    return params['A3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450e872b-9578-42c2-b4cc-3068349469bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2013e94-b562-43c5-a16b-6da19c730b40",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e3f54-b4e3-471e-ab82-a49ba75c2295",
   "metadata": {},
   "source": [
    "### Backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb371c-ed30-4eca-a256-316da2ebc7de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "(c) Implement backward pass to compute the gradients w.r.t the parameters. You should check the correctness of your implementation by either (1) using finite difference or (2) using the existing deep learning libraries. Please provide checking codes in the report ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6e18e-2e17-4ece-844e-77283e638a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Backward propagation\n",
    "def back(self, train_label, output):\n",
    "    params = self.params\n",
    "    change_w = {}\n",
    "\n",
    "    ## W3 update\n",
    "    error = 2 * (output - train_label) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "    change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "    ## W2 update\n",
    "    error = np.dot(params['W3'].T, error) * self.relu(params['Z2'], derivative=True)\n",
    "    change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "    ## W1 update\n",
    "    error = np.dot(params['W2'].T, error) * self.relu(params['Z1'], derivative=True)\n",
    "    change_w['W1'] = np.outer(error, params['A0'])\n",
    "\n",
    "    return change_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a783ce-061c-4669-a19f-feb9c0fd07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Weight parameters update\n",
    "def update_network_parameters(self, changes_to_w):\n",
    "    for key, value in changes_to_w.items():\n",
    "        self.params[key] -= self.l_rate * value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9923ae5-5c84-46d2-a63c-0ed78f808683",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating accuracy with validation data and following label\n",
    "def compute_accuracy(self, val_data, val_label):\n",
    "    predictions = []\n",
    "    for x, y in zip(val_data, val_label):\n",
    "        output = self.forward(x)\n",
    "        pred = np.argmax(output)\n",
    "        predictions.append(pred == np.argmax(y))\n",
    "    \n",
    "    return np.mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e1118-7ab0-4105-a5ed-eacaa1dcbdff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d0ab7-8ce3-42d5-84c6-fcf5107e1a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb8534a1-f5f8-486b-af82-166f96a76d9a",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c46f3b-2948-4905-847a-a45ee42e7110",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comparison with pytorch library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cea0c7-6b10-41c5-8084-fd2d246c0ad0",
   "metadata": {},
   "source": [
    "* (2) Using the existing deep learning libraries - with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96421550-9067-446d-8064-9697230fbe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining Mean Squared Error calculation\n",
    "def mse_cal(y, y_pred):\n",
    "    mse_y = np.square(np.subtract(y, y_pred)).mean()\n",
    "    return mse_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a0093-379b-4a2c-b87f-683bed67fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init \n",
    "import torchvision\n",
    "from torchvision import transforms, datasets \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87116786-760b-48f6-b028-57c4f0f94677",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df2d63-0cbc-457b-aa2f-e39bb97f7bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.001\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ece5de-9a3f-43a4-8246-7803b8e427e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "train_d = datasets.MNIST(root='../data/MNIST',\n",
    "                         train=True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "\n",
    "test_d = datasets.MNIST(root='../data/MNIST',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb594d-b512-4b50-adc2-6ac8ce2c629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_d, batch_size=args.bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_d, batch_size=args.bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec512642-35d1-47b6-ae30-b7477ad99661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc665b41-a515-4142-90b3-225a5672938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_MNIST_torch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_MNIST_torch, self).__init__()\n",
    "        self.layer1 = nn.Linear(28 * 28, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.layer1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.layer3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37569223-27ed-42c0-b1e1-5875399f2c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_MNIST = MLP_MNIST_torch()\n",
    "model = model_MNIST.to(DEVICE)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96d72e-5e05-4ea7-aeeb-d47c8406d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc50f62-1ce4-498d-a4c5-43abb01a4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(args.epochs):\n",
    "    loss = 0\n",
    "    batch = len(train_loader)\n",
    "\n",
    "    for images, labels in train_loader: \n",
    "        images = images.view(-1, 28 * 28).to(DEVICE) \n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(images)\n",
    "        cost = criterion(hypothesis, labels)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        loss += cost / batch\n",
    "\n",
    "    print('Epoch:', '%03d' % (epoch + 1), 'Training loss =', '{:.5f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76039f83-382e-418f-a151-3d1fe6f9bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model using test sets\n",
    "with torch.no_grad():\n",
    "    y_pred = []\n",
    "    images_test = test_d.data.view(-1, 28 * 28).float().to(DEVICE)\n",
    "    labels_test = test_d.targets.to(DEVICE)\n",
    "    \n",
    "    prediction = model(images_test)\n",
    "    y_pred.append(prediction)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == labels_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Test Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed90a89-f568-456b-af0a-053ec5a0a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59002f84-1f79-4623-9def-bd290cf429a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc655f18-eaac-4737-bedf-55d34eefa6a4",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef23bcf-b621-4373-b1be-9fd134d463ab",
   "metadata": {},
   "source": [
    "### SGD algorithm based training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9f6b2-0bd8-4624-b18d-c2aeefd98d37",
   "metadata": {},
   "source": [
    "(d) Implement a stochastic gradient descent (SGD) algorithm and train your model. Please provide training and validation loss curves in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b3c7d-3cc8-4bbb-acb1-72a7f171cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training and evaluate with training dataset and validation dataset.\n",
    "def train(self, train_data, train_label, val_data, val_label):\n",
    "    start_time = time.time()\n",
    "    for iteration in range(self.epochs):\n",
    "        for x,y in zip(train_data, train_label):\n",
    "            output = self.forward(x)\n",
    "            changes_to_w = self.back(y, output)\n",
    "            self.update_network_parameters(changes_to_w)\n",
    "            \n",
    "        accuracy = self.compute_accuracy(val_data, val_label)\n",
    "        print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "            iteration+1, time.time() - start_time, accuracy * 100\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989c1ee-7e44-4bd1-aac8-6c9131106ec7",
   "metadata": {},
   "source": [
    "* Overall process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a104e48-0555-42bd-9a1a-325c7fc887a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_MLP_OVERALL():\n",
    "    def __init__(self, sizes, epochs=args.epochs, lr=args.lr):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.l_rate = lr\n",
    "        \n",
    "        self.loss =[]\n",
    "        self.acc =[]\n",
    "        self.params = self.initialization()\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        exps = np.exp(x - x.max())\n",
    "        if derivative:\n",
    "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "    \n",
    "    def relu(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return np.maximum(0,x)\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def drelu(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return 1 * (x > 0)\n",
    "        return 1 * (x > 0) \n",
    "\n",
    "    def initialization(self):\n",
    "        input_layer=self.sizes[0]\n",
    "        hidden_1=self.sizes[1]\n",
    "        hidden_2=self.sizes[2]\n",
    "        output_layer=self.sizes[3]\n",
    "\n",
    "        params = {\n",
    "            'W1':np.random.randn(hidden_1, input_layer) * np.sqrt(1. / hidden_1),\n",
    "            'W2':np.random.randn(hidden_2, hidden_1) * np.sqrt(1. / hidden_2),\n",
    "            'W3':np.random.randn(output_layer, hidden_2) * np.sqrt(1. / output_layer)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def forward(self, train_data):\n",
    "        params = self.params\n",
    "        params['A0'] = train_data.reshape(28*28)\n",
    "#         print(params['A0'])\n",
    "\n",
    "        # hidden layer 1\n",
    "        params['Z1'] = np.dot(params[\"W1\"], params['A0'])\n",
    "        params['A1'] = self.relu(params['Z1'])\n",
    "\n",
    "        # hidden layer 2\n",
    "        params['Z2'] = np.dot(params[\"W2\"], params['A1'])\n",
    "        params['A2'] = self.relu(params['Z2'])\n",
    "\n",
    "        # output layer\n",
    "        params['Z3'] = np.dot(params[\"W3\"], params['A2'])\n",
    "        params['A3'] = self.softmax(params['Z3'])\n",
    " \n",
    "\n",
    "        return params['A3']\n",
    "\n",
    "    \n",
    "    def back(self, train_label, output):\n",
    "        params = self.params\n",
    "        change_w = {}\n",
    "        l = 0\n",
    "\n",
    "        # W3 update\n",
    "        error = 2 * (output - train_label) / output.shape[0] * self.softmax(params['Z3'], derivative=True)\n",
    "        change_w['W3'] = np.outer(error, params['A2'])\n",
    "\n",
    "        # W2 update\n",
    "        error = np.dot(params['W3'].T, error) * self.drelu(params['Z2'], derivative=True)\n",
    "        change_w['W2'] = np.outer(error, params['A1'])\n",
    "\n",
    "        # W1 update\n",
    "        error = np.dot(params['W2'].T, error) * self.drelu(params['Z1'], derivative=True)\n",
    "        change_w['W1'] = np.outer(error, params['A0'])\n",
    "        \n",
    "        return change_w\n",
    "\n",
    "    def update_network_parameters(self, changes_to_w):        \n",
    "        for key, value in changes_to_w.items():\n",
    "            self.params[key] -= self.l_rate * value\n",
    "\n",
    "    def compute_accuracy(self, val_data, val_label):\n",
    "        predictions = []\n",
    "\n",
    "        for x, y in zip(val_data, val_label):\n",
    "            output = self.forward(x)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(y))\n",
    "        \n",
    "        return np.mean(predictions)\n",
    "           \n",
    "    \n",
    "    ## training and evaluate with training dataset and validation dataset.\n",
    "    def train(self, train_data, train_label, val_data, val_label):\n",
    "        start_time = time.time()\n",
    "        for iteration in range(self.epochs):\n",
    "            l = 0\n",
    "            for x,y in zip(train_data, train_label):\n",
    "                output = self.forward(x)\n",
    "                changes_to_w = self.back(y, output)\n",
    "                self.update_network_parameters(changes_to_w)\n",
    "                \n",
    "            accuracy = self.compute_accuracy(val_data, val_label)\n",
    "            self.acc.append(accuracy*100)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, accuracy * 100\n",
    "            ))\n",
    "    def plot(self):\n",
    "        plt.plot(self.acc)\n",
    "        plt.xlabel('epochs')\n",
    "        plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c7ea8-d57f-45fc-951e-2725221f26f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP_OVERALL(sizes=[784, 128, 128, 10])\n",
    "model.train(train_data, train_label, val_data, val_label)\n",
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae202014-8af3-4ddc-a6b0-d935954c446d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad4e12-b20d-4e4a-adcd-2d19dd559aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4201ac-480a-4331-8bb0-f6e0ab7a179d",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a387ae91-839f-4258-94e4-b8a291185c16",
   "metadata": {},
   "source": [
    "### Try various hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74720fb7-0de6-4e3e-b5a3-fbb3d90e4f44",
   "metadata": {},
   "source": [
    "(e) Train with different hyperparameters. Try at least 5 different learning rates and minibatch sizes. Plot training and validation curves for all different configurations in a single plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ca25c-30bf-401f-98da-a6b1bab3369b",
   "metadata": {},
   "source": [
    "* In the training process above, I used \"batch = 32, epochs=30, learning rate = 0.001\". Let's change learning rate values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78a2935-9c29-4490-9e13-c5e742890222",
   "metadata": {},
   "source": [
    "#### lr = 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbf9a5-c4aa-49f5-af45-87747e306ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.1\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807da90-6d74-466f-b3b9-1a28a362b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP_OVERALL(sizes=[784, 128, 128, 10])\n",
    "model.train(train_data, train_label, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed314eda-9b0d-4551-a757-bf350eb7ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.plot() + plt.title(\"learning rate 0.1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d497b7-4239-427a-920f-f0257b0ca5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f60bb742-b05f-4d26-a22a-4ab7d6b233e4",
   "metadata": {},
   "source": [
    "#### lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b655c33-3724-4c39-89bb-163ca4627acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.01\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f551f3d-f00f-40fa-bacb-1de4fd5f5ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP_OVERALL(sizes=[784, 128, 128, 10])\n",
    "model.train(train_data, train_label, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc737b-9b26-4ed1-9d25-079144e4cd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.plot() + plt.title(\"learning rate 0.01\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1f321-a4b9-4061-b28f-3905ab815b5d",
   "metadata": {},
   "source": [
    "#### lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97766768-0b0d-4cfe-bdf6-abfbf5bec788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.05\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b7971-8ae2-4212-a42b-53ddd19ea335",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP_OVERALL(sizes=[784, 128, 128, 10])\n",
    "model.train(train_data, train_label, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b63774-7ede-4bbf-8185-cce9c9fd2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.plot() + plt.title(\"learning rate 0.05\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76706ed-832b-415d-8a33-70c5850703a6",
   "metadata": {},
   "source": [
    "#### lr = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204e418-e200-43ab-89ab-9f084ea5a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.005\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124271ac-e676-4b79-8355-2fcb27c29001",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP_OVERALL(sizes=[784, 128, 128, 10])\n",
    "model.train(train_data, train_label, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4650c2-9fcf-4f1b-a8e1-675c667efbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.plot() + plt.title(\"learning rate 0.005\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc467c-b8d6-44e6-94e6-35ca3ad4ad0a",
   "metadata": {},
   "source": [
    "#### lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bde7be-7028-4214-a3f8-b1815551f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=32\n",
    "    lr=0.0001\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffef2725-9021-4f4f-8797-279f7a262e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_MLP_OVERALL(sizes=[784, 128, 128, 10])\n",
    "model.train(train_data, train_label, val_data, val_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac47201-af2c-4350-b156-a8765822bcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.plot() + plt.title(\"learning rate 0.0001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b83e8-956a-4d7d-862e-6061e502e7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69e56f4e-9947-4655-846c-bef4da826e1e",
   "metadata": {},
   "source": [
    "- - -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
