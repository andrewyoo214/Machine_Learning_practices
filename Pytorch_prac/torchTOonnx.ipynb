{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e15e8ff-455c-4e3e-b120-95855443c40c",
   "metadata": {},
   "source": [
    "# PyTorch model to onnx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0197a7b0-7f96-4f4f-8247-482a4120ee74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5e798a4-08cb-46bf-b36f-5c03c1d9d55a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7404bcc2-d2b6-4274-8c28-f429d6c13333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce04b482-1594-4aab-a628-6fbf159afbd7",
   "metadata": {},
   "source": [
    "## Training dataset load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d2e5c-609f-4f74-85c6-503be28eb886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b9ca7e-7f2a-41d3-a1dc-380a10b4e2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert images to Tensor ( Channel X Height X Width)\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.4911, 0.4820, 0.4467),(0.2022, 0.1993, 0.2009))\n",
    "                             ]) \n",
    "                            \n",
    "\n",
    "# Download training data\n",
    "train=torchvision.datasets.CIFAR100(root='./data',train=True,download=True,transform=transform)\n",
    "\n",
    "# Download test data                             \n",
    "test = torchvision.datasets.CIFAR100(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "# Define validation ratio \n",
    "validation_ratio= 0.2\n",
    "batch_size = 32\n",
    "train_data,validation_data=torch.utils.data.random_split(train,[int((1-validation_ratio)*len(train)), int((validation_ratio)*len(train))])\n",
    "print(len(train_data))\n",
    "print(len(validation_data))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size,pin_memory=True)\n",
    "val_loader = DataLoader(validation_data, batch_size,pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test,batch_size=100,shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f50410c-b9dd-45b0-bdaf-775cfeaed33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3fc8aae-8523-4513-900f-b50222414a87",
   "metadata": {},
   "source": [
    "## Device check and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4259694-1cb1-481a-963a-abd4553d768a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if your system has cuda gpu or only cpu\n",
    "\n",
    "def check_device():\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "# Function to transfer from CPU to GPU\n",
    "def move_device(tensor, device):\n",
    "    \n",
    "    # Move all individual tensors from cpu to gpu\n",
    "    if isinstance(tensor, (list,tuple)):\n",
    "        return [move_device(element, device) for element in tensor]\n",
    "    return tensor.to(device, non_blocking=True) \n",
    "\n",
    "# Execute transfer from CPU to GPU for each device\n",
    "class DeviceDataLoader():\n",
    "    \n",
    "    # Define Constructor\n",
    "    def __init__(self, dataloader, device):\n",
    "        self.dl = dataloader\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \n",
    "       # Transfer each batch and return\n",
    "        for i in self.dl: \n",
    "            yield move_device(i, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        # Return the number of batches\n",
    "        return len(self.dl)\n",
    "\n",
    "\n",
    "device = check_device()\n",
    "\n",
    "# Move all the tensors to GPU\n",
    "train_dl = DeviceDataLoader(train_loader, device)\n",
    "valid_dl = DeviceDataLoader(val_loader, device)\n",
    "test_dl = DeviceDataLoader(test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d74d51-d959-4e87-86a1-ec8b4e39e84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cf070c-5fe0-44fd-9c13-71f2fbc4e7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class convnet_no_dropout(nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self):\n",
    "        super(convnet_no_dropout, self).__init__()\n",
    "        '''\n",
    "         Convolutional layers\n",
    "         Conv2d (input channels, output channels, kernel_size, padding) \n",
    "\n",
    "        Each Sequential layer has :\n",
    "              1. A Convolutional Layer\n",
    "              2. Relu activation function\n",
    "              3. Maxpool layer\n",
    "        '''\n",
    "\n",
    "        self.conv_layer_1 = torch.nn.Sequential(\n",
    "            # Convoolutional layer\n",
    "            nn.Conv2d(in_channels=3, out_channels=16,kernel_size= 3,stride=1, padding=1),\n",
    "            \n",
    "            # Activation function\n",
    "            nn.ReLU(),\n",
    "\n",
    "            # Max pooling layer\n",
    "            torch.nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32,kernel_size= 3,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.conv_layer_3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64,kernel_size= 3,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128,kernel_size= 3,stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "    \n",
    "        \n",
    "        # Fully Connected layers\n",
    "        self.hidden_layer = nn.Linear(128*2*2, 206)\n",
    "        self.output_layer = nn.Linear(206, 100)\n",
    "        \n",
    "    def forward(self, ip):\n",
    "\n",
    "        # Calling all the convolutional layers\n",
    "        output = self.conv_layer_1(ip)\n",
    "        output = self.conv_layer_2(output)\n",
    "        output = self.conv_layer_3(output)\n",
    "        output = self.conv_layer_4(output)\n",
    "        \n",
    "        # Flattening \n",
    "        output = output.view(-1, 128*2*2)\n",
    "        \n",
    "        # Call fully connected layer\n",
    "        output = self.hidden_layer(output)\n",
    "        \n",
    "        output=self.output_layer(output)\n",
    "   \n",
    "        return output\n",
    "\n",
    "model1 = convnet_no_dropout()\n",
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f3697-f04b-46fb-adae-379778bc9664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad0150-2d76-47db-acb7-738ac1360df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def accuracy(predicted,labels):\n",
    "    pred, predclassid=torch.max(predicted,dim=1)\n",
    "    return torch.tensor(torch.sum(predclassid==labels).item()/len(predicted))\n",
    "\n",
    "\n",
    "def evaluate(model1,dl,loss_func):\n",
    "    model1.eval()\n",
    "    batch_losses, batch_accs=[],[]\n",
    "    for images,labels in valid_dl:\n",
    "        #start loop\n",
    "        with torch.no_grad():\n",
    "            predicted=model1(images)\n",
    "        batch_losses.append(loss_func(predicted,labels))\n",
    "        batch_accs.append(accuracy(predicted,labels))\n",
    "    epoch_avg_loss=torch.stack(batch_losses).mean().item()\n",
    "    epoch_avg_acc=torch.stack(batch_accs).mean().item()\n",
    "    return epoch_avg_loss,epoch_avg_acc\n",
    "\n",
    "def train(model1,train_dl,valid_dl,epochs, max_lr, loss_func,optim):\n",
    "    \n",
    "    # Normal optimizer\n",
    "    #optimizer=optim(model1.parameters(), max_lr)\n",
    "    \n",
    "    # Applying L2 Regularization\n",
    "    #optimizer=optim(model1.parameters(), max_lr,weight_decay=1e-5)\n",
    "    \n",
    "    # For SGD\n",
    "    optimizer=optim(model1.parameters(), max_lr, momentum=0.9,weight_decay=1e-5)\n",
    "    \n",
    "    '''\n",
    "    Learning Rate Scheduler\n",
    "    '''\n",
    "    scheduler=torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr,epochs*len(train_dl))\n",
    "#     scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=5,verbose=True)\n",
    "#     scheduler=torch.optim.lr_scheduler.ExponentialLR(optimizer,  gamma=0.9)\n",
    "    \n",
    "    results=[]\n",
    "    for epoch in range(epochs):\n",
    "        model1.train()\n",
    "        train_losses=[]\n",
    "        train_batch_accs=[]\n",
    "        lrs=[]\n",
    "\n",
    "        for images, labels in train_dl:\n",
    "            predicted=model1(images)\n",
    "            loss=loss_func(predicted,labels)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "          # keep track of learning rate\n",
    "            lrs.append(optimizer.param_groups[0]['lr'])\n",
    "            train_batch_accs.append(accuracy(predicted,labels))\n",
    "    \n",
    "        scheduler.step()\n",
    "        epoch_train_acc=torch.stack(train_batch_accs).mean().item()\n",
    "        epoch_train_loss=torch.stack(train_losses).mean().item()\n",
    "        epoch_avg_loss,epoch_avg_acc=evaluate(model1,valid_dl,loss_func)\n",
    "        \n",
    "        results.append({'avg_valid_loss': epoch_avg_loss,\n",
    "                        'avg_val_acc': epoch_avg_acc,\n",
    "                        'avg_train_loss':epoch_train_loss,\n",
    "                        'avg_train_acc':epoch_train_acc,\n",
    "                        'lrs':lrs})\n",
    "        \n",
    "        print('Number of epochs:', epoch,'|', \n",
    "              'Validation loss :',epoch_avg_loss, ' |','Training loss :'\n",
    "              ,epoch_train_loss,' |  '\n",
    "              ,'Training accuracy:', epoch_train_acc\n",
    "              , 'validation accuracy :',epoch_avg_acc)\n",
    "    return results\n",
    "\n",
    "\n",
    "model1=move_device(model1,device)\n",
    "epochs = 5\n",
    "\n",
    "'''\n",
    "Learning Rates\n",
    "'''\n",
    "max_lr1 = 1e-1\n",
    "max_lr2 = 1e-2\n",
    "max_lr3 = 1e-3\n",
    "max_lr4 = 1e-4\n",
    "\n",
    "loss_func=nn.functional.cross_entropy\n",
    "\n",
    "'''\n",
    "Optimizers\n",
    "'''\n",
    "#optim=torch.optim.Adam\n",
    "optim=torch.optim.SGD\n",
    "\n",
    "'''\n",
    "Train function call\n",
    "'''\n",
    "results1= train(model1,train_dl,valid_dl,epochs, max_lr1, loss_func,optim)\n",
    "results2= train(model1,train_dl,valid_dl,epochs, max_lr2, loss_func,optim)\n",
    "results3= train(model1,train_dl,valid_dl,epochs, max_lr3, loss_func,optim)\n",
    "results4= train(model1,train_dl,valid_dl,epochs, max_lr4, loss_func,optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d1a73-a334-482a-88b3-5353eb847c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20da07-a13a-44a1-b93c-17192c296f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f95f0d-ca0d-4c3c-b5d5-a99a4ae0cd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b35546-d878-49dd-b8ba-d7f1300f130e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_model = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ebcd6-c0ae-4463-8ef3-d3696d3817cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae63c7b-a2e4-4fb3-a01b-639c9ad6b2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model1, \"E:/RESEARCH/torch_cifar100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab74a9-7f48-40f1-a0c2-1a59604adb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5292112c-75c5-4534-91fd-bc97fa14dd91",
   "metadata": {},
   "source": [
    "## Convert the model into onnx format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10a1a2-6df4-4601-9fee-6e4c0df4b675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b89b726-59fc-4135-8f80-2c18e5647791",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(16, 3, 3, 3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf851ef-6cfd-433a-a9dd-d6676347e371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37040a23-7793-4d5c-8dfb-f0996279f6ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c02c6d-0618-4dde-9e5b-0f3a8b5d325a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294d07c-6f1b-42d0-9805-144d6f4186e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2049ed61-b3dc-49ac-b7fa-b943f1884d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77a85bc-eb89-4d6f-bee6-cc60da7ae2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(torch_model, \n",
    "                  x,                          #모델 입력값(튜플 또는 여러 입력값들도 가능)\n",
    "                  f = \"E:/RESEARCH/torch_onnx.onnx\", #실행될 모델, 모델저장경로\n",
    "                  export_params = True,       #모델 파일 안에 학습된 모델 가중치를 저장할지의 여부\n",
    "                  opset_version = 10,         #모델을 변환할 때 사용할 ONNX의 버전\n",
    "                  do_constant_folding = True, #최적화시 상수폴딩을 사용할지의 여부\n",
    "                  input_names = ['input'],    #모델의 입력값을 가리키는 이름\n",
    "                  output_names = ['output'],  #모델의 출력값을 가리키는 이름\n",
    "                  dynamic_axes = {'input' : {0 : 'batch_size'}, 'output' : {0 : 'batch_size'}}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de536b-f05b-499d-ad03-dfbc44489c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51c183-30b2-4a38-90bd-6831eaf8745f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf844b2-6819-4426-8c0f-5ec0a1a9f73c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038a6098-abea-4adb-850e-a55db6ffb8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf09e08-a75f-4874-892a-a9c5398f7319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d922513-bae4-4cab-8fe4-d6c58cffd467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563489e-f7da-4c76-ab53-abfa3e92c49a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "649c23b8-1638-4146-bde8-151209837fd9",
   "metadata": {},
   "source": [
    "# Is this really working?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2153e8cf-031f-4c60-86c0-a6afabfd6880",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "# import onnx_tf\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98af6ea6-4ceb-48aa-8f62-46e74c9576ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(10, 3, 224, 224, device='cuda')\n",
    "model = torchvision.models.alexnet(pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff3755-6bd5-4a7b-8f2d-4f6debbe850c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec2f74-ca1d-4405-9023-04f776525c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3620d111-67c5-4d13-94a8-3e6a020f1660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\n",
    "output_names = [ \"output1\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593c3df5-e58d-4135-871d-274d773c2b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.onnx.export(model, dummy_input, \"E:/RESEARCH/alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8b2ea-5040-4f83-a75e-8423012ac991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070289e0-3dd9-490a-8fff-c7c326bbb103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "# onnx_model = onnx.load(\"E:/RESEARCH/alexnet.onnx\")\n",
    "onnx_model = onnx.load(\"E:/RESEARCH/YOLOtiny.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(onnx_model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bbd3bc-75e7-420e-8ae7-1b14d2d13c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e7b30-c288-42a4-8895-165d225bd6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0448dc9-39b6-449a-a37a-2552139c1427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb302da9-5d1c-4011-9214-5144df9ba75b",
   "metadata": {},
   "source": [
    "## Onnx to torch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfaa362-cbf1-4431-b8b2-ce94460adb94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from onnx2torch import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f86b7-9a5e-4994-ab86-f70f482fc1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ac11e7-1e54-4889-a493-ea135b9f63a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebf6fab-c4ec-4cd8-9c24-77c1f214d722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c3a66-55ca-42ad-98e3-68fb358902c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2b9fe7-23ec-44b9-8084-6df589496dae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f19217-26d3-4b3b-a73e-a53e1c255173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e98383-6b6f-4909-b980-27e2606fc582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a570d0-1534-436d-a810-65a26ad400fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa657fac-a4da-4452-b68a-769b989d9513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad03b9e-349f-401b-bc83-d2cc72a1fd14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cd84e0-fac3-4acd-b132-92142af91a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4aca6-406d-4213-b6ac-3f6738093cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811985d-7c82-4e57-9d10-8359ee1c873e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d047a1f-d80c-4b76-824e-9ef29cadd9ba",
   "metadata": {},
   "source": [
    "# Implementation Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca556786-46c9-4d81-860a-045b888ed3bb",
   "metadata": {},
   "source": [
    "* ML model을 바로 tflite 모델로 추출하려면 tflite-model-maker 필요한데 사실상 사용이 불가능.\n",
    "* 결국 우회루트 및 확장성을 위해서 ML model(Tensorflow, PyTorch) -> onnx -> tflite 로 거쳐서 가야함.\n",
    "* 우선 tensor Keras model에서 onnx 로 가는 \"keras2onnx\" 라이브러리는 환경이 구데기. (python 3.5-3.8, tensorflow 1.x/2.0-2.2 가능)\n",
    "* 시도하다가 결국 PyTorch model -> onnx -> tflite 로 가는 방법을 선택.\n",
    "* PyTorch model 짜고 학습하고 onnx 파일로 추출하는것 까지는 얼추 가능함.\n",
    "* 근데 또 onnx -> tflite 로 가려고 하니 onnx-tf 를 사용해야 하기에 tensorflow 설치 (참고로 tensorflow>=2.8.0 가능)\n",
    "* 이번에는 protobuf 를 3.20.0 이하로 낮추라고 함. 그래서 protobuf==3.19.0 으로 낮춰서 설치.\n",
    "* 그랬더니 또 onnx 가 protobuf>=3.20.2 의 환경을 갖추어야 한다고 함. + tensorboard2.9.1 이 환경이 안맞다고 한다.\n",
    "* 검색해보니 pytorch 버전을 낮추면 될 수 도 있다는 글도 있고..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1993af58-9c65-4fd6-85a5-25e310966476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e338165d-11e2-4b77-8e14-3869a56eec28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd6fe52-55b4-4851-8731-89fc8e28efc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d1e65f-ade7-45e3-ab0f-ad60b9bbd9a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de393d6-4619-49ca-bfe7-2b05efa011af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2e073-25c5-435b-a332-5d1869f2f22e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0458c-3312-469f-b374-ce0a1ca30e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
