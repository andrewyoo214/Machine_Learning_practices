{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29ae7307-c70b-44b4-9991-b17578f4ef7d",
   "metadata": {},
   "source": [
    "# TFLITE generation for unity application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba4fdb-dfbe-44ec-8b32-7b3e7e2002ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49efc87b-a63f-45d0-a861-47bc8ed20f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "from keras.datasets import cifar10\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668deb6e-da72-4671-8c80-c4a5b611f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5304e7d8-990f-4c82-89c9-ebffb08ea609",
   "metadata": {},
   "source": [
    "* Device check (whether using cpu or gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c9ef6-27da-4aaf-9346-c58078687be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32f0a6-eadb-45e1-85e8-5ceb85c36ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# print(gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6baed-03af-4dc8-a8cb-9b5a8b7dd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399f969e-df05-452b-b626-0c25bf7e159c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7332409-7d9c-4309-adcd-3a161ce2f197",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c6f64-b894-4ab3-8e28-da632381c12e",
   "metadata": {},
   "source": [
    "## Current Project summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792af0f-6af5-4803-a3e7-0c027bf84163",
   "metadata": {},
   "source": [
    "* current model is coco_ssd_mobilenet\n",
    "* (https://github.com/asus4/tf-lite-unity-sample)\n",
    "* It follows object detection supported from tensorflow\n",
    "* (https://www.tensorflow.org/lite/models/object_detection/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d695a-363f-44f0-8936-4b263845afb6",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4055a8b2-1274-4b54-a60b-a292b5db85fa",
   "metadata": {},
   "source": [
    "## Training dataset load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3b9f8b-56a1-469f-b351-715e2bbb334f",
   "metadata": {},
   "source": [
    "* Here, we are going to use CIFAR-10 dataset for simple testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9c741a-46ba-4be4-acdf-929417647a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542befab-e01a-4794-ad88-d8905702d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the dimensions of the datasets\n",
    "\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f244f-4311-45ef-84a7-140fe1637f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "# x_train=x_train / 255.0\n",
    "# x_test=x_test / 255.0\n",
    "\n",
    "x_train=x_train.astype(np.float32) / 255.0\n",
    "x_test=x_test.astype(np.float32) / 255.0\n",
    "\n",
    "#One hot encoding\n",
    "y_train_cat=to_categorical(y_train,10)\n",
    "y_test_cat=to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad83d7-f157-4957-96bc-ab3966777c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualization for sample training dataset image\n",
    "# img = plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675da35-2289-4538-94fb-e5f1cfcdc11b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7ced2-9613-480f-ab54-1493687d0be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5e8c7c7-1c6b-4289-aab8-c35ec6cfa815",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6976ef-2354-4945-947b-a3aa8db581d3",
   "metadata": {},
   "source": [
    "## Prepare the detection model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c8524-6e9a-42f0-8664-352cbb79f5cc",
   "metadata": {},
   "source": [
    "* Here, we try transfer learning, starting from pre-trained model \"MobileNetV2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03769387-62d9-43d8-84c7-8c3563776c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing original MobileNetV2 model\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ead97c-d3a2-4504-a1c3-bdbc7601ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reorganizing the MobileNetV2 model for our own custom dataset\n",
    "## and be ready for the transfer learning\n",
    "\n",
    "# base_model = MobileNetV2(weights='imagenet') ## loading original MobileNetV2 model(input size is 224x224x3)\n",
    "\n",
    "base_model = MobileNetV2(\n",
    "    input_shape = (32,32,3),         # input image resolution\n",
    "    alpha = 1.0,                     # float, larger than zero, controls the width of the network\n",
    "    include_top = False,             # whether to include the fully-connected layer at the top of the network.\n",
    "    weights= 'imagenet',             # None(random initialization), 'imagenet'(pre-training of ImageNet) or the path to the weights\n",
    "    input_tensor = None,             # optional keras tensor to use as image input\n",
    "    pooling = None,                  # optional pooling mode for feature extraction (None, avg, max)\n",
    "    # classes = y_train.shape[1],      # integer number of classes to classify images into\n",
    "    # classifier_activation='softmax'  # activation function to use on the \"top\" layer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee32c16b-eba1-4353-ba36-f263d87f7ab2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Check the overall architecture of the base model(mobilenetv2)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb9560-9d76-4c0b-92d7-c69dbf518263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding layers to base model of MobileNet\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Creating base layer\n",
    "model.add(base_model)\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "\n",
    "#Adding the Dense Layers and Dropout\n",
    "model.add(Dense(512,activation=('relu'))) \n",
    "model.add(Dense(256,activation=('relu'))) \n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation=('relu')))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation=('softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7baf7a-ab52-47e0-9c8f-254cf9500d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1b89f-267c-470b-8a6e-e42cd99a97de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling Model using SGD \n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d7bfb8-9765-4e11-b761-3acd376cc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting my own Callback system\n",
    "## Adjusting EarlyStopping supported by keras\n",
    "AndrewCallback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',           # quantity to be monitored\n",
    "    # min_delta=0,                  # minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=5,                   # number of epochs with no improvement\n",
    "    verbose=1,                    # 0 is silent, 1 displays messages\n",
    "    mode='auto',                  # auto / min: will stop monitored has stopped decreasing / max: stop when monitored has stopped increasing\n",
    "    # baseline=None,                # baseline value\n",
    "    restore_best_weights=True,    # whether to restore model weights from the epoch with the best value of the monitored quantity\n",
    "    # start_from_epoch=0            # numberof epochs to wait before starting to monitor improvement\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecfb8c-f424-4bd0-b19d-7808db7a60bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Training Model\n",
    "with tf.device('/device:GPU:0'):\n",
    "    hist = model.fit(x_train, y_train_cat,      # x, y dataset for model training\n",
    "                     batch_size = 100,          # model training batch size\n",
    "                     epochs = 20,               # model training epochs\n",
    "                     validation_split = 0.1,    # setting validation ratio\n",
    "                     # callbacks= AndrewCallback  # callback settings (for early stopping, ...)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89551648-486c-4725-8032-688dd2c710f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706c2c5-4e73-49b4-8b9e-c098d5b5354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing accuracy of trained model\n",
    "with tf.device('/device:GPU:0'):\n",
    "    model.evaluate(x_test, y_test_cat)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683c384-2bdf-4719-88f2-dcbc4ba165b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizing Model Accuracy\n",
    "fig = plt.figure(figsize=(4,3))\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train', 'Val'], loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7c0b37-eaa6-4808-9600-c1cc40d93741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f3233-f501-482e-b953-252766c34ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed631f9e-16e5-47e4-a622-87235513bda5",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48311314-f806-4af1-a4cb-5b0f79d2eb8a",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc491f3b-17e0-4fe9-99b8-317ef60405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check the current model path (where pb file saved)\n",
    "model.save('C:/Users/user/Jupyter/ML_practices/Tensorflow_prac/SSD_object_detection/retrained_model') #path and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c396275-35b0-4329-b4e6-ed48ab343de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca0f25-d560-4679-ad65-f0972662bc9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b790e5a2-b09a-4882-b329-880bfab28ffc",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367728f-b471-4d09-9ead-5691642b1e19",
   "metadata": {},
   "source": [
    "## Converting the pb model into tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2e9e5-5a33-4b9c-88fa-c73781bf9985",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load pb model\n",
    "model_path = 'C:/Users/user/Jupyter/ML_practices/Tensorflow_prac/SSD_object_detection/retrained_model/'\n",
    "saved_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481061d-2c65-41e7-a9c8-76a646c94c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62270334-d42e-4290-b826-a1a27ffc8acc",
   "metadata": {},
   "source": [
    "* Setting the converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f7c681-3a60-4986-b490-32c8f81a5d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def representative_data_gen():\n",
    "#     for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "#         yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47191da2-a4ee-4793-b46c-5c2a31e45107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 32, 32, 3)\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1d58e-6ac4-49e6-9093-0161a8ccdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for image in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "        yield [image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7253c20b-4ae2-4e86-b524-bf842801cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converter without using representative_dataset(simple)\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model(model_path) # path to the SavedModel directory\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "## Converter using representative_dataset\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path) # path to the SavedModel directory\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b15065-ec0c-4ecf-9fcf-f969e7d18e00",
   "metadata": {},
   "source": [
    "* Convert the saved pb model into tflite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42928b9-c6e8-4b84-97dc-ca4f4ee3d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d2593e-8d54-4dba-a114-a57855f0e5b6",
   "metadata": {},
   "source": [
    "* Save the tflite model into the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37d466-53d3-4eff-8b6f-2ce61b776960",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('C:/Users/user/Jupyter/ML_practices/Tensorflow_prac/SSD_object_detection/retrained_model/coco_ssd_mobilenet_quant.tflite', \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a230cd3-b3d6-45eb-accb-ed1fbcfffb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2227613a-73f6-4641-9b02-263179b8fe60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072ee68-b732-4cb8-ae7f-d4fd14aef8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e58bb6d7-dbce-4963-9c46-2c553199a804",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6a4e6-c2d8-4c0c-96ad-73a2d241123b",
   "metadata": {},
   "source": [
    "# Testing current model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f781982-6dae-445e-ab43-a4ee3ba18c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_model_path = 'C:/Users/user/Jupyter/ML_practices/Tensorflow_prac/SSD_object_detection/retrained_model/coco_ssd_mobilenet_quant.tflite'\n",
    "current_model_path = 'C:/Users/user/Jupyter/ML_practices/Tensorflow_prac/SSD_object_detection/retrained_model/original/ssd_original.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30778b08-9b8e-4140-8b2f-beabbeb8822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=current_model_path) ## loading current model(coco_ssd_mobilenet)\n",
    "interpreter.allocate_tensors() ## tensor initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f223d-83aa-4c1b-bf69-07a4c0d46c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16457a6d-13f0-4122-a161-1b9a2cda0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f4882d-22d6-4db5-bd24-89010892ed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea859af5-92bb-47e1-9cfa-e11eaffa7cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841542f8-64bf-42a7-ab4a-78bac231a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a5ddc-0731-45f8-8292-672310ed913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac326b5-fed4-4d31-aaec-ea0d664c89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece078d-0537-4049-80c5-600ca088e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83af8b-7c61-4302-9874-30aff13be4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b4527-21b9-429d-a5b8-affb17941b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9fc79-8bc7-430c-97d1-71426436c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a0f05b-9355-4644-8f90-cee0c0ba8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b866821-62fd-4e52-8a56-9e545198fc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedaa00-39df-4b57-bc15-80f01b43c375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02fc155-e698-4238-8889-caa0a7a3b5a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3302cd97-3825-4c85-9305-988ba6817688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca707c4-1e15-4946-88e2-42039e872fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96bf993-333b-4173-a65a-96bc3726c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.lite.experimental.Analyzer.analyze(model_content=interpreter, gpu_compatibility=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7cd6df-5194-47d4-bfde-28aea8572eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534385e-fdb5-48bd-b250-7a765cc2a276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bc30b4-6ec4-450d-9374-b68e8767a61f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33d35e-db78-4839-a390-08754a3a132c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68d9c1-280e-4522-b4cf-1c2320eb46fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
