{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d4e5207-0824-4a98-b491-5bbf29e9bd4f",
   "metadata": {},
   "source": [
    "## TFLITE TRIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0864754-1ad0-407a-8422-2e4ef167662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d7fcd-0690-4462-bc4f-ea2a8cb5f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten,Dense,BatchNormalization,Activation,Dropout\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891cc67-2fed-47e5-bb05-13f627e0c9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4d46e7-c7f7-49e3-804e-2022ffc105e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current tensorflow version:\", tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885a31e1-fa33-4523-b3ba-6567738b8e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b2739-8355-4411-9514-573d5d0b2d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = 'E:/ssd_model_temp/saved_model.pb'\n",
    "model_path = 'E:/ssd_model_temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab63069-f3b6-441b-a649-0f32fabe76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssd_model = tf.saved_model.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5279406-fb99-4ec1-8c6c-ed095b8d8768",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1421b7-af3d-4b41-bb14-278fb8d07506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1422978-b95e-4469-b4df-dc3044406292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ffdcc5d-5cf4-4c1c-92c5-7cc8b1c1a7da",
   "metadata": {},
   "source": [
    "## Re-training the model with other dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4882b893-d081-4eaa-bbc8-9824110a5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e6b03-171c-49db-8f56-66de2195c4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c14203-a230-45da-b321-f884baa5cf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the dimensions of the datasets to make sure everything's kosher\n",
    "\n",
    "print((x_train.shape,y_train.shape))\n",
    "print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5f859-1d19-4fc2-89b8-998517da127e",
   "metadata": {},
   "source": [
    "* One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f80fc-6531-4431-899b-69c1d80053f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train / 255.0\n",
    "x_test=x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc36b6-7a76-4ec8-920c-b23256c471b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "x_train=x_train.astype(np.float32) / 255.0\n",
    "x_test=x_test.astype(np.float32) / 255.0\n",
    "\n",
    "#One hot encoding\n",
    "y_train_cat=to_categorical(y_train,10)\n",
    "y_test_cat=to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20de02e3-e691-4de6-b056-8536985a7268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c2f8ca-cd50-4e15-b0c6-c612dd765ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fa8bf8c-74f7-4b2d-be6b-7c0dfe802f15",
   "metadata": {},
   "source": [
    "## Importing MobilenetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cc3ad-bde7-4099-be57-4a15db07be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e91e3-c90e-41c1-8e3a-4a1d5b9ee067",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(input_shape=(32,32,3), \n",
    "                    include_top = False,\n",
    "                    weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabca586-77d5-400a-bbe2-84f2deb339e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91098b3-9c08-487a-93d2-088b9354ef6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b59d55f-f162-44b2-b87c-4236abf87639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23087aef-962b-418e-990b-48614e79c2a8",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c631cf-886e-4969-a45e-dc73cd747b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e44c1f-dac5-4c2e-9175-2e473fe351c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce790167-7f5e-4208-8918-034d2513e89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa80b9c4-c19d-460e-a463-98521042e6b5",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6cee8c-b7e2-44bc-af4b-139dd04f36bb",
   "metadata": {},
   "source": [
    "## SSD_NOTEBOOK from tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed57019-e458-4cda-b125-582bebc41219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc56e0c-9186-41ca-8f3a-6b0c2ca9ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a5caa-5bb2-413f-8bce-a83c0a2278d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba34f0-8e29-4447-ab56-53653fe9c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import ssd_vgg_300, ssd_common, np_methods\n",
    "from preprocessing import ssd_vgg_preprocessing\n",
    "from notebooks import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fc42a-de1e-4ace-9dac-490cbbe6aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow session: grow memory when needed. TF, DO NOT USE ALL MY GPU MEMORY!!!\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)\n",
    "isess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81270f-2f2c-48cb-897a-2f3cce28b83c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5adc7a-f14d-4d54-882b-702e20d6f38f",
   "metadata": {},
   "source": [
    "### SSD 300 MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045a31a9-b5d4-4fff-8074-c0d2a09cea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placeholder.\n",
    "net_shape = (300, 300)\n",
    "data_format = 'NHWC'\n",
    "img_input = tf.placeholder(tf.uint8, shape=(None, None, 3))\n",
    "# Evaluation pre-processing: resize to SSD net shape.\n",
    "image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(\n",
    "    img_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)\n",
    "image_4d = tf.expand_dims(image_pre, 0)\n",
    "\n",
    "# Define the SSD model.\n",
    "reuse = True if 'ssd_net' in locals() else None\n",
    "ssd_net = ssd_vgg_300.SSDNet()\n",
    "with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):\n",
    "    predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)\n",
    "\n",
    "# Restore SSD model.\n",
    "ckpt_filename = '../checkpoints/ssd_300_vgg.ckpt'\n",
    "# ckpt_filename = '../checkpoints/VGG_VOC0712_SSD_300x300_ft_iter_120000.ckpt'\n",
    "isess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(isess, ckpt_filename)\n",
    "\n",
    "# SSD default anchor boxes.\n",
    "ssd_anchors = ssd_net.anchors(net_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81482468-dc32-46b8-9627-c9fbc3f62914",
   "metadata": {},
   "source": [
    "### Post-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94957d9d-e4f5-43b6-87e2-5ea7b8b18b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main image processing routine.\n",
    "def process_image(img, select_threshold=0.5, nms_threshold=.45, net_shape=(300, 300)):\n",
    "    # Run SSD network.\n",
    "    rimg, rpredictions, rlocalisations, rbbox_img = isess.run([image_4d, predictions, localisations, bbox_img],\n",
    "                                                              feed_dict={img_input: img})\n",
    "    \n",
    "    # Get classes and bboxes from the net outputs.\n",
    "    rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(\n",
    "            rpredictions, rlocalisations, ssd_anchors,\n",
    "            select_threshold=select_threshold, img_shape=net_shape, num_classes=21, decode=True)\n",
    "    \n",
    "    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)\n",
    "    rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)\n",
    "    # Resize bboxes to original image shape. Note: useless for Resize.WARP!\n",
    "    rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)\n",
    "    return rclasses, rscores, rbboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9087b42f-73ff-4f88-a2ed-643165d5ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some demo image and visualize output.\n",
    "path = '../demo/'\n",
    "image_names = sorted(os.listdir(path))\n",
    "\n",
    "img = mpimg.imread(path + image_names[-5])\n",
    "rclasses, rscores, rbboxes =  process_image(img)\n",
    "\n",
    "# visualization.bboxes_draw_on_img(img, rclasses, rscores, rbboxes, visualization.colors_plasma)\n",
    "visualization.plt_bboxes(img, rclasses, rscores, rbboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3e281d-9f0c-4605-a6e3-d21971a78f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc1484a-7b37-4c04-8a0f-179eaa676917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d01f92-2aa8-425a-89a1-9160ffc4b6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9f6db9-22fe-4933-9687-7bb9ca2c9060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8043a40-f675-4ff4-941f-f48d25a6efb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "321651bc-c0d8-45d8-b8de-dc3f2b61e1cd",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8356046-48e4-4468-9c2a-7de8a5a7f9a7",
   "metadata": {},
   "source": [
    "## Converting the pb model into tflite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf7c54-d0ea-4482-a803-15c56ed0312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in tf.data.Dataset.from_tensor_slices(x_train).batch(1).take(100):\n",
    "        yield [input_value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db241593-c945-4eed-8085-fb4fc41d5f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_path) # path to the SavedModel directory\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4701bc-131b-4f61-84cc-e7b471742d9f",
   "metadata": {},
   "source": [
    "* Convert the saved model into tflite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20eea0b-ac00-4b3d-a387-c45dbeb68cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_quant = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d62efed-71bf-4fec-9fa9-3d106ac57c10",
   "metadata": {},
   "source": [
    "* Save the tflite model into the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dabd08-764c-4ee9-bc71-cc1cdc2e7052",
   "metadata": {},
   "outputs": [],
   "source": [
    "open('E:/ssd_model_temp/ssd_model.tflite', \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79121b4-9d4c-4662-a901-25b336d93691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe42aad2-6874-402c-9108-2b8c46765f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c04aa6-bb87-4e75-a6ff-aade18f8922f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
