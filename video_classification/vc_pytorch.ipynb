{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aecd52dc-3d90-4c92-b374-6c8b2f09d9af",
   "metadata": {},
   "source": [
    "# Video Classification with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db17dcd-7ea2-493b-aec9-d8472ebb1abd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. PyTorch 3D RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0f20188-ce06-43ac-b19b-b53a8c56d010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required components \n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9defd4af-ebbe-4344-b443-fa29b971967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing remaining components\n",
    "import json\n",
    "import urllib\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    ")\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15474af7-9d3f-4ce1-b580-c429de5324e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\facebookresearch_pytorchvideo_master\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOW_8x8_R50.pyth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\SLOW_8x8_R50.pyth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61ce70186684decaca42f358dfb8707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose the `slow_r50` pretrained model - for our video classification model training \n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'slow_r50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b3e29f-9109-4efd-a9bb-4dae93f4d5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE setup - Set the model to eval mode and move to desired device.\n",
    "# Set to GPU or CPU\n",
    "\n",
    "device = \"cpu\"\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9553cb5a-f2bc-4bc1-bbc1-41b60f80ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download the id to label mapping for the Kinetics 400 dataset on which the torch hub models were trained. \n",
    "#This will be used to get the category label names from the predicted class ids.\n",
    "\n",
    "json_url = \"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\"\n",
    "json_filename = \"kinetics_classnames.json\"\n",
    "try: urllib.URLopener().retrieve(json_url, json_filename)\n",
    "except: urllib.request.urlretrieve(json_url, json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1e2a8a6-6198-4f3e-96ce-24e7a9797c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_filename, \"r\") as f:\n",
    "    kinetics_classnames = json.load(f)\n",
    "\n",
    "# Create an id to label name mapping\n",
    "kinetics_id_to_classname = {}\n",
    "for k, v in kinetics_classnames.items():\n",
    "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6d027-f76a-4bab-a084-dd3890d2fd5f",
   "metadata": {},
   "source": [
    "* Input Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba436b4-032f-4091-a960-942d82439135",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "mean = [0.45, 0.45, 0.45]\n",
    "std = [0.225, 0.225, 0.225]\n",
    "crop_size = 256\n",
    "num_frames = 8\n",
    "sampling_rate = 8\n",
    "frames_per_second = 30\n",
    "\n",
    "# Note that this transform is specific to the slow_R50 model.\n",
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std),\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCropVideo(crop_size=(crop_size, crop_size))\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The duration of the input clip is also specific to the model.\n",
    "clip_duration = (num_frames * sampling_rate)/frames_per_second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f574d8-8854-4a21-a450-a0b861600692",
   "metadata": {},
   "source": [
    "* Loading video data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b530da-f207-465e-9d03-1fe026c3c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_link = \"https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\"\n",
    "video_path = 'archery.mp4'\n",
    "try: urllib.URLopener().retrieve(url_link, video_path)\n",
    "except: urllib.request.urlretrieve(url_link, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df94b3c-c1d8-4f41-9fe4-d59ba2849e1b",
   "metadata": {},
   "source": [
    "* Load the video and transform into input format (for the model training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60431d9e-7340-4821-82dd-9a78eefe41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An exception occurred in telemetry logging.Disabling telemetry to prevent further exceptions.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\iopath\\common\\file_io.py\", line 946, in __log_tmetry_keys\n",
      "    handler.log_event()\n",
      "  File \"C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\iopath\\common\\event_logger.py\", line 97, in log_event\n",
      "    del self._evt\n",
      "AttributeError: _evt\n"
     ]
    }
   ],
   "source": [
    "# Select the duration of the clip to load by specifying the start and end duration\n",
    "# The start_sec should correspond to where the action occurs in the video\n",
    "start_sec = 0\n",
    "end_sec = start_sec + clip_duration\n",
    "\n",
    "# Initialize an EncodedVideo helper class and load the video\n",
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "# Load the desired clip\n",
    "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "\n",
    "# Apply a transform to normalize the video input\n",
    "video_data = transform(video_data)\n",
    "\n",
    "# Move the inputs to the desired device\n",
    "inputs = video_data[\"video\"]\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6a356-4d20-47c8-890c-d463dae30c90",
   "metadata": {},
   "source": [
    "* Predictions on Video Clip. Output come with top 5 predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4295d9e6-3ba8-419f-be3c-c4fb90a85ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels: archery, throwing axe, playing paintball, stretching arm, riding or walking with horse\n"
     ]
    }
   ],
   "source": [
    "# Pass the input clip through the model\n",
    "preds = model(inputs[None, ...])\n",
    "\n",
    "# Get the predicted classes\n",
    "post_act = torch.nn.Softmax(dim=1)\n",
    "preds = post_act(preds)\n",
    "pred_classes = preds.topk(k=5).indices[0]\n",
    "\n",
    "# Map the predicted classes to the label names\n",
    "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]\n",
    "print(\"Top 5 predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c321ae3-74e7-4e4a-9133-fa2fe9e73a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "485cee6c-8ec0-4d67-9f9b-368eddbb534a",
   "metadata": {},
   "source": [
    "## 2. PyTorch - using pytorchvideo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306e624d-bbf4-46b6-9834-3eb0e8a76102",
   "metadata": {},
   "source": [
    "https://github.com/YuxinZhaozyx/pytorch-VideoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54801f60-9c9e-443c-bbb0-51ff80cdff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import PIL\n",
    "import collections\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aed5c7-2cad-4d70-906f-c5cdebe89461",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size = 2, shuffle = True)\n",
    "\n",
    "dataset = datasets.VideoDataset(\n",
    "\t\"./data/example_video_file.csv\",\n",
    "    transform=torchvision.transforms.Compose([\n",
    "        transforms.VideoFilePathToTensor(max_len=50, fps=10, padding_mode='last'),\n",
    "        transforms.VideoRandomCrop([512, 512]),\n",
    "        transforms.VideoResize([256, 256]),\n",
    "    ])\n",
    ")\n",
    "\n",
    "for videos in data_loader:\n",
    "    print(videos.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76c9e58-5cd6-4294-a126-0e76dddbc6b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775806a-ef7b-492d-a5cc-be0ba9a7abbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "885fb4b4-6a3d-479e-86c7-5c3cf7c42c8e",
   "metadata": {},
   "source": [
    "## VC Autism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa5f6f4-8206-4a0c-a164-f30bff3b2bbb",
   "metadata": {},
   "source": [
    "### Autism Non-Autism majore differences\n",
    "\n",
    "1. good eye contact\n",
    "2. sits relatively still"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a503c8-7a11-427c-a9ff-d09ffe0896ca",
   "metadata": {},
   "source": [
    "* image classification approach\n",
    "* Concept: train significant feature images of autism patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b1d5f5-ba52-46b4-9281-75506d5d28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "166ae84f-4c4b-4fa8-98f8-3fbc0904d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b4c36-f5e7-4515-b093-227aa9d1f765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f74db877-974d-4709-b879-9cffa34de45c",
   "metadata": {},
   "source": [
    "* Changing file names in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db7f858b-18d1-4925-9fed-42242362bae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"E:/RESEARCH/Datasets/VC/autism_test/val/nonautism\"\n",
    "file_names = os.listdir(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0533f26b-1577-4f38-8ab4-f726a9fe0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for name in file_names:\n",
    "    src = os.path.join(file_path, name)\n",
    "    dst = str(i) + '.png'\n",
    "    dst = os.path.join(file_path, dst)\n",
    "    os.rename(src, dst)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1affb307-e787-4329-b3b9-8b2669bee3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354d501-2ab8-48b9-8f10-d3f98f05da57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea2868d0-2c95-453a-ba08-8c935243fe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1eaa212d170>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=6\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    \n",
    "    num_channels=3\n",
    "    num_classes=50\n",
    "    verbose='store_true'\n",
    "    seed=712002\n",
    "\n",
    "args = Args()    \n",
    "\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15a2875c-cb83-4d33-b3b2-b6b0c993933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.7.1  Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "#Setting torch environment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "    \n",
    "print('Using PyTorch version:', torch.__version__, ' Device: ', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6388741e-cbec-438e-8b27-0315610f66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Transformation\n",
    "data_transforms = transforms.Compose([\n",
    "#     transforms.CenterCrop(1024),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomResizedCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "#     transforms.ColorJitter(contrast=(0.3, 1), saturation=(0.3, 1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456,0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "024ad5c2-7a7b-4001-b4b2-9892d25faa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading image data\n",
    "printer_data = datasets.ImageFolder(root = 'E:/RESEARCH/Datasets/VC/autism_test/train', transform = data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aea5710a-35c3-4750-919c-a24ec67464db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(printer_data))\n",
    "test_size = len(printer_data)-train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4877b02-a280-471f-9daa-56bc68e6754f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "17b8db0c-7369-4943-9b8b-968d9f77dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torch.utils.data.random_split(printer_data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddb45770-48f8-42ab-adf7-014abcddf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4e742b1-10f9-4b8d-be4f-169acc84e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af646223-dc73-4a8d-adbb-97d7e36f9129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ae951300-9507-4904-b5b6-d090c88900ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\efficientnet-b3-5fb5a3c3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a199741326b14622ac2a19f3917bd5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/47.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_eff3 = EfficientNet.from_pretrained('efficientnet-b3', num_classes=2)\n",
    "model = model_eff3.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8ec73-0a01-4300-acca-5abe560bbae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ce396-78c5-44ee-8754-17d53168692f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8671f1d-f31d-4c6c-8294-03daf219d2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac199f7d-d56e-4bd3-850a-dc3cccfc619b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNet(\n",
      "  (_conv_stem): Conv2dStaticSamePadding(\n",
      "    3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "  )\n",
      "  (_bn0): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_blocks): ModuleList(\n",
      "    (0): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        40, 40, kernel_size=(3, 3), stride=[1, 1], groups=40, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        40, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        10, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (1): MBConvBlock(\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (2): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (3): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (4): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (5): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (6): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (7): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        288, 288, kernel_size=(5, 5), stride=(1, 1), groups=288, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (8): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        288, 288, kernel_size=(3, 3), stride=[2, 2], groups=288, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(288, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        288, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        12, 288, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (9): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (10): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (11): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (12): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(3, 3), stride=(1, 1), groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (13): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        576, 576, kernel_size=(5, 5), stride=[1, 1], groups=576, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(576, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        576, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        24, 576, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (14): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (15): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (16): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (17): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=(1, 1), groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(136, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (18): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        816, 816, kernel_size=(5, 5), stride=[2, 2], groups=816, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(816, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        816, 34, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        34, 816, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (19): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (20): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (21): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (22): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (23): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(5, 5), stride=(1, 1), groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(232, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (24): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        1392, 1392, kernel_size=(3, 3), stride=[1, 1], groups=1392, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(1392, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        1392, 58, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        58, 1392, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "    (25): MBConvBlock(\n",
      "      (_expand_conv): Conv2dStaticSamePadding(\n",
      "        384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn0): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "        2304, 2304, kernel_size=(3, 3), stride=(1, 1), groups=2304, bias=False\n",
      "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "      )\n",
      "      (_bn1): BatchNorm2d(2304, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_se_reduce): Conv2dStaticSamePadding(\n",
      "        2304, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_se_expand): Conv2dStaticSamePadding(\n",
      "        96, 2304, kernel_size=(1, 1), stride=(1, 1)\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_project_conv): Conv2dStaticSamePadding(\n",
      "        2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (static_padding): Identity()\n",
      "      )\n",
      "      (_bn2): BatchNorm2d(384, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "      (_swish): MemoryEfficientSwish()\n",
      "    )\n",
      "  )\n",
      "  (_conv_head): Conv2dStaticSamePadding(\n",
      "    384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "    (static_padding): Identity()\n",
      "  )\n",
      "  (_bn1): BatchNorm2d(1536, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "  (_dropout): Dropout(p=0.3, inplace=False)\n",
      "  (_fc): Linear(in_features=1536, out_features=2, bias=True)\n",
      "  (_swish): MemoryEfficientSwish()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Setting Optimizer and Objective Function\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, total_steps=30, anneal_strategy='cos')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5c6bda3-fb69-43bb-babc-409b2422ae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during CNN model\n",
    "\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    print(optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
    "                epoch, batch_idx * len(image), \n",
    "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "\n",
    "    scheduler.step() #for learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d77eff1d-7246-4330-b87a-dd46773f574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for checking model performance during the learning process\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim = True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    \n",
    "    test_loss /= (len(test_loader)) \n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73b88658-1cfb-4d35-acb0-739391f40c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9999999999999996e-05\n",
      "Train Epoch: 1 [0/800 (0%)]\tTrain Loss: 0.728874\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.1940, \tTest Accuracy: 97.00 % \n",
      "\n",
      "7.653782439458233e-05\n",
      "Train Epoch: 2 [0/800 (0%)]\tTrain Loss: 0.223381\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0380, \tTest Accuracy: 99.00 % \n",
      "\n",
      "0.00018058874503045722\n",
      "Train Epoch: 3 [0/800 (0%)]\tTrain Loss: 0.042501\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0383, \tTest Accuracy: 99.50 % \n",
      "\n",
      "0.00033631195246475686\n",
      "Train Epoch: 4 [0/800 (0%)]\tTrain Loss: 0.057092\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0827, \tTest Accuracy: 98.50 % \n",
      "\n",
      "0.0005200000000000001\n",
      "Train Epoch: 5 [0/800 (0%)]\tTrain Loss: 0.181576\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.3405, \tTest Accuracy: 85.00 % \n",
      "\n",
      "0.0007036880475352432\n",
      "Train Epoch: 6 [0/800 (0%)]\tTrain Loss: 0.055214\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.1795, \tTest Accuracy: 95.50 % \n",
      "\n",
      "0.0008594112549695428\n",
      "Train Epoch: 7 [0/800 (0%)]\tTrain Loss: 0.020126\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.8230, \tTest Accuracy: 95.50 % \n",
      "\n",
      "0.0009634621756054177\n",
      "Train Epoch: 8 [0/800 (0%)]\tTrain Loss: 0.010895\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.2683, \tTest Accuracy: 92.00 % \n",
      "\n",
      "0.001\n",
      "Train Epoch: 9 [0/800 (0%)]\tTrain Loss: 0.028665\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.4995, \tTest Accuracy: 88.50 % \n",
      "\n",
      "0.0009944154354509117\n",
      "Train Epoch: 10 [0/800 (0%)]\tTrain Loss: 0.109283\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0521, \tTest Accuracy: 98.00 % \n",
      "\n",
      "0.0009777864917474587\n",
      "Train Epoch: 11 [0/800 (0%)]\tTrain Loss: 0.304906\n",
      "\n",
      "[EPOCH: 11], \tTest Loss: 0.0339, \tTest Accuracy: 99.00 % \n",
      "\n",
      "0.0009504846320134736\n",
      "Train Epoch: 12 [0/800 (0%)]\tTrain Loss: 0.374479\n",
      "\n",
      "[EPOCH: 12], \tTest Loss: 11.2412, \tTest Accuracy: 76.50 % \n",
      "\n",
      "0.0009131197346804487\n",
      "Train Epoch: 13 [0/800 (0%)]\tTrain Loss: 0.080306\n",
      "\n",
      "[EPOCH: 13], \tTest Loss: 0.4064, \tTest Accuracy: 94.00 % \n",
      "\n",
      "0.0008665264698111694\n",
      "Train Epoch: 14 [0/800 (0%)]\tTrain Loss: 0.014218\n",
      "\n",
      "[EPOCH: 14], \tTest Loss: 0.7219, \tTest Accuracy: 90.00 % \n",
      "\n",
      "0.000811745653949763\n",
      "Train Epoch: 15 [0/800 (0%)]\tTrain Loss: 0.013427\n",
      "\n",
      "[EPOCH: 15], \tTest Loss: 0.1174, \tTest Accuracy: 94.50 % \n",
      "\n",
      "0.0007500009999999999\n",
      "Train Epoch: 16 [0/800 (0%)]\tTrain Loss: 0.027189\n",
      "\n",
      "[EPOCH: 16], \tTest Loss: 0.2879, \tTest Accuracy: 94.00 % \n",
      "\n",
      "0.0006826717815011488\n",
      "Train Epoch: 17 [0/800 (0%)]\tTrain Loss: 0.004353\n",
      "\n",
      "[EPOCH: 17], \tTest Loss: 0.5283, \tTest Accuracy: 90.00 % \n",
      "\n",
      "0.0006112620219362892\n",
      "Train Epoch: 18 [0/800 (0%)]\tTrain Loss: 0.024611\n",
      "\n",
      "[EPOCH: 18], \tTest Loss: 0.0610, \tTest Accuracy: 97.50 % \n",
      "\n",
      "0.0005373668973330249\n",
      "Train Epoch: 19 [0/800 (0%)]\tTrain Loss: 0.019310\n",
      "\n",
      "[EPOCH: 19], \tTest Loss: 0.0662, \tTest Accuracy: 99.00 % \n",
      "\n",
      "0.00046263710266697503\n",
      "Train Epoch: 20 [0/800 (0%)]\tTrain Loss: 0.000433\n",
      "\n",
      "[EPOCH: 20], \tTest Loss: 0.0055, \tTest Accuracy: 100.00 % \n",
      "\n",
      "0.00038874197806371076\n",
      "Train Epoch: 21 [0/800 (0%)]\tTrain Loss: 0.001090\n",
      "\n",
      "[EPOCH: 21], \tTest Loss: 0.0109, \tTest Accuracy: 99.50 % \n",
      "\n",
      "0.0003173322184988512\n",
      "Train Epoch: 22 [0/800 (0%)]\tTrain Loss: 0.002669\n",
      "\n",
      "[EPOCH: 22], \tTest Loss: 0.0104, \tTest Accuracy: 99.50 % \n",
      "\n",
      "0.0002500030000000001\n",
      "Train Epoch: 23 [0/800 (0%)]\tTrain Loss: 0.000377\n",
      "\n",
      "[EPOCH: 23], \tTest Loss: 0.0047, \tTest Accuracy: 100.00 % \n",
      "\n",
      "0.00018825834605023698\n",
      "Train Epoch: 24 [0/800 (0%)]\tTrain Loss: 0.000159\n",
      "\n",
      "[EPOCH: 24], \tTest Loss: 0.0116, \tTest Accuracy: 99.00 % \n",
      "\n",
      "0.00013347753018883065\n",
      "Train Epoch: 25 [0/800 (0%)]\tTrain Loss: 0.001017\n",
      "\n",
      "[EPOCH: 25], \tTest Loss: 0.0057, \tTest Accuracy: 100.00 % \n",
      "\n",
      "8.688426531955129e-05\n",
      "Train Epoch: 26 [0/800 (0%)]\tTrain Loss: 0.000560\n",
      "\n",
      "[EPOCH: 26], \tTest Loss: 0.0197, \tTest Accuracy: 99.50 % \n",
      "\n",
      "4.9519367986526286e-05\n",
      "Train Epoch: 27 [0/800 (0%)]\tTrain Loss: 0.001989\n",
      "\n",
      "[EPOCH: 27], \tTest Loss: 0.0044, \tTest Accuracy: 100.00 % \n",
      "\n",
      "2.2217508252541176e-05\n",
      "Train Epoch: 28 [0/800 (0%)]\tTrain Loss: 0.025386\n",
      "\n",
      "[EPOCH: 28], \tTest Loss: 0.0060, \tTest Accuracy: 100.00 % \n",
      "\n",
      "5.588564549088189e-06\n",
      "Train Epoch: 29 [0/800 (0%)]\tTrain Loss: 0.000577\n",
      "\n",
      "[EPOCH: 29], \tTest Loss: 0.0034, \tTest Accuracy: 100.00 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking train, val loss and accuracy\n",
    "\n",
    "total = []\n",
    "\n",
    "for epoch in range(1, args.epochs):\n",
    "    train(model, train_loader, optimizer, log_interval = 200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
    "        epoch, test_loss, test_accuracy))\n",
    "    \n",
    "    total.append((test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84e2d5-394a-46ee-bdb0-6d566a2ebeff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de3ae9-4478-466d-a766-892ead5423f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dec81d-5481-4c38-8614-0ef2b54476dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce6d4df-cfd7-4ec5-b3d7-6688f287f936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d45bed-ba04-48bf-a30a-3d547c88db0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce365ac-b47b-478c-95a6-d18adac52a4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78db5112-98ce-40ec-8f8b-5f7df92c428d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e124d243-7506-4e88-b54b-091d65f40afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c895a-1c47-42ea-80b0-2c3ee73b6c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d2c19-c0fc-4926-94ee-ef2b928e3ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032fe8b6-488c-4de9-9d78-877c4b36d973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6712c09e-05f4-4ce4-a08e-3bc7821eec21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ba856-ffca-4ec1-b227-94b7e100111f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22d9c4-8b34-4d50-becb-4743403e2686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b028d5c-7de4-42d9-bc1b-8dfbc7237e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
