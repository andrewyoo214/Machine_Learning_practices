{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd379931-9f25-4101-b1fa-77ac82e23fdd",
   "metadata": {},
   "source": [
    "# Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c679b3b-7e14-463a-bb85-d939666c4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c29f3b-ecf4-484c-8b7d-c64626cb1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c495bd-d0c8-4426-b54f-c1a059f72baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model\n",
    "from pickle import dump\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6609cf18-e33c-4b0b-be77-8ff7b7de8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath= r\"E:\\RESEARCH\\Datasets\\VC\\sports\\data\"\n",
    "outputmodel = r\"E:\\RESEARCH\\Datasets\\VC\\sports\\classificationModel\"\n",
    "outputlabelbinarizer = \"E:\\RESEARCH\\Datasets\\VC\\sports\\classificationBinarizer\"\n",
    "epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0768bf03-048a-4903-95e9-2334aeac7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are being loaded...\n"
     ]
    }
   ],
   "source": [
    "sports_labels = set(['boxing','swimming','table_tennis'])\n",
    "print(\"Images are being loaded...\")\n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in sports_labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #if image is not in RGB form, change it to RGB format\n",
    "    image = cv2.resize(image, (244, 244)) #resizing the image. Here we trying resnet50 so 244x244\n",
    "    data.append(image) # appending data\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "795f4b82-3750-4749-8abb-c2c5301b4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels) # hot encodded values as 0,1,2\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0535e8f4-60e1-4047-ad32-c0c66a2b9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size = 0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5edd59-2cb7-4169-9a42-91864afea6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image data augmentation\n",
    "trainingAugmentation = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\"\n",
    ")\n",
    "\n",
    "validationAugmentation = ImageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainingAugmentation.mean = mean\n",
    "validationAugmentation.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfedd65f-31df-4d85-962d-4d6e7a2521d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\keras_applications\\resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the md5 file hash does not match the original value of a268eb855778b3df3c7506639542a6af so we will re-download the data.\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 11s 0us/step\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(244,244,3)))\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for basemodelLayers in baseModel.layers:\n",
    "    basemodelLayers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "691c85f5-46d1-4eec-8d61-174b9e4b4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.0001, momentum=0.9, decay=1e-4/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae15a25-fcde-4fdf-b261-c606bb0b0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b17f3b3d-e231-4a26-9c06-3203f7b34cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\vc\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 228s 5s/step - loss: 1.2661 - accuracy: 0.4450 - val_loss: 0.6737 - val_accuracy: 0.6641\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 222s 5s/step - loss: 0.8311 - accuracy: 0.6350 - val_loss: 0.3829 - val_accuracy: 0.7434\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 221s 5s/step - loss: 0.6809 - accuracy: 0.7274 - val_loss: 0.6343 - val_accuracy: 0.7821\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 223s 5s/step - loss: 0.5320 - accuracy: 0.7905 - val_loss: 0.4206 - val_accuracy: 0.8350\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 223s 5s/step - loss: 0.4726 - accuracy: 0.8172 - val_loss: 0.5807 - val_accuracy: 0.8187\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 223s 5s/step - loss: 0.4370 - accuracy: 0.8412 - val_loss: 0.3377 - val_accuracy: 0.8411\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 220s 4s/step - loss: 0.4106 - accuracy: 0.8523 - val_loss: 0.3334 - val_accuracy: 0.8859\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 227s 5s/step - loss: 0.3948 - accuracy: 0.8777 - val_loss: 0.3384 - val_accuracy: 0.8982\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 230s 5s/step - loss: 0.3520 - accuracy: 0.8751 - val_loss: 0.2656 - val_accuracy: 0.9002\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 231s 5s/step - loss: 0.3355 - accuracy: 0.8894 - val_loss: 0.2058 - val_accuracy: 0.9002\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 238s 5s/step - loss: 0.2988 - accuracy: 0.8929 - val_loss: 0.3548 - val_accuracy: 0.9022\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 256s 5s/step - loss: 0.3312 - accuracy: 0.8790 - val_loss: 0.2371 - val_accuracy: 0.9104\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 245s 5s/step - loss: 0.3156 - accuracy: 0.8977 - val_loss: 0.4040 - val_accuracy: 0.8982\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 253s 5s/step - loss: 0.2913 - accuracy: 0.8941 - val_loss: 0.2308 - val_accuracy: 0.9165\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 247s 5s/step - loss: 0.2924 - accuracy: 0.8977 - val_loss: 0.1778 - val_accuracy: 0.9185\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 248s 5s/step - loss: 0.2897 - accuracy: 0.8985 - val_loss: 0.2941 - val_accuracy: 0.8982\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 251s 5s/step - loss: 0.2682 - accuracy: 0.9096 - val_loss: 0.2687 - val_accuracy: 0.9226\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 250s 5s/step - loss: 0.2724 - accuracy: 0.9031 - val_loss: 0.3002 - val_accuracy: 0.9277\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 252s 5s/step - loss: 0.2418 - accuracy: 0.9158 - val_loss: 0.2568 - val_accuracy: 0.9267\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 245s 5s/step - loss: 0.2833 - accuracy: 0.9084 - val_loss: 0.3377 - val_accuracy: 0.9409\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 248s 5s/step - loss: 0.2732 - accuracy: 0.9193 - val_loss: 0.1215 - val_accuracy: 0.9409\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 252s 5s/step - loss: 0.2329 - accuracy: 0.9209 - val_loss: 0.1965 - val_accuracy: 0.9328\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 244s 5s/step - loss: 0.2394 - accuracy: 0.9150 - val_loss: 0.2007 - val_accuracy: 0.9409\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 248s 5s/step - loss: 0.2215 - accuracy: 0.9447 - val_loss: 0.1099 - val_accuracy: 0.9532\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 248s 5s/step - loss: 0.2345 - accuracy: 0.9265 - val_loss: 0.2625 - val_accuracy: 0.9328\n"
     ]
    }
   ],
   "source": [
    "History = model.fit_generator(\n",
    "    trainingAugmentation.flow(X_train, Y_train, batch_size=32),\n",
    "    steps_per_epoch = len(X_train) // 32,\n",
    "    validation_data = validationAugmentation.flow(X_test, Y_test),\n",
    "    validation_steps = len(X_test) // 32,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26f75d-dc85-451c-8b98-050e08915dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(outputmodel)\n",
    "# lbinarizer = open(r\"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer.pkl\", \"wb\")\n",
    "# lbinarizer = write(pickle.dumps(lb))\n",
    "# lbinarizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad5753-cee6-4516-b51e-c7896a09dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(outputmodel)\n",
    "dump(outputmodel,open(r\"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ed83a-0ff8-4b73-a53d-afffd5b61a13",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=BllyHlq5SsQ&list=PLxefhmF0pcPl_v-lLsqF3drP6NOoSYJR0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d975ac2-3e9b-4684-8018-ed3427f12b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8773a0bc-85e0-4498-91d9-01cb9b1e471c",
   "metadata": {},
   "source": [
    "## Now, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9874b9f6-f179-4f27-b5ce-fba63637b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aa9f34-bf13-4261-bab3-05d437dd70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\")\n",
    "lb = pickle.loads(open(r\"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer.pkl\",\"rb\").read())\n",
    "outputvideo = r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\\demo_output.avi\"\n",
    "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
    "Queue = deque(maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0efe52f-7456-49d2-8cf1-33bc3621b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb.classes_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93294378-a3fd-43b8-b4c0-f601b9fec0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture_video = cv2.VideoCapture(r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\\demo.mp4\")\n",
    "writer = None\n",
    "(Width, Height) = (None, None)\n",
    "\n",
    "while True:\n",
    "    (taken, frame) = capture_video.read()\n",
    "    if not taken:\n",
    "        break\n",
    "    if Width is None or Height is None:\n",
    "        (Width, Height) = frame.shape[:2]\n",
    "    \n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (244, 244)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "    preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "    Queue.append(preds)\n",
    "    results = np.array(Queue).mean(axis=0)\n",
    "    i = np.argmax(results)\n",
    "    label = lb.classes_[i]\n",
    "    text = \"The scene is about playing {}\".format(label)\n",
    "    cv2.putText(output, text, (45,60), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (255, 0, 0), 5)\n",
    "    \n",
    "    if writer is None:\n",
    "        fourcc = cv3.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(\"outputvideo\", fourcc, 30, (Width, Height), True)\n",
    "    writer.write(output)\n",
    "    cv2.imshow(\"In progress\",output)\n",
    "    key = cv2.waitKet(1) & 0xFF\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "print(\"Finalizing ...\")\n",
    "writer.release()\n",
    "capture_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50749b8-90b8-4b56-a1b7-047b4f26698a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6193c9-fd4f-462c-a5de-992baea68b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cb9ab-d731-48bc-9e55-2c24e7a62a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4089987d-0d41-4d41-8475-b434e80ccf65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fbd41-a2b5-4357-b92e-6e6fd71d4dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688840f-ae0c-445e-b10f-0ed98b8b9b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ed2be-ab0e-4ed4-8e56-4cc163410a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d367fb-b957-490a-a159-d1e53432ddbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede178f0-0358-4c48-81be-be7f4d5f0c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow_docs.vis import embed\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba75f5-cf77-480c-8212-54dceabe1f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a914d-4cea-4d04-aa2b-c66bbe7b6cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce70e2-7dc6-4fc8-a53a-f08365c09cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac37cd-3047-443b-aaee-d6e35a0da1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbecf1-455b-4094-bedd-1667da9a0784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40796f1-f273-4a4b-a13f-9abab76386fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62b6ff-6dcf-4a40-bd34-fc0c617eb3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308db887-b503-46d9-bd17-365ec039a1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47867a6a-ffc0-423a-8bb1-81140d23f43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
