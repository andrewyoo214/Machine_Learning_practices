{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd379931-9f25-4101-b1fa-77ac82e23fdd",
   "metadata": {},
   "source": [
    "# Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c679b3b-7e14-463a-bb85-d939666c4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c29f3b-ecf4-484c-8b7d-c64626cb1684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07c495bd-d0c8-4426-b54f-c1a059f72baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model\n",
    "from pickle import dump\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6609cf18-e33c-4b0b-be77-8ff7b7de8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath= r\"E:\\RESEARCH\\Datasets\\sports\\data\"\n",
    "outputmodel = r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\"\n",
    "outputlabelbinarizer = \"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer\"\n",
    "epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0768bf03-048a-4903-95e9-2334aeac7d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images are being loaded...\n"
     ]
    }
   ],
   "source": [
    "sports_labels = set(['boxing','swimming','table_tennis'])\n",
    "print(\"Images are being loaded...\")\n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in sports_labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #if image is not in RGB form, change it to RGB format\n",
    "    image = cv2.resize(image, (244, 244)) #resizing the image. Here we trying resnet50 so 244x244\n",
    "    data.append(image) # appending data\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "795f4b82-3750-4749-8abb-c2c5301b4ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels) # hot encodded values as 0,1,2\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0535e8f4-60e1-4047-ad32-c0c66a2b9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels, test_size = 0.25, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af5edd59-2cb7-4169-9a42-91864afea6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image data augmentation\n",
    "trainingAugmentation = ImageDataGenerator(\n",
    "    rotation_range = 30,\n",
    "    zoom_range = 0.15,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.15,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\"\n",
    ")\n",
    "\n",
    "validationAugmentation = ImageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainingAugmentation.mean = mean\n",
    "validationAugmentation.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfedd65f-31df-4d85-962d-4d6e7a2521d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(244,244,3)))\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for basemodelLayers in baseModel.layers:\n",
    "    basemodelLayers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691c85f5-46d1-4eec-8d61-174b9e4b4962",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.0001, momentum=0.9, decay=1e-4/epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dae15a25-fcde-4fdf-b261-c606bb0b0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer = opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b17f3b3d-e231-4a26-9c06-3203f7b34cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49/49 [==============================] - 58s 1s/step - loss: 1.3171 - accuracy: 0.4444 - val_loss: 0.5847 - val_accuracy: 0.7598\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 61s 1s/step - loss: 0.7160 - accuracy: 0.7144 - val_loss: 0.3375 - val_accuracy: 0.8770\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 60s 1s/step - loss: 0.5451 - accuracy: 0.7827 - val_loss: 0.2734 - val_accuracy: 0.9121\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.4483 - accuracy: 0.8256 - val_loss: 0.2426 - val_accuracy: 0.9199\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.4216 - accuracy: 0.8399 - val_loss: 0.2216 - val_accuracy: 0.9277\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.3563 - accuracy: 0.8562 - val_loss: 0.1917 - val_accuracy: 0.9434\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.3483 - accuracy: 0.8725 - val_loss: 0.1786 - val_accuracy: 0.9473\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.3090 - accuracy: 0.8770 - val_loss: 0.1712 - val_accuracy: 0.9434\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.3182 - accuracy: 0.8796 - val_loss: 0.1627 - val_accuracy: 0.9453\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2979 - accuracy: 0.8725 - val_loss: 0.1495 - val_accuracy: 0.9570\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2963 - accuracy: 0.8894 - val_loss: 0.1472 - val_accuracy: 0.9551\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2611 - accuracy: 0.9057 - val_loss: 0.1431 - val_accuracy: 0.9590\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2509 - accuracy: 0.9141 - val_loss: 0.1339 - val_accuracy: 0.9648\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2515 - accuracy: 0.9018 - val_loss: 0.1298 - val_accuracy: 0.9648\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2500 - accuracy: 0.9076 - val_loss: 0.1276 - val_accuracy: 0.9648\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2347 - accuracy: 0.9154 - val_loss: 0.1228 - val_accuracy: 0.9668\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2282 - accuracy: 0.9167 - val_loss: 0.1217 - val_accuracy: 0.9668\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2093 - accuracy: 0.9232 - val_loss: 0.1120 - val_accuracy: 0.9688\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2249 - accuracy: 0.9135 - val_loss: 0.1121 - val_accuracy: 0.9688\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2040 - accuracy: 0.9245 - val_loss: 0.1116 - val_accuracy: 0.9688\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.1870 - accuracy: 0.9382 - val_loss: 0.1087 - val_accuracy: 0.9688\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2064 - accuracy: 0.9304 - val_loss: 0.1057 - val_accuracy: 0.9707\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2010 - accuracy: 0.9258 - val_loss: 0.1014 - val_accuracy: 0.9746\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.1905 - accuracy: 0.9297 - val_loss: 0.1066 - val_accuracy: 0.9688\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 59s 1s/step - loss: 0.2042 - accuracy: 0.9258 - val_loss: 0.1027 - val_accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "History = model.fit_generator(\n",
    "    trainingAugmentation.flow(X_train, Y_train, batch_size=32),\n",
    "    steps_per_epoch = len(X_train) // 32,\n",
    "    validation_data = validationAugmentation.flow(X_test, Y_test),\n",
    "    validation_steps = len(X_test) // 32,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c26f75d-dc85-451c-8b98-050e08915dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(outputmodel)\n",
    "# lbinarizer = open(r\"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer.pkl\", \"wb\")\n",
    "# lbinarizer = write(pickle.dumps(lb))\n",
    "# lbinarizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50ad5753-cee6-4516-b51e-c7896a09dc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: E:\\RESEARCH\\Datasets\\sports\\classificationModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(outputmodel)\n",
    "dump(outputmodel,open(r\"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c793a-79f0-4159-bb70-d97bf398533d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d975ac2-3e9b-4684-8018-ed3427f12b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8773a0bc-85e0-4498-91d9-01cb9b1e471c",
   "metadata": {},
   "source": [
    "## Now, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9874b9f6-f179-4f27-b5ce-fba63637b9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89aa9f34-bf13-4261-bab3-05d437dd70e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\")\n",
    "lb = pickle.loads(open(r\"E:\\RESEARCH\\Datasets\\sports\\classificationBinarizer.pkl\",\"rb\").read())\n",
    "outputvideo = r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\\demo_output.avi\"\n",
    "mean = np.array([123.68, 116.779, 103.939][::1], dtype=\"float32\")\n",
    "Queue = deque(maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0efe52f-7456-49d2-8cf1-33bc3621b411",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-a426848e0077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "lb.classes_[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93294378-a3fd-43b8-b4c0-f601b9fec0de",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-36d1dcd3cd26>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQueue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"The scene is about playing {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'classes_'"
     ]
    }
   ],
   "source": [
    "capture_video = cv2.VideoCapture(r\"E:\\RESEARCH\\Datasets\\sports\\classificationModel\\demo.mp4\")\n",
    "writer = None\n",
    "(Width, Height) = (None, None)\n",
    "\n",
    "while True:\n",
    "    (taken, frame) = capture_video.read()\n",
    "    if not taken:\n",
    "        break\n",
    "    if Width is None or Height is None:\n",
    "        (Width, Height) = frame.shape[:2]\n",
    "    \n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (244, 244)).astype(\"float32\")\n",
    "    frame -= mean\n",
    "    preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "    Queue.append(preds)\n",
    "    results = np.array(Queue).mean(axis=0)\n",
    "    i = np.argmax(results)\n",
    "    label = lb.classes_[i]\n",
    "    text = \"The scene is about playing {}\".format(label)\n",
    "    cv2.putText(output, text, (45,60), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (255, 0, 0), 5)\n",
    "    \n",
    "    if writer is None:\n",
    "        fourcc = cv3.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(\"outputvideo\", fourcc, 30, (Width, Height), True)\n",
    "    writer.write(output)\n",
    "    cv2.imshow(\"In progress\",output)\n",
    "    key = cv2.waitKet(1) & 0xFF\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "print(\"Finalizing ...\")\n",
    "writer.release()\n",
    "capture_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50749b8-90b8-4b56-a1b7-047b4f26698a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6193c9-fd4f-462c-a5de-992baea68b44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cb9ab-d731-48bc-9e55-2c24e7a62a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7699201-06c3-4f6c-93e8-13edc3d6ca00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede178f0-0358-4c48-81be-be7f4d5f0c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba75f5-cf77-480c-8212-54dceabe1f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a914d-4cea-4d04-aa2b-c66bbe7b6cf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce70e2-7dc6-4fc8-a53a-f08365c09cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac37cd-3047-443b-aaee-d6e35a0da1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbbecf1-455b-4094-bedd-1667da9a0784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40796f1-f273-4a4b-a13f-9abab76386fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62b6ff-6dcf-4a40-bd34-fc0c617eb3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308db887-b503-46d9-bd17-365ec039a1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47867a6a-ffc0-423a-8bb1-81140d23f43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
