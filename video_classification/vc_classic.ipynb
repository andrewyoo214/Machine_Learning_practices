{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74fd5ae6-fddc-4a58-893a-5998feb39f8d",
   "metadata": {},
   "source": [
    "# Video Classification on CM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1da5cc-5ee8-4987-b5b4-0225c4c4884a",
   "metadata": {},
   "source": [
    "* Here we generate real-time classical music instruments information generator on classical music concert video input. \n",
    "* We basically adopt video classification method using pytorch, to classify what instrument is currently viewed on the screen. \n",
    "* Audience will receive the streaming video with information on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda0c3eb-4bba-4c1c-856b-ffcf38aeed45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a2f13d-b751-498b-979d-1c54d8af3c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f896f26-7f7e-4751-a302-21bd10505fc1",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fd2e4-6ec5-430b-86b0-3f5a458afdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required components \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "import urllib\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a75ce7-9dad-40f2-8b10-dd349c8a0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing remaining components\n",
    "import json\n",
    "import urllib\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    ")\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33fe3a-120a-4219-906a-5e72e8e70120",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699d1732-04e3-4d43-89e2-6c218791b12b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3534c8d-fb73-481a-a4b9-2aa03b2cfa66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0f501cb-07a3-4d33-a2d8-cfed68314fd1",
   "metadata": {},
   "source": [
    "## Data Crawling for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2fa4e-cbf4-408a-bf61-85da656beed2",
   "metadata": {},
   "source": [
    "* Here we create each folder for classical instruments that used in classical music concert\n",
    "* Classical Instruments: bassoon, cello, clarinet, doublebasses, flute, harp, horn, oboe, timpani, trombone, trumpet, tuba, viola, violin (total 14 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd079faf-61a3-49ee-819e-a0a8ab212415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import time\n",
    "from urllib.parse import quote_plus\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from icrawler.builtin import GoogleImageCrawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea78c751-f486-4b10-9586-89e6afbaad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### image crawling from google with GoogleImageCrawler\n",
    "google_crawler = GoogleImageCrawler(\n",
    "    feeder_threads=1,\n",
    "    parser_threads=1,\n",
    "    downloader_threads=4,\n",
    "    storage={'root_dir': 'E:/RESEARCH/Datasets/VC/classic/violin'})\n",
    "#     storage={'root_dir': 'E:/RESEARCH/Datasets/image/CIFAR_PUB/truck'}) #set the storage root\n",
    "\n",
    "filters = dict(\n",
    "#     type='photo',\n",
    "    #type=photo,face,clipart,linedrawing,animated\n",
    "    size='medium',\n",
    "    #size=large, medium, icon, or larger than a given size e.g.\">640x480\" or exactly giving size\"=1024x768\n",
    "#     color='orange',\n",
    "    #coler=blackandwhite, red, oragne, yellow, green, teal, blue, purple, pink, white, gray, black, brown\n",
    "#     license='commercial,modify',\n",
    "    #license=noncommercial, commercial, noncommercial,modify , commercial,modify\n",
    "    date=((2000, 1, 1), (2021, 12, 30)))\n",
    "\n",
    "# type the keyword of the image that you want to crawl from google\n",
    "google_crawler.crawl(keyword= 'violin orchestra', filters=filters, offset=0, max_num=1000,\n",
    "                     min_size=(200,200), max_size=None, file_idx_offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae0d74b-b4ec-4a2b-bd70-42eeb585eac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7816b4d7-8724-41be-a777-fb9931db1df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b7a8c-0ae0-4d53-9ee0-f665220534e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8879929-cd2c-4d3b-9280-057144d7005f",
   "metadata": {},
   "source": [
    "## Training model preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a2026-b1d0-4fbf-a5fd-253be1d5dc72",
   "metadata": {},
   "source": [
    "* Our approach is train the model from image classification task, and apply it for the video classification. \n",
    "* So it is also possible to use pretrained models, such as, resnet, efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bb96f5-b746-465e-b431-efd2510bb4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the `slowFAST_r50` pretrained model - for our video classification model training \n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fd817-eb45-4561-b124-ae4843daa154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ca06b-0d09-4417-a345-2e3583dde4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218f2f91-05da-470c-8e58-94093a6c488e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad4ea5-1d90-4b54-870a-9cd518b35c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540d9e67-1ca3-4986-93b9-9ac7c8ec4a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3468a1-81b8-4049-a8c6-1baa276cbb41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7efbdd-f571-4407-97d6-e36fa4df54b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c6f8d8-4e2b-46e1-8d19-dfb683cf1124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dc5bd2-a1bf-41ce-aeb6-34f6a1dc66b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc65e8a-d2f0-4c10-a505-44f6e4f85c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbad7d-ea5b-4934-b8ad-4baa8751efc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f528fd-c78e-4626-83f0-bfe70becd64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8cd723-bda8-4ee5-b904-1aab6cff9fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c23dc-88d4-4182-a940-227f19c4205a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef1800-a496-472e-af6e-4677f31eaa0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c756a-bb29-4e65-b6cf-418e5cab7721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c6155-e112-41d5-8ee8-f39f85f264c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9e65d-e2d0-4eea-bd44-6ffa539f31af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c67f6-c6f9-4e65-b566-ee8facea7be2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
