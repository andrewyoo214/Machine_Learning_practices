{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14256a7-f748-4036-bc2e-0cdb72c3ade6",
   "metadata": {},
   "source": [
    "# AIM5004_HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763857cf-9ed9-4f2b-bb1a-dc11e57aebb7",
   "metadata": {},
   "source": [
    "* Implementation of MLP (Multilayer Perceptron). You are going to write codes in any programming languages from the scratch. You can use some libraries, e.g. numpy, but you are NOT allowed to use any deep learning libraries, such as. Tensorflow, Pytorch, and JAX.\n",
    "\n",
    "* You should submit the codes as Jupyter notebook, .ipynb file or google colab link. All codes should be executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89ea062-558d-4c41-91dd-3e27c26d808f",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb822c2-5672-49a4-90d3-a0b7e90d2d55",
   "metadata": {},
   "source": [
    "(a) Download MNIST dataset from http://yann.lecun.com/exdb/mnist/ and report the\n",
    "statistics of the dataset, e.g. how many training (and testing) images, the size of each image, the number of class and the number of images per each classes. Normalize data to [0, 1] if necessary. Show random 3 images per each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d8158-4b9d-4d4c-b0fa-c9844d95cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import random\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a49a9f-ced3-4364-8fe3-d3dd32adf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef1e54-4e67-4164-829a-54379735b689",
   "metadata": {},
   "source": [
    "We got 4 data files\n",
    "- train-images-idx3-ubyte.gz\n",
    "- train-labels-idx1-ubyte.gz\n",
    "- t10k-images-idx3-ubyte.gz\n",
    "- t10k-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e1d5a-a62e-4931-9e7c-4b6b4c84625f",
   "metadata": {},
   "source": [
    "### Handling Training dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a110d9-41c9-4d77-8a58-86a5efa99e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open gz train data downloaded from lecun. - using gzip.open \n",
    "with gzip.open('./data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_data_ori = idx2numpy.convert_from_file(f)\n",
    "\n",
    "with gzip.open('./data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_label = idx2numpy.convert_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9b695d-a3b2-44c0-ae51-42ae6156d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resizing training dataset and normalize data\n",
    "train_data_ori = train_data_ori.reshape(len(train_data_ori),-1)\n",
    "train_data_ori = train_data_ori.astype(float)/255\n",
    "# train_data_ori = MinMaxScaler().fit_transform(train_data_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32a5cb5-4f62-4a40-997e-8e3b2f77401a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Encoding training label values\n",
    "train_label = np.eye(10)[train_label].reshape(len(train_label),10)\n",
    "\n",
    "## Seperate out the validation set.\n",
    "train_data_ori, val_data, train_label, val_label = train_test_split(train_data_ori, train_label, test_size=10000, random_state=710674)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cee8c5-55ec-4333-bded-85b5470815a2",
   "metadata": {},
   "source": [
    "### Handling Test dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54208b-5fc2-4958-b8a2-1145d717c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open gz test dataset\n",
    "with gzip.open('./data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_data = idx2numpy.convert_from_file(f)\n",
    "    \n",
    "with gzip.open('./data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_label = idx2numpy.convert_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8006a3-f2b3-4494-8b68-f8d29cab00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping test dataset and normalize the data\n",
    "test_data = test_data.reshape(len(test_data),-1)\n",
    "test_data = test_data.astype(float)/255\n",
    "# test_data = MinMaxScaler().fit_transform(test_data)\n",
    "\n",
    "## Encoding test label values\n",
    "test_label = np.eye(10)[test_label].reshape(len(test_label),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc96f3-89b8-4f57-9dd1-0958cac56b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping data into pixel formats: (28 x 28) format\n",
    "train_data = train_data_ori.reshape(len(train_data_ori),28,28)\n",
    "val_data = val_data.reshape(len(val_data),28,28)\n",
    "test_data = test_data.reshape(len(test_data),28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158df3cf-a7ad-49ae-bac6-299868e23ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd613dd5-0329-4b36-a077-69030ec96aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bfceffe-0042-4dfb-9b7a-7f614925f119",
   "metadata": {},
   "source": [
    "### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3503c01-fe60-4201-a17e-70b22e65f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The train data has \", str(train_data.shape[0]), \"samples\")\n",
    "print(\"The validation data has \", str(val_data.shape[0]), \"samples\")\n",
    "print(\"The test data has \", str(test_data.shape[0]), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d25f1c-c45a-435a-9aba-509c31081345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b17e494-1a5c-41ce-b1ae-0d568b11e328",
   "metadata": {},
   "source": [
    "### Random image samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a80187-42fb-4e1d-a52f-f6a6aa5493fc",
   "metadata": {},
   "source": [
    "* Show random 3 images per each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd934dc-eb82-40d6-a8f1-5043aa3e80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cc2145-8786-46d6-b95a-36109e1a9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding out which data row is matched for\n",
    "class0 = train_df.loc[train_df[0] == 1]\n",
    "class1 = train_df.loc[train_df[1] == 1]\n",
    "class2 = train_df.loc[train_df[2] == 1]\n",
    "class3 = train_df.loc[train_df[3] == 1]\n",
    "class4 = train_df.loc[train_df[4] == 1]\n",
    "class5 = train_df.loc[train_df[5] == 1]\n",
    "class6 = train_df.loc[train_df[6] == 1]\n",
    "class7 = train_df.loc[train_df[7] == 1]\n",
    "class8 = train_df.loc[train_df[8] == 1]\n",
    "class9 = train_df.loc[train_df[9] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9e7c7-5f7d-419d-bdfa-b73f83fdf2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_index = class0.index\n",
    "class1_index = class1.index\n",
    "class2_index = class2.index\n",
    "class3_index = class3.index\n",
    "class4_index = class4.index\n",
    "class5_index = class5.index\n",
    "class6_index = class6.index\n",
    "class7_index = class7.index\n",
    "class8_index = class8.index\n",
    "class9_index = class9.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe834723-1b5c-4ac0-a5f5-b829a5c710f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SampleImages():\n",
    "#     ran = random.sample(range(len(train_data)),3)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.subplot(5,6,1)\n",
    "    plt.imshow(train_data[0], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,2)\n",
    "    plt.imshow(train_data[3], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,3)\n",
    "    plt.imshow(train_data[4], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,4)\n",
    "    plt.imshow(train_data[13], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,5)\n",
    "    plt.imshow(train_data[39], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,6)\n",
    "    plt.imshow(train_data[44], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,7)\n",
    "    plt.imshow(train_data[11], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,8)\n",
    "    plt.imshow(train_data[16], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,9)\n",
    "    plt.imshow(train_data[30], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,10)\n",
    "    plt.imshow(train_data[9], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,11)\n",
    "    plt.imshow(train_data[22], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,12)\n",
    "    plt.imshow(train_data[38], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,13)\n",
    "    plt.imshow(train_data[6], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,14)\n",
    "    plt.imshow(train_data[7], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,15)\n",
    "    plt.imshow(train_data[18], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,16)\n",
    "    plt.imshow(train_data[1], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,17)\n",
    "    plt.imshow(train_data[20], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,18)\n",
    "    plt.imshow(train_data[24], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,19)\n",
    "    plt.imshow(train_data[8], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,20)\n",
    "    plt.imshow(train_data[21], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,21)\n",
    "    plt.imshow(train_data[26], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,22)\n",
    "    plt.imshow(train_data[5], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,23)\n",
    "    plt.imshow(train_data[12], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,24)\n",
    "    plt.imshow(train_data[17], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,25)\n",
    "    plt.imshow(train_data[2], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,26)\n",
    "    plt.imshow(train_data[29], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,27)\n",
    "    plt.imshow(train_data[45], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,28)\n",
    "    plt.imshow(train_data[15], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,29)\n",
    "    plt.imshow(train_data[23], cmap='gray');plt.axis('off')\n",
    "    plt.subplot(5,6,30)\n",
    "    plt.imshow(train_data[25], cmap='gray');plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266ac01-24ec-4bae-b335-b1ad1a6f510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleImages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1dc47-8cda-4d1a-86e4-5f20c69c4884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7786756f-2114-4902-9f5e-00415d70c63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d68f4-3d37-40bc-91ba-c6b4236c078f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "585733ec-1d84-4e36-afc6-0d0a61c3015a",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65808e6d-d702-4cd4-b5fb-26dc490b199a",
   "metadata": {},
   "source": [
    "(b) Implement a MLP architecture and write forward pass. You need to implement all\n",
    "following layers, ReLU activation function, and softmax function. You should also\n",
    "implement cross-entropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f3747-d47d-4c4d-82fb-3e9c0312b59d",
   "metadata": {},
   "source": [
    "(1) Architecture:\\\n",
    "[Layer 1] → Flatten layer that will flatten image 2D matrix into 1D vector.\\\n",
    "[Layer 2] → Dense layer (fully connected layer) with 128 hidden units, followed\n",
    "by ReLU activation function.\\\n",
    "[Layer 3] → Dense layer (fully connected layer) with 128 hidden units, followed\n",
    "by ReLU activation function.\\\n",
    "[Layer 4] → Output dense layer (fully connected layer) with 10 softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1cdfe-7536-42bc-90e5-d7a895110379",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sigmoid\n",
    "def sigmoid(z):\n",
    "    return 1.0/ (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a853d-b71e-438a-8cef-4d830d03be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relu Function\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c7822-8389-4f6a-8c6d-769c6cd115b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Relu activation function layer\n",
    "class relu(layer):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, input):\n",
    "        relu_forward = np.maximum(0,input)\n",
    "        return relu_forward\n",
    "    def backward(self, input, grad_output):\n",
    "        relu_grad = input >0\n",
    "        return grad_output*relu_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c927d7b4-a348-4849-af14-c678aef61c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_units, output_units, learning_rate=0.1):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.normal(loc=0.0, \n",
    "                                        scale = np.sqrt(2/(input_units+output_units)), \n",
    "                                        size = (input_units,output_units))\n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        return np.dot(input,self.weights) + self.biases\n",
    "    \n",
    "    \n",
    "    def backward(self,input,grad_output):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        \n",
    "\n",
    "        grad_weights = np.dot(input.T, grad_output)\n",
    "        grad_biases = grad_output.mean(axis=0)*input.shape[0]\n",
    "        \n",
    "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
    "        \n",
    "        # Here we perform a stochastic gradient descent step. \n",
    "        self.weights = self.weights - self.learning_rate * grad_weights\n",
    "        self.biases = self.biases - self.learning_rate * grad_biases\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba1933-562c-4588-97df-bff76710bfde",
   "metadata": {},
   "source": [
    "[LAYER1] Flatten data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7918c73-cfb4-42d2-9744-8b58d03f2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca599ad-2f86-4a46-81a9-f3a1334bc492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f3a4e-bd23-4b39-88a4-4758ef63ef13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027f2ca-7b07-45e6-b46a-f2348852434e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfe03d-3492-47d7-b48f-24b8bb90622f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672e400-c47a-4bf0-97f0-e12c4e5247ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2013e94-b562-43c5-a16b-6da19c730b40",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb371c-ed30-4eca-a256-316da2ebc7de",
   "metadata": {},
   "source": [
    "(c) Implement backward pass to compute the gradients w.r.t the parameters. You should check the correctness of your implementation by either (1) using finite difference or (2) using the existing deep learning libraries. Please provide checking codes in the report ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8ec8a2-225c-4cbc-9457-d8221aa26bf0",
   "metadata": {},
   "source": [
    "* Check the values like MSE or finite difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96421550-9067-446d-8064-9697230fbe7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ce52a0-a3ce-48b3-ba85-4d77efd83d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1104f0-8715-4110-88b0-a30cc69a0a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77cbfa-4a7c-4aec-ad5a-e8388c5a6e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94835169-9ba8-4720-a45f-86256f5ae87f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31c46f3b-2948-4905-847a-a45ee42e7110",
   "metadata": {},
   "source": [
    "* Comparison - (2) Using the existing deep learning libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a0093-379b-4a2c-b87f-683bed67fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init \n",
    "import torchvision\n",
    "from torchvision import transforms, datasets \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d96fdec-5386-4674-9708-7b8341ab9876",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe34ce-eb03-4649-b816-eab125a536d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = transform(train_data)\n",
    "xtest = transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240e40d-db05-42af-b485-2ad396e8a8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(xtrain, batch_size=32)\n",
    "test_loader = DataLoader(xtest, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc665b41-a515-4142-90b3-225a5672938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_torch(nn.Module):\n",
    "    def __init__(self, input_size=784, output_size=10, layers=[128,128]):\n",
    "        super().__init()\n",
    "        self.d1 = nn.Linear(input_size, layers[0])\n",
    "        self.d2 = nn.Linear(layers[0], layers[1])\n",
    "        self.d3 = nn.Linear(layers[1], output_size)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.d1(X))\n",
    "        X = F.relu(self.d2(X))\n",
    "        X = self.d3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37569223-27ed-42c0-b1e1-5875399f2c72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a96d72e-5e05-4ea7-aeeb-d47c8406d4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc84079-a680-4a1f-bd23-8b5d58d566e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ce46c0-e3bf-4762-a1b9-6416b649f845",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd745265-1213-4bdb-8986-21672faead3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed90a89-f568-456b-af0a-053ec5a0a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59002f84-1f79-4623-9def-bd290cf429a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc655f18-eaac-4737-bedf-55d34eefa6a4",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9f6b2-0bd8-4624-b18d-c2aeefd98d37",
   "metadata": {},
   "source": [
    "(d) Implement a stochastic gradient descent (SGD) algorithm and train your model. Please provide training and validation loss curves in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba78f4-8446-4924-b51a-6c0fd885d282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=30\n",
    "    bs=6\n",
    "    lr=0.001\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99271c69-3339-4c81-92c4-ef621484ca76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_mnist (x, y):\n",
    "    lr = args.lr\n",
    "    n_epochs = args.epochs\n",
    "    batch = args.bs\n",
    "    w = np.random.randn(1, 13)\n",
    "    b = np.random.randn(1, 1)\n",
    "    epoch =1\n",
    "    \n",
    "    while epoch <= n_epochs:\n",
    "        temp = x.sample(bs)\n",
    "        x_tr = temp.iloc[:, 0:13].values\n",
    "        y_tr = temp.iloc[:, -1].values\n",
    "        \n",
    "        lw = w\n",
    "        lb = b\n",
    "        loss = 0\n",
    "        y_pred = []\n",
    "        sq_loss = []\n",
    "        \n",
    "        for i in range(batch):\n",
    "            lw = (-2/batch * x_tr[i]) * (y_tr[i] - np.dot(x_tr[i], w.T) - b)\n",
    "            lb = (-2/batch) * (y_tr[i] - np.dot(x_tr[i], w.T) -b)\n",
    "            w = w - lr * lw\n",
    "            b = b - lr*lb\n",
    "            predicted = np.dot(x_tr[i], w.T)\n",
    "            y_pred.append(predicted)\n",
    "        \n",
    "        loss = mean_squared_error(y_pred, y_tr)\n",
    "        print(\"Epoch: %d, Loss: %.3f\" %(epoch, loss))\n",
    "        epoch += 1\n",
    "        lr = lr/1.01\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3730371-26ba-4baf-ba3a-42ba5f186df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, w, b):\n",
    "    y_pred = []\n",
    "    for i in range(len(x)):\n",
    "        temp_ = x\n",
    "        x_test = temp_.iloc[:, 0:13].values\n",
    "        y = np.asscalar(np.dot(w, x_test[i]) + b)\n",
    "        y_pred.append(y)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "w, b = sgd_mnist(x_train, y_train)\n",
    "y_pred_sgd = predict(x_test, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02624f66-e43d-4c52-927b-2c79c0c5ad10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7106c-5cab-4ede-8bf9-04fbfaecd1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603b0ec-bfce-4ff7-afcf-18fd3c065e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58375ed1-f701-4390-aded-3d56a77de480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da4201ac-480a-4331-8bb0-f6e0ab7a179d",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74720fb7-0de6-4e3e-b5a3-fbb3d90e4f44",
   "metadata": {},
   "source": [
    "(e) Train with different hyperparameters. Try at least 5 different learning rates and minibatch sizes. Plot training and validation curves for all different configurations in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40a5fe-5ce9-4116-9778-83d7020e55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bbf9a5-c4aa-49f5-af45-87747e306ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807da90-6d74-466f-b3b9-1a28a362b167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049e8c7a-e163-44e6-b417-de5306be6d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca39e-4d59-4e36-9c1e-37e1c0b865d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d5fd9-0af0-46ed-8b35-7efbe77daf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
