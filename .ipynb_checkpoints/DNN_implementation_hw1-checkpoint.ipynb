{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14256a7-f748-4036-bc2e-0cdb72c3ade6",
   "metadata": {},
   "source": [
    "# AIM5004_HW1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763857cf-9ed9-4f2b-bb1a-dc11e57aebb7",
   "metadata": {},
   "source": [
    "* Implementation of MLP (Multilayer Perceptron). You are going to write codes in any programming languages from the scratch. You can use some libraries, e.g. numpy, but you are NOT allowed to use any deep learning libraries, such as. Tensorflow, Pytorch, and JAX.\n",
    "\n",
    "* You should submit the codes as Jupyter notebook, .ipynb file or google colab link. All codes should be executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb822c2-5672-49a4-90d3-a0b7e90d2d55",
   "metadata": {},
   "source": [
    "(a) Download MNIST dataset from http://yann.lecun.com/exdb/mnist/ and report the\n",
    "statistics of the dataset, e.g. how many training (and testing) images, the size of each image, the number of class and the number of images per each classes. Normalize data to [0, 1] if necessary. Show random 3 images per each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "471d8158-4b9d-4d4c-b0fa-c9844d95cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import random\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a49a9f-ced3-4364-8fe3-d3dd32adf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef1e54-4e67-4164-829a-54379735b689",
   "metadata": {},
   "source": [
    "We got 4 data files\n",
    "- train-images-idx3-ubyte.gz\n",
    "- train-labels-idx1-ubyte.gz\n",
    "- t10k-images-idx3-ubyte.gz\n",
    "- t10k-labels-idx1-ubyte.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7e1d5a-a62e-4931-9e7c-4b6b4c84625f",
   "metadata": {},
   "source": [
    "### Handling Training dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05a110d9-41c9-4d77-8a58-86a5efa99e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open gz train data downloaded from lecun. - using gzip.open \n",
    "with gzip.open('./data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_data = idx2numpy.convert_from_file(f)\n",
    "\n",
    "with gzip.open('./data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_label = idx2numpy.convert_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9b695d-a3b2-44c0-ae51-42ae6156d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resizing training dataset and normalize data\n",
    "train_data = train_data.reshape(len(train_data),-1)\n",
    "train_data = MinMaxScaler().fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a32a5cb5-4f62-4a40-997e-8e3b2f77401a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Encoding training label values\n",
    "train_label = np.eye(10)[train_label].reshape(len(train_label),10)\n",
    "\n",
    "## Seperate out the validation set. \n",
    "train_data, val_data, train_label, val_label = train_test_split(train_data, train_label, test_size=10000, random_state=710674)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cee8c5-55ec-4333-bded-85b5470815a2",
   "metadata": {},
   "source": [
    "### Handling Test dataset and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef54208b-5fc2-4958-b8a2-1145d717c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open gz test dataset\n",
    "with gzip.open('./data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_data = idx2numpy.convert_from_file(f)\n",
    "    \n",
    "with gzip.open('./data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_label = idx2numpy.convert_from_file(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8006a3-f2b3-4494-8b68-f8d29cab00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping test dataset and normalize the data\n",
    "test_data = test_data.reshape(len(test_data),-1)\n",
    "test_data = MinMaxScaler().fit_transform(test_data)\n",
    "\n",
    "## Encoding test label values\n",
    "test_label = np.eye(10)[test_label].reshape(len(test_label),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "106f79c4-d85a-455b-b483-a02fe27aa8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0dc96f3-89b8-4f57-9dd1-0958cac56b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reshaping data into pixel formats: (28 x 28) format\n",
    "train_data = train_data.reshape(len(train_data),28,28)\n",
    "val_data = val_data.reshape(len(val_data),28,28)\n",
    "test_data = test_data.reshape(len(test_data),28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158df3cf-a7ad-49ae-bac6-299868e23ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd613dd5-0329-4b36-a077-69030ec96aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bfceffe-0042-4dfb-9b7a-7f614925f119",
   "metadata": {},
   "source": [
    "### Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3503c01-fe60-4201-a17e-70b22e65f625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train data has  50000 samples\n",
      "The validation data has  10000 samples\n",
      "The test data has  10000 samples\n"
     ]
    }
   ],
   "source": [
    "print(\"The train data has \", str(train_data.shape[0]), \"samples\")\n",
    "print(\"The validation data has \", str(val_data.shape[0]), \"samples\")\n",
    "print(\"The test data has \", str(test_data.shape[0]), \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ae6cc-1b92-4922-9510-ff5f12c498f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20924b-c4c0-43ae-9a02-847177e19523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d25f1c-c45a-435a-9aba-509c31081345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b17e494-1a5c-41ce-b1ae-0d568b11e328",
   "metadata": {},
   "source": [
    "### Random image samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f59a7bcb-3c21-4f19-9607-a110f21cd224",
   "metadata": {},
   "outputs": [],
   "source": [
    "random = []\n",
    "for i in range(0, len(train_data)):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f145f00-3d24-4608-91af-af28d339a4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8310827543516508"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c33e0ba-20e7-4538-a3cf-3abbc63487c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_data.loc[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796dcf02-241e-4a85-b4cb-0264ae33a07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1d1712-99b7-4a2f-84a6-80f1ceca67b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266ac01-24ec-4bae-b335-b1ad1a6f510e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65808e6d-d702-4cd4-b5fb-26dc490b199a",
   "metadata": {},
   "source": [
    "(b) Implement a MLP architecture and write forward pass. You need to implement all\n",
    "following layers, ReLU activation function, and softmax function. You should also\n",
    "implement cross-entropy loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78f3747-d47d-4c4d-82fb-3e9c0312b59d",
   "metadata": {},
   "source": [
    "(1) Architecture:\\\n",
    "[Layer 1] → Flatten layer that will flatten image 2D matrix into 1D vector.\\\n",
    "[Layer 2] → Dense layer (fully connected layer) with 128 hidden units, followed\n",
    "by ReLU activation function.\\\n",
    "[Layer 3] → Dense layer (fully connected layer) with 128 hidden units, followed\n",
    "by ReLU activation function.\\\n",
    "[Layer 4] → Output dense layer (fully connected layer) with 10 softmax outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77cb8a-cbbf-4770-a546-0a218518ffa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dfe03d-3492-47d7-b48f-24b8bb90622f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672e400-c47a-4bf0-97f0-e12c4e5247ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfdde3-3626-4df4-9ffb-ee83fde19f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbdb371c-ed30-4eca-a256-316da2ebc7de",
   "metadata": {},
   "source": [
    "(c) Implement backward pass to compute the gradients w.r.t the parameters. You should check the correctness of your implementation by either (1) using finite difference or (2) using the existing deep learning libraries. Please provide checking codes in the report ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0dc7b-f062-41ae-985c-04ab573d0b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1104f0-8715-4110-88b0-a30cc69a0a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59002f84-1f79-4623-9def-bd290cf429a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c0272-7c57-46fe-9efc-37ce3239ff7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da9f6b2-0bd8-4624-b18d-c2aeefd98d37",
   "metadata": {},
   "source": [
    "(d) Implement a stochastic gradient descent (SGD) algorithm and train your model. Please provide training and validation loss curves in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99271c69-3339-4c81-92c4-ef621484ca76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603b0ec-bfce-4ff7-afcf-18fd3c065e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58375ed1-f701-4390-aded-3d56a77de480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3275fd9-8e71-4651-87ec-e325603f4ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74720fb7-0de6-4e3e-b5a3-fbb3d90e4f44",
   "metadata": {},
   "source": [
    "(e) Train with different hyperparameters. Try at least 5 different learning rates and minibatch sizes. Plot training and validation curves for all different configurations in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c40a5fe-5ce9-4116-9778-83d7020e55b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eca39e-4d59-4e36-9c1e-37e1c0b865d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892d5fd9-0af0-46ed-8b35-7efbe77daf08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
